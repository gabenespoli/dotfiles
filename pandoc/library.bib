Automatically generated by Mendeley Desktop 1.17.11
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Henry2017,
abstract = {Entrainment of neural oscillations on multiple time scales is important for the perception of speech. Musical rhythms, and in particular the perception of a regular beat in musical rhythms, is also likely to rely on entrainment of neural oscillations. One recently proposed approach to studying beat perception in the context of neural entrainment and resonance has received an enthusiastic response from the community. The approach involves comparing frequency- domain representations of acoustic rhythm stimuli to the frequency-domain representations of neural responses to those rhythms (measured by electroencephalography, EEG). The relative heights of EEG frequencies are compared to the relative heights of stimulus frequencies, and enhancements of beat-related frequencies in the EEG are interpreted as reflecting an internal representation of the beat. Here, we show that frequency-domain representations of rhythms are sensitive to the acoustic features of the tones making up the rhythms (tone duration, onset/offset ramp duration); in fact, relative heights of amplitude peaks at beat-related frequencies can be completely reversed by manipulating tone acoustics. Crucially, we show that changes to these acoustic tone features, and in turn changes to the frequency-domain representations of rhythms, do not affect beat perception. Instead, beat perception depends on the pattern of onsets (i.e., whether a rhythm has a simple or complex metrical structure). Moreover, we show that beat perception can differ for rhythms that have numerically identical frequency-domain representations. Thus, frequency-domain 69 representations of rhythms are dissociable from beat perception. For this reason, we suggest caution in interpreting direct comparisons of rhythms and brain signals in the frequency domain. Instead, we suggest that combining EEG measurements of neural signals with creative behavioral paradigms will be of more benefit to our understanding of beat perception.},
author = {Henry, Molly J and Herrmann, Bj{\"{o}}rn and Grahn, Jessica A},
doi = {10.1371/journal.pone.0172454},
file = {:Users/gmac/mendeley/Henry, Herrmann, Grahn/Henry, Herrmann, Grahn - 2017 - What can we learn about beat perception by comparing brain signals and stimulus envelopes.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
number = {2},
pages = {1--17},
title = {{What can we learn about beat perception by comparing brain signals and stimulus envelopes?}},
volume = {12},
year = {2017}
}
@article{Bhattacharya2001a,
author = {Bhattacharya, Joydeep and Petsche, Hellmuth and Pereda, Ernesto},
file = {:Users/gmac/mendeley/Bhattacharya, Petsche, Pereda/Bhattacharya, Petsche, Pereda - 2001 - Long-Range Synchrony in the Band Role in Music Perception.pdf:pdf},
journal = {The Journal of Neuroscience},
month = {aug},
number = {16},
pages = {6329--6337},
title = {{Long-Range Synchrony in the ? Band: Role in Music Perception}},
url = {papers3://publication/uuid/821C7375-BE61-443E-B37F-D5C3B304DDE0},
volume = {21},
year = {2001}
}
@article{Hevner1935,
author = {Hevner, Kate},
file = {:Users/gmac/mendeley/Hevner/Hevner - 1935 - The Affective Character of the Major and Minor Modes in Music.pdf:pdf},
journal = {The American Journal of Psychology},
month = {jan},
pages = {103--118},
title = {{The Affective Character of the Major and Minor Modes in Music}},
url = {http://www.jstor.org.ezproxy.lib.ryerson.ca/stable/10.2307/1416710?origin=api& papers3://publication/uuid/F1993831-832F-4AB0-B84B-D24B50B61AA6},
volume = {47},
year = {1935}
}
@article{Vempala2013,
abstract = {There are two positions in the classic debate regarding musical emotion: the cognitivist position and the emotivist position. According to the cognitivist position, music expresses emotion but does not induce it in listeners. So, listeners may recognize emotion in music without feeling it, unlike real, everyday emotion. According to the emotivist position, listeners not only recognize emotion but also feel it. This is supported by their physiological responses during music listening, which are similar to responses occurring with real emotion. When listeners provide emotion appraisals, if the cognitivist position were true, then these appraisals might be based on audio features in the music. However, if the emotivist position were true, then appraisals would be based on the emotion experienced by listeners as opposed to what they perceived in the audio features. We propose a hypothesis combining both positions according to which, listeners make emotion appraisals based on a combination of what they perceive in the music as well as what they experience during the listening process. In this paper, we explore all three positions using connectionist prediction models, specifically four different neural networks: (a) using only audio features as input, (b) using only physiological features as input, (c) using both audio and physiological features as input, and (d) using a committee machine that combines contributions from an audio network and a physiology network. We examine the performance of these networks and discuss their implications as possible cognitive models of emotion appraisal within listeners.},
author = {Vempala, Naresh N and Russo, Frank A},
file = {:Users/gmac/mendeley/Vempala, Russo/Vempala, Russo - 2013 - Exploring Cognitivist and Emotivist Positions of Musical Emotion Using Neural Network Models.pdf:pdf},
journal = {Proceedings of the International Conference on Cognitive Modeling},
keywords = {connectionist models,musical emotion,neural},
pages = {257--262},
title = {{Exploring Cognitivist and Emotivist Positions of Musical Emotion Using Neural Network Models}},
year = {2013}
}
@article{Ryan2010,
author = {Ryan, Melissa and Murray, Janice and Ruffman, Ted},
doi = {10.1080/03610730903418372},
file = {:Users/gmac/mendeley/Ryan, Murray, Ruffman/Ryan, Murray, Ruffman - 2010 - Aging and the perception of emotion processing vocal expressions alone and with faces.pdf:pdf},
journal = {Experimental Aging Research},
pages = {1--22},
title = {{Aging and the perception of emotion: processing vocal expressions alone and with faces}},
volume = {36},
year = {2010}
}
@article{Barrett2011,
author = {Barrett, L F and Mesquita, B and Gendron, M},
file = {:Users/gmac/mendeley/Barrett, Mesquita, Gendron/Barrett, Mesquita, Gendron - 2011 - Context in Emotion Perception.pdf:pdf},
journal = {Current Directions in Psychological Science},
month = {oct},
number = {5},
pages = {286--290},
title = {{Context in Emotion Perception}},
url = {http://cdp.sagepub.com/lookup/doi/10.1177/0963721411422522 papers3://publication/doi/10.1177/0963721411422522},
volume = {20},
year = {2011}
}
@article{Vos1995,
author = {Vos, Piet G and Mates, Jiri and van Kruysbergen, Noud W},
file = {:Users/gmac/mendeley/Vos, Mates, van Kruysbergen/Vos, Mates, van Kruysbergen - 1995 - The Perceptual Centre of a Stimulus as the Cue for Synchronization to a Metronome Evidence from Asy.pdf:pdf},
journal = {The Quarterly Journal of Experimental Psychology},
month = {jan},
number = {4},
pages = {1024--1040},
title = {{The Perceptual Centre of a Stimulus as the Cue for Synchronization to a Metronome: Evidence from Asynchronies}},
volume = {48A},
year = {1995}
}
@article{Watkins2003,
author = {Watkins, K E and Strafella, A P and Paus, T},
file = {:Users/gmac/mendeley/Watkins, Strafella, Paus/Watkins, Strafella, Paus - 2003 - Seeing and hearing speech excites the motor system involved in speech production.pdf:pdf},
journal = {Neuropsychologia},
month = {jan},
number = {8},
pages = {989--994},
publisher = {Elsevier Ltd},
title = {{Seeing and hearing speech excites the motor system involved in speech production}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0028393202003160},
volume = {41},
year = {2003}
}
@article{Delorme2007,
author = {Delorme, Arnaud and Sejnowski, Terrence and Makeig, Scott},
file = {:Users/gmac/mendeley/Delorme, Sejnowski, Makeig/Delorme, Sejnowski, Makeig - 2007 - Enhanced detection of artifacts in EEG data using higher-order statistics and independent component.pdf:pdf},
journal = {NeuroImage},
month = {feb},
number = {4},
pages = {1443--1449},
title = {{Enhanced detection of artifacts in EEG data using higher-order statistics and independent component analysis}},
volume = {34},
year = {2007}
}
@article{Repp2005,
abstract = {Abstract Sensorimotor synchronization (SMS), the rhythmic coordination of perception and action, occurs in many contexts, but most conspicuously in music performance and dance. In the laboratory, it is most often studied in the form of finger tapping to a sequence of ... 
},
author = {Repp, Bruno H},
file = {:Users/gmac/mendeley/Repp/Repp - 2005 - Sensorimotor synchronization A review of the tapping literature.pdf:pdf},
journal = {Psychonomic Bulletin & Review},
keywords = {tapping},
month = {dec},
number = {6},
pages = {969--992},
title = {{Sensorimotor synchronization: A review of the tapping literature}},
url = {http://www.springerlink.com/index/10.3758/BF03206433 papers3://publication/doi/10.3758/BF03206433},
volume = {12},
year = {2005}
}
@book{Pickren2010,
address = {Hoboken, NJ},
author = {Pickren, Wade E and Rutherford, Alexandra},
file = {:Users/gmac/mendeley/Pickren, Rutherford/Pickren, Rutherford - 2010 - No Title.pdf:pdf},
month = {jan},
pages = {292--317},
publisher = {Wiley},
title = {{No Title}},
url = {http://books1.scholarsportal.info/viewdoc.html?id=/ebooks/ebooks2/pda/2011-12-01/1/15287.9780470585993&page=292},
year = {2010}
}
@inproceedings{Musacchia2015,
address = {San Francisco, CA},
author = {Musacchia, Gabriella and Ortiz-Mantilla, Silvia and Roesler, Cynthia and Byrne, Julie and Benasich, April},
booktitle = {nd Annual Meeting of the Cognitive Neuroscience Society},
month = {jan},
title = {{Speech encoding in quiet and background noise differs between infants and young adults: A complex auditory brainstem response (cABR) investigation}},
url = {papers3://publication/uuid/22F04F06-E50A-4772-93FD-30B20F7EA307},
year = {2015}
}
@article{Herff2014,
abstract = {When interacting with technical systems, users experience mental workload.},
author = {Herff, Christian},
file = {:Users/gmac/mendeley/Herff/Herff - 2014 - Mental workload during n-back task—quantified in the prefrontal cortex using fNIRS.pdf:pdf},
month = {jan},
pages = {1--9},
title = {{Mental workload during n-back task—quantified in the prefrontal cortex using fNIRS}},
url = {http://journal.frontiersin.org/Journal/10.3389/fnhum.2013.00935/full papers3://publication/doi/10.3389/fnhum.2013.00935/abstract},
year = {2014}
}
@article{BehmerJr.2011,
author = {{Behmer Jr.}, Lawrence Paul and Jantzen, Kelly J},
file = {:Users/gmac/mendeley/Behmer Jr., Jantzen/Behmer Jr., Jantzen - 2011 - Reading sheet music facilitates sensorimotor mu-desynchronization in musicians.pdf:pdf},
journal = {Clinical Neurophysiology},
keywords = {MNS,mu},
month = {jul},
number = {7},
pages = {1342--1347},
title = {{Reading sheet music facilitates sensorimotor mu-desynchronization in musicians}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1388245710008679 papers3://publication/doi/10.1016/j.clinph.2010.12.035},
volume = {122},
year = {2011}
}
@article{Dewey1896,
author = {Dewey, John},
file = {:Users/gmac/mendeley/Dewey/Dewey - 1896 - The Reflex Arc Concept in Psychology.pdf:pdf},
journal = {The Psychological Review},
month = {jul},
pages = {357--370},
title = {{The Reflex Arc Concept in Psychology}},
url = {papers3://publication/uuid/4D38ACEC-9557-41B4-B9B1-CD94222D82E0},
volume = {3},
year = {1896}
}
@article{Jensen2007,
author = {Jensen, Ole and Colgin, Laura L},
file = {:Users/gmac/mendeley/Jensen, Colgin/Jensen, Colgin - 2007 - Cross-frequency coupling between neuronal oscillations.pdf:pdf},
journal = {Trends in Cognitive Sciences},
month = {jul},
number = {7},
pages = {267--269},
publisher = {Elsevier Ltd},
title = {{Cross-frequency coupling between neuronal oscillations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661307001271 papers3://publication/doi/10.1016/j.tics.2007.05.003},
volume = {11},
year = {2007}
}
@incollection{Vuust2014a,
abstract = {Musical rhythm, consisting of apparently abstract intervals of accented temporal events, has the remarkable ability to move our minds and bodies. Why do certain rhythmsmake us want to tap our feet, bop our heads or even get up and dance? And how does the brain process rhythmically complex rhythms during our experiences of music? In this chapter,we describe some common forms of rhythmic complexity inmusic and propose that the theory of predictive coding can explain how rhythm and rhythmic complexity are processed in the brain.Wealso consider howthis theorymay revealwhy we feel so compelled by rhythmic tension in music. First, musical-theoretical and neuroscientific frameworks of rhythm are presented, in which rhythm perception is conceptualized as an interaction between what is heard (‘rhythm') and the brain's anticipatory structuring of music (‘the meter'). Second, three different examples of tension between rhythm and meter in music are described: syncopation, polyrhythm and groove. Third, we pres- ent the theory of predictive coding of music, which posits a hierarchical organization of brain responses reflecting fundamental, survival-related mechanisms associated with predicting future events. According to this theory, perception and learning is manifested through the brain's Bayesian minimization of the error between the input to the brain and the brain's prior expectations. Fourth, empirical studies of neural and behavioral effects of syncopation, polyrhythm and groove will be reported, and we propose how these studies can be seen as special cases of the predictive coding theory. Finally, we argue thatmusical rhythmexploits the brain's general principles of anticipation and propose that pleasure from musical rhythm may be a result of such anticipatory mechanisms.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Vuust, Peter and Gebauer, Line K and Witek, Maria A G},
booktitle = {Neurobiology of Interval Timing},
doi = {10.1007/978-1-4939-1782-2},
eprint = {arXiv:1011.1669v3},
file = {:Users/gmac/mendeley/Vuust, Gebauer, Witek/Vuust, Gebauer, Witek - 2014 - Neural Underpinnings of Music The Polyrhythmic Brain.pdf:pdf},
isbn = {978-1-4939-1781-5},
issn = {0065-2598},
keywords = {Music,Pleasure,Prediction,Rhythmic complexity},
pages = {339--356},
pmid = {25358718},
title = {{Neural Underpinnings of Music: The Polyrhythmic Brain}},
year = {2014}
}
@article{Davis2007,
author = {Davis, A and Smith, P and Ferguson, M and Stephens, D and Gianopoulos, I},
doi = {10.3310/hta11420},
file = {:Users/gmac/mendeley/Davis et al/Davis et al. - 2007 - Acceptability, benefits and costs of early screening for hearing disability study tests and models.pdf:pdf},
isbn = {1366-5278},
issn = {1366-5278},
journal = {Health Technology Assessment},
number = {42},
pmid = {17927921},
title = {{Acceptability, benefits and costs of early screening for hearing disability study tests and models}},
volume = {11},
year = {2007}
}
@article{Kallinen2006,
abstract = {The goal of the present study was to examine the relationships and differences between emotion perceived (i.e., the emotional quality expressed by music) and emotion felt (i.e., the individual's emotional response to music). Thirty-two participants listened to 12 music pieces differing in terms of a priori basic emotional quality, and rated the music from two points of view (i.e., emotion felt and emotion perceived) using 16 adjectives from dimensional models of emotion. As expected, in general, music seemed to arouse emotions similar to the emotional quality perceived in music. However, the affect ratings were significantly moderated by the point of view from which the emotions were assessed. Felt emotions were stronger than perceived emotions in connection with pleasure, but weaker in connection with arousal, positive activation, and negative activation. As also expected, negative perceived quality in music elicited less or an opposite felt emotion. That is, fearful music was perceived as negative but felt as positive.},
author = {Kallinen, K. and Ravaja, N.},
doi = {10.1177/102986490601000203},
file = {:Users/gmac/mendeley/Kallinen, Ravaja/Kallinen, Ravaja - 2006 - Emotion perceived and emotion felt Same and different.pdf:pdf},
isbn = {1029-8649},
issn = {1029-8649},
journal = {Musicae Scientiae},
number = {2},
pages = {191--213},
title = {{Emotion perceived and emotion felt: Same and different}},
volume = {10},
year = {2006}
}
@article{Brattico2013,
author = {Brattico, Elvira and Tupala, Tiina and Glerean, Enrico and Tervaniemi, Mari},
file = {:Users/gmac/mendeley/Brattico et al/Brattico et al. - 2013 - Modulated neural processing of Western harmony in folk musicians.pdf:pdf},
journal = {Psychophysiology},
month = {may},
number = {7},
pages = {653--663},
title = {{Modulated neural processing of Western harmony in folk musicians}},
url = {http://doi.wiley.com/10.1111/psyp.12049 papers3://publication/doi/10.1111/psyp.12049},
volume = {50},
year = {2013}
}
@incollection{Johnstone2000,
author = {Johnstone, Tom},
booktitle = {The Handbook of Emotion},
file = {:Users/gmac/mendeley/Johnstone/Johnstone - 2000 - Vocal Communication of Emotion BT - The Handbook of Emotion.pdf:pdf},
month = {jan},
pages = {220--235},
title = {{Vocal Communication of Emotion BT  - The Handbook of Emotion}},
url = {papers3://publication/uuid/AF91BF89-06A2-4FCE-9DDA-AC7DC11ED885},
year = {2000}
}
@article{Honing2012,
author = {Honing, Henkjan and Ploeger, Annemie},
file = {:Users/gmac/mendeley/Honing, Ploeger/Honing, Ploeger - 2012 - Cognition and the Evolution of Music Pitfalls and Prospects.pdf:pdf},
journal = {Topics in Cognitive Science},
month = {jul},
number = {4},
pages = {513--524},
title = {{Cognition and the Evolution of Music: Pitfalls and Prospects}},
url = {http://doi.wiley.com/10.1111/j.1756-8765.2012.01210.x papers3://publication/doi/10.1111/j.1756-8765.2012.01210.x},
volume = {4},
year = {2012}
}
@article{Russell1994,
abstract = {Emotions are universally recognized from facial expressions--or so it has been claimed. To support that claim, research has been carried out in various modern cultures and in cultures relatively isolated from Western influence. A review of the methods used in that research raises questions of its ecological, convergent, and internal validity. Forced-choice response format, within-subject design, preselected photographs of posed facial expressions, and other features of method are each problematic. When they are altered, less supportive or nonsupportive results occur. When they are combined, these method factors may help to shape the results. Facial expressions and emotion labels are probably associated, but the association may vary with culture and is loose enough to be consistent with various alternative accounts, 8 of which are discussed.},
address = {Department of Psychology, University of British Columbia, Vancouver, Canada V6T 1Z4.},
author = {Russell, James A},
file = {:Users/gmac/mendeley/Russell/Russell - 1994 - Is there universal recognition of emotion from facial expression A review of the cross-cultural studies.pdf:pdf},
journal = {Psychological Bulletin},
month = {jan},
number = {1},
pages = {102--141},
title = {{Is there universal recognition of emotion from facial expression? A review of the cross-cultural studies.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=8202574&retmode=ref&cmd=prlinks papers3://publication/uuid/81172732-F4F6-4E4A-80D8-E2B7109C888B},
volume = {115},
year = {1994}
}
@article{WoodruffCarr2014,
abstract = {Temporal cues are important for discerning word boundaries and syllable segments in speech; their perception facilitates language acquisition and development. Beat synchronization and neural encoding of speech reflect precision in processing temporal cues and have been linked to reading skills. In poor readers, diminished neural precision may contribute to rhythmic and phonological deficits. Here we establish links between beat synchronization and speech processing in children who have not yet begun to read: preschoolers who can entrain to an external beat have more faithful neural encoding of temporal modulations in speech and score higher on tests of early language skills. In summary, we propose precise neural encoding of temporal modulations as a key mechanism underlying reading acquisition. Because beat synchronization abilities emerge at an early age, these findings may inform strategies for early detection of and intervention for language-based learning disabilities.},
author = {{Woodruff Carr}, Kali and White-Schwoch, Travis and Tierney, Adam T and Strait, Dana L and Kraus, Nina},
doi = {10.1073/pnas.1406219111},
file = {:Users/gmac/mendeley/Woodruff Carr et al/Woodruff Carr et al. - 2014 - Beat synchronization predicts neural speech encoding and reading readiness in preschoolers.pdf:pdf},
isbn = {0027-8424},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Analysis of Variance,Auditory Perception,Auditory Perception: physiology,Child,Cues,Electrodes,Electrophysiology,Electrophysiology: instrumentation,Electrophysiology: methods,Female,Humans,Language Development,Learning,Learning: physiology,Male,Neural Pathways,Neural Pathways: physiology,Phonetics,Preschool,Reading,Speech,Speech Perception,Speech Perception: physiology,Speech: physiology},
number = {40},
pages = {14559--64},
pmid = {25246562},
title = {{Beat synchronization predicts neural speech encoding and reading readiness in preschoolers}},
url = {http://www.pnas.org/content/111/40/14559.short},
volume = {111},
year = {2014}
}
@article{Lang1998,
author = {Lang, Peter J and Bradley, Margaret M and Cuthbert, Bruce N.},
file = {:Users/gmac/mendeley/Lang, Bradley, Cuthbert/Lang, Bradley, Cuthbert - 1998 - Emotion and Motivation Measuring Affective Perception.pdf:pdf},
journal = {Journal of Clinical Neurophysiology},
number = {5},
pages = {397--408},
title = {{Emotion and Motivation: Measuring Affective Perception}},
volume = {15},
year = {1998}
}
@article{Juslin2000,
author = {Juslin, Patrik N},
file = {:Users/gmac/mendeley/Juslin/Juslin - 2000 - Cue utilization in communication of emotion in music performance Relating performance to perception.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
month = {jan},
number = {6},
pages = {1797--1813},
publisher = {American Psychological Association},
title = {{Cue utilization in communication of emotion in music performance: Relating performance to perception.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-1523.26.6.1797 papers3://publication/doi/10.1037//0096-1523.26.6.1797},
volume = {26},
year = {2000}
}
@article{Goebl2008,
author = {Goebl, Werner and Palmer, Caroline},
file = {:Users/gmac/mendeley/Goebl, Palmer/Goebl, Palmer - 2008 - Tactile feedback and timing accuracy in piano performance.pdf:pdf},
journal = {Experimental Brain Research},
month = {jan},
number = {3},
pages = {471--479},
title = {{Tactile feedback and timing accuracy in piano performance}},
url = {http://link.springer.com/10.1007/s00221-007-1252-1 papers3://publication/doi/10.1007/s00221-007-1252-1},
volume = {186},
year = {2008}
}
@article{Tognoli2007,
author = {Tognoli, Emmanuelle and Lagarde, Julien and DeGuzman, Gonzalo C and Kelso, J A Scott},
file = {:Users/gmac/mendeley/Tognoli et al/Tognoli et al. - 2007 - The phi complex as a neuromarker of human social coordination.pdf:pdf},
journal = {Proceedings of the National Acadamy of Sciences},
month = {may},
pages = {8190--8195},
title = {{The phi complex as a neuromarker of human social coordination}},
url = {papers3://publication/uuid/BF442748-8C6B-4A3C-A10C-E4A22EE0BEDE},
volume = {104},
year = {2007}
}
@article{Hornsby2013,
author = {Hornsby, Benjamin W Y},
file = {:Users/gmac/mendeley/Hornsby/Hornsby - 2013 - The Effects of Hearing Aid Use on Listening Effort and Mental Fatigue Associated With Sustained Speech Processing Deman.pdf:pdf},
journal = {Ear & Hearing},
month = {aug},
pages = {523--534},
title = {{The Effects of Hearing Aid Use on Listening Effort and Mental Fatigue Associated With Sustained Speech Processing Demands}},
volume = {34},
year = {2013}
}
@article{Rothenberg1977,
annote = {- tested vibration on the volar forearm (because interested in development of a speech delivery system)
- used sine waves, pulses, and "warble" (amplitude modulated) tones
- better discrimination with pulses than pure tones, low freq than high freq; "warble" increased discrimination at high freq},
author = {Rothenberg, Martin and Verrillo, Ronald T and Zahorian, Stephen A and Brachman, Michael L and Bolanowski, S J Jr},
file = {:Users/gmac/mendeley/Rothenberg et al/Rothenberg et al. - 1977 - Vibrotactile frequency for encoding a speech parameter.pdf:pdf},
journal = {Journal of Economic Psychology},
keywords = {haptics},
month = {oct},
number = {4},
pages = {1003--1012},
title = {{Vibrotactile frequency for encoding a speech parameter}},
url = {http://scitation.aip.org/getpdf/servlet/GetPDFServlet?filetype=pdf&id=JASMAN000062000004001003000001&idtype=cvips&doi=10.1121/1.381610&prog=normal},
volume = {62},
year = {1977}
}
@article{Thaut1996,
author = {Thaut, Michael H and McIntosh, G C and Rice, R R and Miller, R A and Rathbun, J and Brault, J M},
file = {:Users/gmac/mendeley/Thaut et al/Thaut et al. - 1996 - Rhythmic Auditory Stimulation in Gait Training for Parkinson's Disease Patients.pdf:pdf},
journal = {Movement Disorders},
month = {jan},
number = {2},
pages = {193--200},
title = {{Rhythmic Auditory Stimulation in Gait Training for Parkinson's Disease Patients}},
url = {papers3://publication/uuid/86E6C244-6544-4FA8-838A-A2B7EAC1E773},
volume = {11},
year = {1996}
}
@book{Cacioppo2007,
address = {Cambridge},
author = {Cacioppo, John T and Tassinary, Louis G and Berntson, Gary},
file = {:Users/gmac/mendeley/Cacioppo, Tassinary, Berntson/Cacioppo, Tassinary, Berntson - 2007 - Handbook of Psychophysiology.pdf:pdf},
isbn = {0-521-62634-X},
publisher = {Cambridge University Press},
title = {{Handbook of Psychophysiology}},
year = {2007}
}
@article{Russell1980,
abstract = {Abstract 1. Factor-analytic evidence has led most psychologists to describe affect as a set of dimensions, such as displeasure, distress, depression, excitement, and so on, with each dimension varying independently of the others. However, there is other evidence that ...},
author = {Russell, James A},
file = {:Users/gmac/mendeley/Russell/Russell - 1980 - A circumplex model of affect.pdf:pdf},
journal = {Journal of Personality and Social Psychology},
month = {jan},
number = {6},
pages = {1161--1178},
title = {{A circumplex model of affect.}},
volume = {39},
year = {1980}
}
@article{Arnal2015,
abstract = {The ability to generate temporal predictions is fundamental for adaptive behavior. Precise timing at the time-scale of seconds is critical, for instance to predict trajectories or to select relevant information. What mechanisms form the basis for such accurate timing? Recent evidence suggests that (1) temporal predictions adjust sensory selection by controlling neural oscillations in time and (2) the motor system plays an active role in inferring "when" events will happen. We hypothesized that oscillations in the delta and beta bands are instrumental in predicting the occurrence of auditory targets. Participants listened to brief rhythmic tone sequences and detected target delays while undergoing magnetoencephalography recording. Prior to target occurrence, we found that coupled delta (1-3 Hz) and beta (18-22 Hz) oscillations temporally align with upcoming targets and bias decisions towards correct responses, suggesting that delta-beta coupled oscillations underpin prediction accuracy. Subsequent to target occurrence, subjects update their decisions using the magnitude of the alpha-band (10-14 Hz) response as internal evidence of target timing. These data support a model in which the orchestration of oscillatory dynamics between sensory and motor systems is exploited to accurately select sensory information in time.},
author = {Arnal, Luc H and Doelling, Keith B and Poeppel, David},
doi = {10.1093/cercor/bhu103},
file = {:Users/gmac/mendeley/Arnal, Doelling, Poeppel/Arnal, Doelling, Poeppel - 2015 - Delta-beta coupled oscillations underlie temporal prediction accuracy.pdf:pdf},
isbn = {1460-2199 (Electronic)\r1047-3211 (Linking)},
issn = {14602199},
journal = {Cerebral Cortex},
keywords = {Auditory,Motor,Neuronal oscillations,Sensorimotor,Timing},
number = {9},
pages = {3077--3085},
pmid = {24846147},
title = {{Delta-beta coupled oscillations underlie temporal prediction accuracy}},
volume = {25},
year = {2015}
}
@inproceedings{Mullen2013,
author = {Mullen, Tim and Kothe, Christian and Chi, Yu Mike and Ojeda, Alejandro and Kerth, Trevor and Makeig, Scott and Cauwenberghs, Gert and Jung, Tzyy-Ping},
booktitle = {IEEE Enginering in Medicine and Biology Society},
doi = {10.1109/EMBC.2013.6609968.Real-Time},
file = {:Users/gmac/mendeley/Mullen et al/Mullen et al. - 2013 - Real-Time Modeling and 3D Visualization of Source Dynamics and Connectivity Using Wearable EEG.pdf:pdf},
pages = {2184--2187},
title = {{Real-Time Modeling and 3D Visualization of Source Dynamics and Connectivity Using Wearable EEG}},
year = {2013}
}
@article{Gaser2003,
author = {Gaser, Christian and Schlaug, Gottfried},
file = {:Users/gmac/mendeley/Gaser, Schlaug/Gaser, Schlaug - 2003 - Brain Structures Differ between Musicians and Non-Musicians.pdf:pdf},
journal = {The Journal of Neuroscience},
month = {oct},
number = {27},
pages = {9240--9245},
title = {{Brain Structures Differ between Musicians and Non-Musicians}},
url = {papers3://publication/uuid/B1D5B144-879A-44D4-B1E5-5F1EB186895B},
volume = {23},
year = {2003}
}
@article{Teki2011,
annote = {- patients with spinocerebellar ataxia type 6 and normal subjects with trans- cranial magnetic stimulation (TMS) applied over the medial cer- ebellum were specifically impaired on absolute timing tasks such as comparing the absolute duration of single intervals and not on relative timing tasks based on rhythmic sequences with a regular beat (Grube et al., 2010a,b)

Methods:
- Although it is sometimes possible to perceive a beat even in jittered sequences, the above stimulus parameters were carefully tested in pilot experiments to eliminate any beat-based percept in the irregular sequences.
- block of irregular first, then block of regular},
author = {Teki, S and Grube, Manon and Kumar, S and Griffiths, Timothy D},
file = {:Users/gmac/mendeley/Teki et al/Teki et al. - 2011 - Distinct Neural Substrates of Duration-Based and Beat-Based Auditory Timing.pdf:pdf},
journal = {Journal of Neuroscience},
month = {mar},
number = {10},
pages = {3805--3812},
title = {{Distinct Neural Substrates of Duration-Based and Beat-Based Auditory Timing}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5561-10.2011 papers3://publication/doi/10.1523/JNEUROSCI.5561-10.2011},
volume = {31},
year = {2011}
}
@article{Abelson1997,
author = {Abelson, R P},
file = {:Users/gmac/mendeley/Abelson/Abelson - 1997 - On the Surprising Longevity of Flogged Horses Why There Is a Case for the Significance Test.pdf:pdf},
journal = {Psychological Science},
keywords = {stats},
month = {jan},
number = {1},
pages = {12--15},
title = {{On the Surprising Longevity of Flogged Horses: Why There Is a Case for the Significance Test}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/j.1467-9280.1997.tb00536.x papers3://publication/doi/10.1111/j.1467-9280.1997.tb00536.x},
volume = {8},
year = {1997}
}
@article{Zatorre2002,
author = {Zatorre, Robert J and Belin, Pascal and Penhune, Virginia B},
file = {:Users/gmac/mendeley/Zatorre, Belin, Penhune/Zatorre, Belin, Penhune - 2002 - Structure and function of auditory cortex music and speech.pdf:pdf},
journal = {Trends in Cognitive Sciences},
month = {jan},
pages = {37--46},
publisher = {Elsevier Ltd},
title = {{Structure and function of auditory cortex: music and speech}},
url = {papers3://publication/uuid/DAD19ED0-126E-4160-90B3-6DF49674D6B9},
volume = {6},
year = {2002}
}
@article{Skrabek2008,
author = {Skrabek, Ryan Quinlan and Galimova, Lena and Ethans, Karen and Perry, Daryl},
file = {:Users/gmac/mendeley/Skrabek et al/Skrabek et al. - 2008 - Nabilone for the Treatment of Pain in Fibromyalgia.pdf:pdf},
journal = {The Journal of Pain},
month = {jan},
pages = {164--173},
title = {{Nabilone for the Treatment of Pain in Fibromyalgia}},
url = {papers3://publication/doi/10.1016/j.jpain.2007.09.002},
volume = {9},
year = {2008}
}
@article{Kirchner2008,
author = {Kirchner, Joann Marie and Bloom, Arvid J and Skutnick-Henley, Paula},
file = {:Users/gmac/mendeley/Kirchner, Bloom, Skutnick-Henley/Kirchner, Bloom, Skutnick-Henley - 2008 - The Relationship Between Performance Anxiety and Flow.pdf:pdf},
journal = {Medical Problems of Performing Artists},
month = {jan},
pages = {59--65},
title = {{The Relationship Between Performance Anxiety and Flow}},
url = {papers3://publication/uuid/1080AAA5-C8A5-4F79-86EC-227BA5D5E0A2},
year = {2008}
}
@article{Olsen1998,
author = {Olsen, Wayne O},
file = {:Users/gmac/mendeley/Olsen/Olsen - 1998 - Average Speech Levels and Spectra in Various SpeakingListening Conditions A Summary of the Pearson, Bennett, & Fidell (19.pdf:pdf},
journal = {American Journal of Audiology},
month = {oct},
pages = {21--25},
title = {{Average Speech Levels and Spectra in Various Speaking/Listening Conditions: A Summary of the Pearson, Bennett, & Fidell (1977) Report}},
url = {papers3://publication/uuid/93B3BDC7-9038-4DDD-91FD-2175CF075033},
volume = {7},
year = {1998}
}
@article{Krishnan2005,
author = {Krishnan, Ananthanarayan and Xu, Yisheng and Gandour, Jackson and Cariani, Peter},
file = {:Users/gmac/mendeley/Krishnan et al/Krishnan et al. - 2005 - Encoding of pitch in the human brainstem is sensitive to language experience.pdf:pdf},
journal = {Cognitive Brain Research},
month = {sep},
number = {1},
pages = {161--168},
title = {{Encoding of pitch in the human brainstem is sensitive to language experience}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0926641005001230 papers3://publication/doi/10.1016/j.cogbrainres.2005.05.004},
volume = {25},
year = {2005}
}
@article{Lindquist2012,
author = {Lindquist, Kristen A and Wager, Tor D and Kober, Hedy and Bliss-Moreau, Eliza and Barrett, Lisa Feldman},
file = {:Users/gmac/mendeley/Lindquist et al/Lindquist et al. - 2012 - The brain basis of emotion A meta-analytic review.pdf:pdf},
journal = {Behavioral and Brain Sciences},
month = {may},
number = {03},
pages = {121--143},
title = {{The brain basis of emotion: A meta-analytic review}},
url = {http://www.journals.cambridge.org/abstract_S0140525X11000446},
volume = {35},
year = {2012}
}
@article{Baldwin1896a,
author = {Baldwin, J Mark},
file = {:Users/gmac/mendeley/Baldwin/Baldwin - 1896 - Consciousness and Evolution.pdf:pdf},
journal = {Psychological Review},
month = {may},
number = {3},
pages = {300--309},
title = {{Consciousness and Evolution}},
url = {papers3://publication/uuid/6F62F42E-0253-4D19-A105-C694BF2CCE79},
volume = {3},
year = {1896}
}
@article{McGugin2012,
author = {McGugin, Rankin Williams and Gatenby, J Christopher and Gore, John C and Gauthier, Isabel},
file = {:Users/gmac/mendeley/McGugin et al/McGugin et al. - 2012 - High-resolution imaging of expertise reveals reliableobject selectivity in the fusiform face area relatedto perc.pdf:pdf},
journal = {Proceedings of the National Acadamy of Sciences},
month = {oct},
pages = {17063--17068},
title = {{High-resolution imaging of expertise reveals reliableobject selectivity in the fusiform face area relatedto perceptual performance}},
url = {papers3://publication/doi/10.1073/pnas.1116333109/-/DCSupplemental},
volume = {109},
year = {2012}
}
@article{Leow2015,
abstract = {Rhythmic auditory stimulation (RAS) is a gait rehabilitation method in which patients synchronize footsteps to a metronome or musical beats. Although RAS with music can ameliorate gait abnormalities, outcomes vary, possibly because music properties, such as groove or familiarity, differ across interventions. To optimize future interventions, we assessed how initially familiar and unfamiliar low-groove and high-groove music affected synchronization accuracy and gait in healthy individuals. We also experimentally increased music familiarity using repeated exposure to initially unfamiliar songs. Overall, familiar music elicited faster stride velocity and less variable strides, as well as better synchronization performance (matching of step tempo to beat tempo). High-groove music, as reported previously, led to faster stride velocity than low-groove music. We propose two mechanisms for familiarity's effects. First, familiarity with the beat structure reduces cognitive demands of synchronizing, leading to better synchronization performance and faster, less variable gait. Second, familiarity might have elicited faster gait by increasing enjoyment of the music, as enjoyment was higher after repeated exposure to initially low-enjoyment songs. Future studies are necessary to dissociate the contribution of these mechanisms to the observed RAS effects of familiar music on gait.},
author = {Leow, Li-Ann and Rinchon, Cricia and Grahn, Jessica A},
doi = {10.1111/nyas.12658},
file = {:Users/gmac/mendeley/Leow, Rinchon, Grahn/Leow, Rinchon, Grahn - 2015 - Familiarity with music increases walking speed in rhythmic auditory cuing.pdf:pdf},
issn = {17496632},
journal = {Annals of the New York Academy of Sciences},
number = {1},
pages = {53--61},
pmid = {25773617},
title = {{Familiarity with music increases walking speed in rhythmic auditory cuing}},
volume = {1337},
year = {2015}
}
@article{Juslin2004,
author = {Juslin, Patrik N and Laukka, Petri},
file = {:Users/gmac/mendeley/Juslin, Laukka/Juslin, Laukka - 2004 - Expression, Perception, and Induction of Musical Emotions A Review and a Questionnaire Study of Everyday Listeni.pdf:pdf},
journal = {Journal of New Music Research},
month = {sep},
number = {3},
pages = {217--238},
title = {{Expression, Perception, and Induction of Musical Emotions: A Review and a Questionnaire Study of Everyday Listening}},
url = {http://www.tandfonline.com/doi/abs/10.1080/0929821042000317813 papers3://publication/doi/10.1080/0929821042000317813},
volume = {33},
year = {2004}
}
@article{Nair2002,
abstract = {We aimed to identify brain areas involved in responding to affect communicated by expressive piano performance. Our subjects listened to two versions of Chopin's Etude in E major, Opus 10, No. 3. The first version was an expressive performance, recorded by a highly trained musician on a computer-monitored piano. Our control was a computer- generated, mechanical performance of the same composition. Data analysis revealed differential brain activation in the two listening conditions. The expressive performance elicited greater activation in anterior cingulate, right temporal pole, right inferior frontal gyri, inferior parietal lobe and superior temporal gyri, areas that have been associated with emotion, attention and speech perception. The mechanical performance elicited greater activation in cerebellum, parahippocampal gyrus, supplementary motor area and dorsolateral prefrontal cortex, areas primarily involved in motor and sequencing tasks. Our results confirm that expressive music performance communicates affect beyond the melody, harmony, tonality, and rhythm of the notated composition. Our observations also suggest that the perception of emotion in music shares neural resources with the perception of emotion in speech, and that these pathways may be different from those recruited during other types of emotional experienc},
author = {Nair, Dg and Large, Edward W},
file = {:Users/gmac/mendeley/Nair, Large/Nair, Large - 2002 - Perceiving emotion in expressive piano performance A functional MRI study.pdf:pdf},
journal = {Proceedings of the 7th International Conference on Music Perception and Cognition},
pages = {627--630},
title = {{Perceiving emotion in expressive piano performance: A functional MRI study}},
url = {http://www.ccs.fau.edu/$\sim$large/Publications/NairLarge2002.pdf},
year = {2002}
}
@article{Hursch1964,
author = {Hursch, C J and Hammond, K R and Hursch, J L},
file = {:Users/gmac/mendeley/Hursch, Hammond, Hursch/Hursch, Hammond, Hursch - 1964 - Some Methodological Considerations in Multiple-Cue Probability Studies.pdf:pdf},
journal = {Psychological Review},
month = {jan},
pages = {42--60},
title = {{Some Methodological Considerations in Multiple-Cue Probability Studies}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=14105718&retmode=ref&cmd=prlinks papers3://publication/uuid/75AE34DA-5B9C-41F1-8AED-D3AD9C0DBF68},
volume = {71},
year = {1964}
}
@article{Mulrow1992,
abstract = {This study was designed to evaluate long-term benefits of hearing aids in elderly individuals with hearing loss. A primary care cohort of 192 elderly, hearing-impaired veterans (mean age 72 +/- 6, 97% White, 94% retired) were assessed at baseline and at 4, 8, and 12 months after hearing aid fitting. Drop-out rates at 4, 8, and 12 months were 5%, 13%, and 16%, respectively. Outcome assessments included several quality-of-life scales: Hearing Handicap Inventory in the Elderly (HHIE), Quantified Denver Scale of Communication Function (QDS), Geriatric Depression Scale (GDS), and the Short Portable Mental Status Questionnaire (SPMSQ). All quality-of-life areas improved significantly from baseline to 4-month post-hearing aid fittings (p < 0.05). Social and emotional (HHIE), communication (QDS), and depression (GDS) benefits were sustained at 8 and 12 months, whereas cognitive changes (SPMSQ) reverted to baseline at 12 months. We conclude that hearing aids provide sustained benefits for at least a year in these elderly individuals with hearing impairment.},
author = {Mulrow, Cynthia D and Tuley, Michael R and Aguilar, Christine},
doi = {10.1044/jshr.3506.1402},
file = {:Users/gmac/mendeley/Mulrow, Tuley, Aguilar/Mulrow, Tuley, Aguilar - 1992 - Sustained benefits of hearing aids.pdf:pdf},
isbn = {0022-4685; 0022-4685},
issn = {0022-4685 (Print) 0022-4685},
journal = {Journal of Speech and Hearing Research},
keywords = {Aged Audiometry,Pure-Tone Auditory Threshold Comm},
pages = {1402--1405},
pmid = {1494282},
title = {{Sustained benefits of hearing aids}},
volume = {35},
year = {1992}
}
@article{Krause2010,
author = {Krause, Vanessa and Pollok, Bettina and Schnitzler, Alfons},
file = {:Users/gmac/mendeley/Krause, Pollok, Schnitzler/Krause, Pollok, Schnitzler - 2010 - Perception in action The impact of sensory information on sensorimotor synchronization in musicians.pdf:pdf},
journal = {Acta Psychologica},
month = {jan},
number = {1},
pages = {28--37},
publisher = {Elsevier B.V.},
title = {{Perception in action: The impact of sensory information on sensorimotor synchronization in musicians and non-musicians}},
url = {http://dx.doi.org/10.1016/j.actpsy.2009.08.003 papers3://publication/doi/10.1016/j.actpsy.2009.08.003},
volume = {133},
year = {2010}
}
@article{Sioros2014,
abstract = {In order to better understand the musical properties which elicit an increased sensation of wanting to move when listening to music-groove-we investigate the effect of adding syncopation to simple piano melodies, under the hypothesis that syncopation is correlated to groove. Across two experiments we examine listeners' experience of groove to synthesized musical stimuli covering a range of syncopation levels and densities of musical events, according to formal rules implemented by a computer algorithm that shifts musical events from strong to weak metrical positions. Results indicate that moderate levels of syncopation lead to significantly higher groove ratings than melodies without any syncopation or with maximum possible syncopation. A comparison between the various transformations and the way they were rated shows that there is no simple relation between syncopation magnitude and groove.},
author = {Sioros, George and Miron, Marius and Davies, Matthew and Gouyon, Fabien and Madison, Guy},
doi = {10.3389/fpsyg.2014.01036},
file = {:Users/gmac/mendeley/Sioros et al/Sioros et al. - 2014 - Syncopation creates the sensation of groove in synthesized music examples.pdf:pdf},
isbn = {1664-1078},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Groove,Listening experiment,Movement,Music,Rhythm,Syncopation},
number = {SEP},
pages = {1--10},
pmid = {25278923},
title = {{Syncopation creates the sensation of groove in synthesized music examples}},
volume = {5},
year = {2014}
}
@article{Large2002,
author = {Large, Edward W and Palmer, Caroline},
file = {:Users/gmac/mendeley/Large, Palmer/Large, Palmer - 2002 - Perceiving temporal regularity in music.pdf:pdf},
journal = {Cognitive Brain Research},
month = {jan},
pages = {1--37},
title = {{Perceiving temporal regularity in music}},
url = {papers3://publication/uuid/6519C8E8-1BEB-4977-A6C5-AE8AC651841D},
volume = {26},
year = {2002}
}
@article{Carrus2011,
abstract = {Brain and Language, 119 (2011) 50-57. doi:10.1016/j.bandl.2011.05.009},
author = {Carrus, Elisa and Koelsch, Stefan and Bhattacharya, Joydeep},
file = {:Users/gmac/mendeley/Carrus, Koelsch, Bhattacharya/Carrus, Koelsch, Bhattacharya - 2011 - Shadows of music-language interaction on low frequency brain oscillatory patterns.pdf:pdf},
journal = {Brain and Language},
month = {oct},
number = {1},
pages = {50--57},
publisher = {Elsevier Inc.},
title = {{Shadows of music-language interaction on low frequency brain oscillatory patterns}},
url = {http://dx.doi.org/10.1016/j.bandl.2011.05.009 papers3://publication/doi/10.1016/j.bandl.2011.05.009},
volume = {119},
year = {2011}
}
@article{Krumhansl1982,
author = {Krumhansl, Carol L and Kessler, Edward J},
file = {:Users/gmac/mendeley/Krumhansl, Kessler/Krumhansl, Kessler - 1982 - Tracing the Dynamic Changes in Perceived Tonal Organization in a Spatial Representation of Musical Keys.pdf:pdf},
journal = {Psychological Review},
month = {jan},
number = {4},
pages = {334--368},
title = {{Tracing the Dynamic Changes in Perceived Tonal Organization in a Spatial Representation of Musical Keys}},
volume = {89},
year = {1982}
}
@article{Sully1884,
author = {Sully, James},
file = {:Users/gmac/mendeley/Sully/Sully - 1884 - Book Review C. Stumpf's Tonpsychologie, I.pdf:pdf},
journal = {Mind},
month = {jan},
pages = {593--602},
title = {{Book Review: C. Stumpf's Tonpsychologie, I.}},
volume = {9},
year = {1884}
}
@article{VanZuijen2004,
abstract = {It is believed that auditory processes governing grouping and segmentation of sounds are automatic and represent universal aspects of music perception (e.g., they are independent of the listener's musical skill). The present study challenges this view by showing that musicians and nonmusicians differ in their ability to preattentively group consecutive sounds. We measured event-related potentials (ERPs) from professional musicians and nonmusicians who were presented with isochronous tone sequences that they ignored. Four consecutive tones in a sequence could be grouped according to either pitch similarity or good continuation of pitch. Occasionally, the tone-group length was violated by a deviant tone. The mismatch negativity (MMN) was elicited to the deviants in both subject groups when the sounds could be grouped based on pitch similarity. In contrast, MMN was only elicited in musicians when the sounds could be grouped according to good continuation of pitch. These results suggest that some forms of auditory grouping depend on musical skill and that not all aspects of auditory grouping are universal.},
author = {van Zuijen, Titia L and Sussman, Elyse and Winkler, Istv{\'{a}}n and N{\"{a}}{\"{a}}t{\"{a}}nen, Risto and Tervaniemi, Mari},
doi = {10.1162/089892904322984607},
file = {:Users/gmac/mendeley/van Zuijen et al/van Zuijen et al. - 2004 - Grouping of sequential sounds--an event-related potential study comparing musicians and nonmusicians.pdf:pdf},
isbn = {0898-929X},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
number = {2},
pages = {331--338},
pmid = {15068601},
title = {{Grouping of sequential sounds--an event-related potential study comparing musicians and nonmusicians.}},
volume = {16},
year = {2004}
}
@inproceedings{Song2015a,
author = {Song, Chunyang and Pearce, Marcus and Harte, Christopher},
booktitle = {Proceedings of the 12th International Conference on Sound and Music Computing (SMC-15)},
file = {:Users/gmac/mendeley/Song, Pearce, Harte/Song, Pearce, Harte - 2015 - SYNPY a python toolkit for syncopation modelling.pdf:pdf},
isbn = {9780992746629},
pages = {295--300},
title = {{SYNPY: a python toolkit for syncopation modelling}},
year = {2015}
}
@article{Lindenberger2009,
author = {Lindenberger, Ulman and Li, Shu-Chen and Gruber, Walter and M{\"{u}}ller, Viktor},
file = {:Users/gmac/mendeley/Lindenberger et al/Lindenberger et al. - 2009 - Brains swinging in concert cortical phase synchronization while playing guitar.pdf:pdf},
journal = {BMC Neuroscience},
month = {jan},
number = {1},
pages = {22},
title = {{Brains swinging in concert: cortical phase synchronization while playing guitar}},
url = {http://www.biomedcentral.com/1471-2202/10/22 papers3://publication/doi/10.1186/1471-2202-10-22},
volume = {10},
year = {2009}
}
@article{Ruiz2009,
author = {Ruiz, M H and Jabusch, H C and Altenmuller, E},
file = {:Users/gmac/mendeley/Ruiz, Jabusch, Altenmuller/Ruiz, Jabusch, Altenmuller - 2009 - Detecting Wrong Notes in Advance Neuronal Correlates of Error Monitoring in Pianists.pdf:pdf},
journal = {Cerebral Cortex},
month = {oct},
number = {11},
pages = {2625--2639},
title = {{Detecting Wrong Notes in Advance: Neuronal Correlates of Error Monitoring in Pianists}},
volume = {19},
year = {2009}
}
@article{Cacioppo1992,
author = {Cacioppo, John T and Berntson, G G and Klein, D J},
file = {:Users/gmac/mendeley/Cacioppo, Berntson, Klein/Cacioppo, Berntson, Klein - 1992 - What is an emotion The role of somatovisceral afference, with special emphasis on somatovisceral illu.pdf:pdf},
journal = {Review of Personality and Social Psychology},
month = {jan},
pages = {63--98},
title = {{What is an emotion? The role of somatovisceral afference, with special emphasis on somatovisceral "illusions"}},
url = {papers3://publication/uuid/638AF8A4-63E4-4050-B0EC-C26A9CB89B91},
volume = {14},
year = {1992}
}
@article{Jung2000,
abstract = {Eye movements, eye blinks, cardiac signals, muscle noise, and line noise present serious problems for electroencephalographic (EEG) interpretation and analysis when rejecting contaminated EEG segments results in an unacceptable data loss. Many methods have been proposed to remove artifacts from EEG recordings, especially those arising from eye movements and blinks. Often regression in the time or frequency domain is performed on parallel EEG and electrooculographic (EOG) recordings to derive parameters characterizing the appearance and spread of EOG artifacts in the EEG channels. Because EEG and ocular activity mix bidirectionally, regressing out eye artifacts inevitably involves subtracting relevant EEG signals from each record as well. Regression methods become even more problematic when a good regressing channel is not available for each artifact source, as in the case of muscle artifacts. Use of principal component analysis (PCA) has been proposed to remove eye artifacts from multichannel EEG. However, PCA cannot completely separate eye artifacts from brain signals, especially when they have comparable amplitudes. Here, we propose a new and generally applicable method for removing a wide variety of artifacts from EEG records based on blind source separation by independent component analysis (ICA). Our results on EEG data collected from normal and autistic subjects show that ICA can effectively detect, separate, and remove contamination from a wide variety of artifactual sources in EEG records with results comparing favorably with those obtained using regression and PCA methods. ICA can also be used to analyze blink-related brain activity.},
address = {Howard Hughes Medical Institute, Salk Institute, San Diego, California, USA. jung@inc.ucsd.edu},
author = {Jung, Tzyy-Ping and Makeig, S and Humphries, C and Lee, T W and McKeown, M J and Iragui, V and Sejnowski, T J},
file = {:Users/gmac/mendeley/Jung et al/Jung et al. - 2000 - Removing electroencephalographic artifacts by blind source separation.pdf:pdf},
journal = {Psychophysiology},
month = {mar},
number = {2},
pages = {163--178},
title = {{Removing electroencephalographic artifacts by blind source separation.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=10731767&retmode=ref&cmd=prlinks papers3://publication/uuid/9E1C9F81-119F-4860-88F6-FCEDB90537FC},
volume = {37},
year = {2000}
}
@article{Ruggles2012,
abstract = {Anecdotally, middle-aged listeners report difficulty conversing in social settings, even when they have normal audiometric thresholds [1-3]. Moreover, young adult listeners with "normal" hearing vary in their ability to selectively attend to speech amid similar streams of speech. Ignoring age, these individual differences correlate with physiological differences in temporal coding precision present in the auditory brainstem, suggesting that the fidelity of encoding of suprathreshold sound helps explain individual differences [4]. Here, we revisit the conundrum of whether early aging influences an individual's ability to communicate in everyday settings. Although absolute selective attention ability is not predicted by age, reverberant energy interferes more with selective attention as age increases. Breaking the brainstem response down into components corresponding to coding of stimulus fine structure and envelope, we find that age alters which brainstem component predicts performance. Specifically, middle-aged listeners appear to rely heavily on temporal fine structure, which is more disrupted by reverberant energy than temporal envelope structure is. In contrast, the fidelity of envelope cues predicts performance in younger adults. These results hint that temporal envelope cues influence spatial hearing in reverberant settings more than is commonly appreciated and help explain why middle-aged listeners have particular difficulty communicating in daily life.},
address = {Department of Biomedical Engineering, Center for Computational Neuroscience and Neural Technology, Boston University, Boston, MA 02215, USA.},
author = {Ruggles, Dorea and Bharadwaj, Hari and Shinn-Cunningham, Barbara G},
file = {:Users/gmac/mendeley/Ruggles, Bharadwaj, Shinn-Cunningham/Ruggles, Bharadwaj, Shinn-Cunningham - 2012 - Why middle-aged listeners have trouble hearing in everyday settings.pdf:pdf},
journal = {Current biology : CB},
month = {aug},
number = {15},
pages = {1417--1422},
title = {{Why middle-aged listeners have trouble hearing in everyday settings.}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0960982212005787 papers3://publication/doi/10.1016/j.cub.2012.05.025},
volume = {22},
year = {2012}
}
@article{Epting2011,
abstract = {There are a number of factors that can influence an athlete's performance during a game other than the athlete's skill. Athletes must perform in front of crowds in every game, and crowds express their feelings about athletes' performances by, for instance, cheering ( ...
},
author = {Epting, L K and Riggs, K N and Knowles, J D},
file = {:Users/gmac/mendeley/Epting, Riggs, Knowles/Epting, Riggs, Knowles - 2011 - Cheers vs. jeers effects of audience feedback on individual athletic performance.pdf:pdf},
journal = {North American journal of {\ldots}},
month = {jan},
title = {{Cheers vs. jeers: effects of audience feedback on individual athletic performance}},
url = {http://www.questia.com/library/journal/1G1-256864603/cheers-vs-jeers-effects-of-audience-feedback-on papers3://publication/uuid/C9A96F40-C39E-47AE-AE47-492C31A439F3},
year = {2011}
}
@article{Fujioka2010,
abstract = {The frontal-striatal circuits, the cerebellum, and motor cortices play crucial roles in processing timing information on second to millisecond scales. However, little is known about the physiological mechanism underlying human's preference to robustly encode a sequence of time intervals into a mental hierarchy of temporal units called meter. This is especially salient in music: temporal patterns are typically interpreted as integer multiples of a basic unit (i.e., the beat) and accommodated into a global context such as march or waltz. With magnetoencephalography and spatial-filtering source analysis, we demonstrated that the time courses of neural activities index a subjectively induced meter context. Auditory evoked responses from hippocampus, basal ganglia, and auditory and association cortices showed a significant contrast between march and waltz metric conditions during listening to identical click stimuli. Specifically, the right hippocampus was activated differentially at 80 ms to the march downbeat (the count one) and approximately 250 ms to the waltz downbeat. In contrast, basal ganglia showed a larger 80 ms peak for march downbeat than waltz. The metric contrast was also expressed in long-latency responses in the right temporal lobe. These findings suggest that anticipatory processes in the hippocampal memory system and temporal computation mechanism in the basal ganglia circuits facilitate endogenous activities in auditory and association cortices through feedback loops. The close interaction of auditory, motor, and limbic systems suggests a distributed network for metric organization in temporal processing and its relevance for musical behavior.},
address = {Rotman Research Institute, Baycrest, Canada. tfujioka@rotman-baycrest.on.ca},
author = {Fujioka, Takako and Zendel, Benjamin Rich and Ross, Bernhard},
file = {:Users/gmac/mendeley/Fujioka, Zendel, Ross/Fujioka, Zendel, Ross - 2010 - Endogenous neuromagnetic activity for mental hierarchy of timing.pdf:pdf},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
month = {mar},
number = {9},
pages = {3458--3466},
publisher = {Society for Neuroscience},
title = {{Endogenous neuromagnetic activity for mental hierarchy of timing.}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3086-09.2010 papers3://publication/doi/10.1523/JNEUROSCI.3086-09.2010},
volume = {30},
year = {2010}
}
@article{Stumpf1898,
author = {Stumpf, Carl},
journal = {Beiträge zur Akustischen Musikwissenschaft},
month = {jan},
pages = {1--108},
title = {{Konsonanz und Dissonanz}},
url = {papers3://publication/uuid/9DDBF25F-7FF5-441B-8EAE-1812DE8AE9A8},
volume = {1},
year = {1898}
}
@article{Fishburn2014,
abstract = {Functional near-infrared spectroscopy (fNIRS) is an emerging low-cost noninvasive neuroimaging technique that measures cortical bloodflow.},
author = {Fishburn, Frank A and Norr, Megan E and Medvedev, Andrei V and Vaidya, Chandan J},
file = {:Users/gmac/mendeley/Fishburn et al/Fishburn et al. - 2014 - Sensitivity of fNIRS to cognitive state and load.pdf:pdf},
journal = {Frontiers in Human Neuroscience},
month = {feb},
pages = {1--11},
title = {{Sensitivity of fNIRS to cognitive state and load}},
url = {http://journal.frontiersin.org/Journal/10.3389/fnhum.2014.00076/full papers3://publication/doi/10.3389/fnhum.2014.00076/abstract},
volume = {8},
year = {2014}
}
@article{Krumhansl1979,
abstract = {In this series of experiments, evidence was found for a complex psychological representation of musical pitch. The results of a scaling study, in which subjects judged the similarities between pairs of tones presented in an explicitly tonal context, suggest that musical listeners extract a pattern of relationships among tones that is determined not only by pitch height and chroma, but also by membership in the major triad chord and the diatonic scale associated with the tonal system of the context. Multidimensional scaling of the similarity ratings gave a three-dimensional conical structure around which the tones were ordered according to pitch height. The major triad components formed a closely related cluster near the vertex of the cone; the remaining diatonic scale tones formed a less closely related subset farther from the vertex; and, the nondiatonic tones, still farther from the vertex, were widely dispersed. The results also suggest that, in the psychological representation, tones less closely related to the tonality are less stable than tones closely related to the tonality, and that the representation incorporates the tendency for unstable tones to move toward the more stable tones in time, reflecting the dynamic character of musical tones. In the similarity ratings of the scaling study, tones less related to the tonality were judged more similar to tones more related to the tonality than the reverse temporal order. Furthermore, in a delayed recognition task memory performance for nondiatonic tones was less accurate than for diatonic tones, and nondiatonic tones were more often confused with diatonic tones than diatonic tones were confused with nondiatonic tones. These results indicate the tonality-specific nature of the psychological representation and argue that the perception of music depends not only on psychoacoustic properties of the tones, but also on processes that relate the tones to one another through contact with a well-defined and complex psychological representation of musical pitch.},
author = {Krumhansl, Carol L.},
doi = {10.1016/0010-0285(79)90016-1},
file = {:Users/gmac/mendeley/Krumhansl/Krumhansl - 1979 - The psychological representation of musical pitch in a tonal context.pdf:pdf},
isbn = {0010-0285},
issn = {00100285},
journal = {Cognitive Psychology},
number = {3},
pages = {346--374},
title = {{The psychological representation of musical pitch in a tonal context}},
volume = {11},
year = {1979}
}
@article{Rauschecker2011,
abstract = {The dual-pathway model of auditory cortical processing assumes that two largely segregated processing streams originating in the lateral belt subserve the two main functions of hearing: identification of auditory " objects" , including speech; and localization of sounds in space (Rauschecker and Tian, 2000). Evidence has accumulated, chiefly from work in humans and nonhuman primates, that an antero-ventral pathway supports the former function, whereas a postero-dorsal stream supports the latter, i.e processing of space and motion-in-space. In addition, the postero-dorsal stream has also been postulated to subserve some functions of speech and language in humans. A recent review (Rauschecker and Scott, 2009) has proposed the possibility that both functions of the postero-dorsal pathway can be subsumed under the same structural forward model: an efference copy sent from prefrontal and premotor cortex provides the basis for " optimal state estimation" in the inferior parietal lobe and in sensory areas of the posterior auditory cortex. The current article corroborates this model by adding and discussing recent evidence. ?? 2010 Elsevier B.V.},
author = {Rauschecker, Josef P},
doi = {10.1016/j.heares.2010.09.001},
file = {:Users/gmac/mendeley/Rauschecker/Rauschecker - 2011 - An expanded role for the dorsal auditory pathway in sensorimotor control and integration.pdf:pdf},
isbn = {1878-5891 (Electronic)\r0378-5955 (Linking)},
issn = {03785955},
journal = {Hearing Research},
number = {1-2},
pages = {16--25},
pmid = {20850511},
publisher = {Elsevier B.V.},
title = {{An expanded role for the dorsal auditory pathway in sensorimotor control and integration}},
url = {http://dx.doi.org/10.1016/j.heares.2010.09.001},
volume = {271},
year = {2011}
}
@article{Schmidt2016a,
abstract = {Normal-hearing listeners use acoustic cues in speech to interpret a speaker's emotional state. This study investigates the effect of hearing aids on the perception of the emotion dimensions arousal (aroused/calm) and valence (positive/negative attitude) in older adults with hearing loss. More specifically, we investigate whether wearing a hearing aid improves the correlation between affect ratings and affect-related acoustic parameters. To that end, affect ratings by 23 hearing-aid users were compared for aided and unaided listening. Moreover, these ratings were compared to the ratings by an age-matched group of 22 participants with age-normal hearing.For arousal, hearing-aid users rated utterances as generally more aroused in the aided than in the unaided condition. Intensity differences were the strongest indictor of degree of arousal. Among the hearing-aid users, those with poorer hearing used additional prosodic cues (i.e., tempo and pitch) for their arousal ratings, compared to those with relatively good hearing. For valence, pitch was the only acoustic cue that was associated with valence. Neither listening condition nor hearing loss severity (differences among the hearing-aid users) influenced affect ratings or the use of affect-related acoustic parameters. Compared to the normal-hearing reference group, ratings of hearing-aid users in the aided condition did not generally differ in both emotion dimensions. However, hearing-aid users were more sensitive to intensity differences in their arousal ratings than the normal-hearing participants.We conclude that the use of hearing aids is important for the rehabilitation of affect perception and particularly influences the interpretation of arousal.},
author = {Schmidt, Juliane and Herzog, Diana and Scharenborg, Odette and Janse, Esther},
doi = {10.1007/978-3-319-25474-6_6},
file = {:Users/gmac/mendeley/Schmidt et al/Schmidt et al. - 2016 - Do hearing aids improve affect perception.pdf:pdf},
isbn = {9783319254746},
issn = {22148019},
journal = {Advances in Experimental Medicine and Biology},
keywords = {Acoustic parameters,Affective prosody,Arousal,Emotion perception,Hearing aids,Hearing loss,Mean F0,Mean intensity,Natural speech,Older adults,Valence},
pages = {47--55},
pmid = {27080645},
title = {{Do hearing aids improve affect perception?}},
volume = {894},
year = {2016}
}
@article{Owen2006,
annote = {- lack of motor output? -- treating brain activity as behaviour
- her "decision" to cooperate with the authors -- was it really a decision or just an automatic response?
- BCI to have patient control some kind of feedback loop -- brain activity causes some action that she responds to},
author = {Owen, A M},
file = {:Users/gmac/mendeley/Owen/Owen - 2006 - Detecting Awareness in the Vegetative State.pdf:pdf},
journal = {Science},
month = {sep},
number = {5792},
pages = {1402},
title = {{Detecting Awareness in the Vegetative State}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1130197 papers3://publication/doi/10.1126/science.1130197},
volume = {313},
year = {2006}
}
@article{Winkler2015,
author = {Winkler, Irene and Debener, Stefan and Muller, Klaus Robert and Tangermann, Michael},
doi = {10.1109/EMBC.2015.7319296},
file = {:Users/gmac/mendeley/Winkler et al/Winkler et al. - 2015 - On the influence of high-pass filtering on ICA-based artifact reduction in EEG-ERP.pdf:pdf},
isbn = {9781424492718},
issn = {1557170X},
journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
pages = {4101--4105},
title = {{On the influence of high-pass filtering on ICA-based artifact reduction in EEG-ERP}},
volume = {2015-Novem},
year = {2015}
}
@article{Lee2009,
author = {Lee, K M and Skoe, E and Kraus, Nina and Ashley, R},
file = {:Users/gmac/mendeley/Lee et al/Lee et al. - 2009 - Selective Subcortical Enhancement of Musical Intervals in Musicians.pdf:pdf},
journal = {Journal of Neuroscience},
month = {may},
number = {18},
pages = {5832--5840},
title = {{Selective Subcortical Enhancement of Musical Intervals in Musicians}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.6133-08.2009 papers3://publication/doi/10.1523/JNEUROSCI.6133-08.2009},
volume = {29},
year = {2009}
}
@article{Bashivan,
abstract = {The increasing quality and affordability of consumer electroencepha-logram (EEG) headsets make them attractive for situations where medical grade devices are impractical. Predicting and tracking cognitive states is possible for tasks that were previously not conducive to EEG monitoring. For instance, monitoring operators for states inappropriate to the task (e.g. drowsy drivers), tracking mental health (e.g. anxiety) and productivity (e.g. tiredness) are among possible applications for the technology. Consumer grade EEG headsets are af-fordable and relatively easy to use, but they lack the resolution and quality of signal that can be achieved using medical grade EEG devices. Thus, the key questions remain: to what extent are wearable EEG devices capable of mental state recognition, and what kind of mental states can be accurately recognized with these devices? In this work, we examined responses to two different types of input: instructional ('logical') versus recreational ('emotional') videos, using a range of machine-learning methods. We tried SVMs, sparse logistic regres-sion, and Deep Belief Networks, to discriminate between the states of mind in-duced by different types of video input, that can be roughly labeled as 'logical' vs. 'emotional'. Our results demonstrate a significant potential of wearable EEG devices in differentiating cognitive states between situations with large contextual but subtle apparent differences.},
author = {Bashivan, Pouya and Rish, Irina and Heisig, Steve},
file = {:Users/gmac/mendeley/Bashivan, Rish, Heisig/Bashivan, Rish, Heisig - Unknown - Mental State Recognition via Wearable EEG.pdf:pdf},
keywords = {Brain-Computer Interface,Machine Learning,Mental State Recognition,Wearable EEG},
title = {{Mental State Recognition via Wearable EEG}},
url = {https://arxiv.org/pdf/1602.00985.pdf}
}
@article{Gusnard2001,
author = {Gusnard, Debra A and Akbudak, Erbil and Shulman, Gordon L and Raichle, Marcus E},
file = {:Users/gmac/mendeley/Gusnard et al/Gusnard et al. - 2001 - Medial prefrontal cortex and self-referential mentalactivity Relation to a default mode ofbrain function.pdf:pdf},
journal = {Proceedings of the National Acadamy of Sciences},
month = {mar},
pages = {4259--4264},
title = {{Medial prefrontal cortex and self-referential mentalactivity: Relation to a default mode ofbrain function}},
url = {papers3://publication/uuid/6181E32A-EB79-4900-9D51-3C4F27F892C1},
volume = {98},
year = {2001}
}
@article{Wheeler1985,
author = {Wheeler, B L},
file = {:Users/gmac/mendeley/Wheeler/Wheeler - 1985 - Relationship of Personal Characteristics to Mood and Enjoyment after Hearing Live and Recorded Music and to Musical Tas.pdf:pdf},
journal = {Psychology of Music},
keywords = {audience,performance},
month = {oct},
number = {2},
pages = {81--92},
title = {{Relationship of Personal Characteristics to Mood and Enjoyment after Hearing Live and Recorded Music and to Musical Taste}},
url = {http://pom.sagepub.com/cgi/doi/10.1177/0305735685132002 papers3://publication/doi/10.1177/0305735685132002},
volume = {13},
year = {1985}
}
@article{Jung2000a,
abstract = {OBJECTIVES:Electrical potentials produced by blinks and eye movements present serious problems for electroencephalographic (EEG) and event-related potential (ERP) data interpretation and analysis, particularly for analysis of data from some clinical populations. Often, all epochs contaminated by large eye artifacts are rejected as unusable, though this may prove unacceptable when blinks and eye movements occur frequently.

METHODS:Frontal channels are often used as reference signals to regress out eye artifacts, but inevitably portions of relevant EEG signals also appearing in EOG channels are thereby eliminated or mixed into other scalp channels. A generally applicable adaptive method for removing artifacts from EEG records based on blind source separation by independent component analysis (ICA) (Neural Computation 7 (1995) 1129; Neural Computation 10(8) (1998) 2103; Neural Computation 11(2) (1999) 606) overcomes these limitations.

RESULTS:Results on EEG data collected from 28 normal controls and 22 clinical subjects performing a visual selective attention task show that ICA can be used to effectively detect, separate and remove ocular artifacts from even strongly contaminated EEG recordings. The results compare favorably to those obtained using rejection or regression methods.

CONCLUSIONS:The ICA method can preserve ERP contributions from all of the recorded trials and all the recorded data channels, even when none of the single trials are artifact-free.},
address = {University of California, San Diego, La Jolla, CA 92093, USA. jung@salk.edu},
author = {Jung, Tzyy-Ping and Makeig, S and Westerfield, M and Townsend, J and Courchesne, E and Sejnowski, T J},
file = {:Users/gmac/mendeley/Jung et al/Jung et al. - 2000 - Removal of eye activity artifacts from visual event-related potentials in normal and clinical subjects.pdf:pdf},
journal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
month = {oct},
number = {10},
pages = {1745--1758},
title = {{Removal of eye activity artifacts from visual event-related potentials in normal and clinical subjects.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=11018488&retmode=ref&cmd=prlinks papers3://publication/uuid/6B436ECE-5D91-4268-9212-CEF118708A20},
volume = {111},
year = {2000}
}
@article{Aiken2008a,
abstract = {OBJECTIVE:To evaluate the response of the human auditory cortex to the temporal amplitude-envelope of speech. Responses to the speech envelope could be useful for validating the neural encoding of intelligible speech, particularly during hearing aid fittings--because hearing aid gain and compression characteristics for ongoing speech should more closely resemble real world performance than for isolated brief syllables.

DESIGN:The speech envelope comprises energy changes corresponding to phonemic and syllabic transitions. Envelope frequencies between 2 and 20 Hz are important for speech intelligibility. Human event-related potentials were recorded to six different sentences and the sources of these potentials in the auditory cortex were determined. To improve the signal to noise ratio over ongoing electroencephalographic recordings, we averaged the responses over multiple presentations, and derived source waveforms from multichannel scalp recordings. Source analysis led to bilateral, symmetrical, vertical, and horizontal dipoles in the posterior auditory cortices. The source waveforms were then cross-correlated with the low frequency log-envelopes of the sentences. The significance and latency of the maximum correlation for each sentence demonstrated the presence and latency of the brain's response. The source waveforms were also cross-correlated with a simple model based on a series of overlapping transient responses to stimulus change (the derivative of the log-envelope).

RESULTS:Correlations between the log-envelope and vertical dipole source waveforms were significant for all sentences and for all but one of the participants (mean r = 0.35), at an average delay of 175 (left) to 180 (right) msec. Correlations between the transient response model (P1 at 68 msec, N1 at 124 msec, and P2 at 208 msec) and the vertical dipole source waveforms were detected for all sentences and all participants (mean r = 0.30), at an average delay of 6 (right) to 10 (left) msec.

CONCLUSIONS:These results show that the human auditory cortex either directly follows the speech envelope or consistently reacts to changes in this envelope. The delay between the envelope and the response is approximately 180 msec.},
address = {Rotman Research Institute, Baycrest Centre for Geriatric Care, University of Toronto, Toronto, Canada. steve.aiken@dal.ca},
author = {Aiken, Steven J and Picton, Terence W},
file = {:Users/gmac/mendeley/Aiken, Picton/Aiken, Picton - 2008 - Human cortical responses to the speech envelope.pdf:pdf},
journal = {Ear & Hearing},
month = {apr},
number = {2},
pages = {139--157},
title = {{Human cortical responses to the speech envelope.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=18595182&retmode=ref&cmd=prlinks papers3://publication/uuid/EDAF33E8-9027-4911-8D53-FF6FCC93C7E5},
volume = {29},
year = {2008}
}
@article{Logothetis2001,
author = {Logothetis, Nikos K and Pauls, Jon and Trinath, Torsten and Oeltermann, Axel},
file = {:Users/gmac/mendeley/Logothetis et al/Logothetis et al. - 2001 - Neurophysiological investigation of the basis of the fMRI signal.pdf:pdf},
journal = {Nature},
month = {jul},
pages = {150--157},
title = {{Neurophysiological investigation of the basis of the fMRI signal}},
url = {papers3://publication/uuid/03E5026D-CF0B-49E7-AC1E-CD98A3243332},
volume = {412},
year = {2001}
}
@article{Burger2012,
abstract = {Listening to music makes us move in various ways. Several factors can affect the characteristics of these movements, including individual factors, musical features, or perceived emotional content of music. Music is based on regular and repetitive temporal patterns that give rise to a percept of pulse. From these basic metrical structures more complex temporal structures emerge, such as rhythm. It has been suggested that certain rhythmic features can induce movement in humans. Rhythmic structures vary in their degree of complexity and regularity, and one could expect that this variation influences movement patterns – for instance, when moving to rhythmically more complex music, the movements may also be more irregular. To investigating this relationship, sixty participants were presented with 30 musical stimuli representing different genres of popular music. All stimuli were 30 seconds long, non-vocal, and differed in their rhythmic complexity. Optical motion capture was used to record participants' movements. Two movement features were extracted from the data: Spatial Regularity and Temporal Regularity. Additionally, 12 beat-related musical features were extracted from the music stimuli. A subsequent correlational analysis revealed that beat-related musical features influenced the regularity of music-induced movement. In particular, a clear pulse and high percussiveness resulted in small spatial variation of participants' movements, whereas an unclear pulse and low percussiveness led to greater spatial variation of their movements. Additionally, temporal regularity was positively correlated to flux in the low frequencies (e.g., kick drum, bass guitar) and pulse clarity, suggesting that strong rhythmic components and a clear pulse encourage temporal regularity.},
author = {Burger, Birgitta and Thompson, Marc R and Luck, Geoff and Saarikallio, Suvi and Toiviainen, Petri},
file = {:Users/gmac/mendeley/Burger et al/Burger et al. - 2012 - Music Moves Us Beat-Related Musical Features Influence Regularity of Music-Induced Movement.pdf:pdf},
isbn = {978-960-99845-1-5},
journal = {Proceedings of the 12th international Conference on Music Perception and Cognition},
pages = {183--187},
title = {{Music Moves Us: Beat-Related Musical Features Influence Regularity of Music-Induced Movement}},
url = {http://icmpc-escom2012.web.auth.gr/sites/default/files/papers/183_Proc.pdf},
year = {2012}
}
@article{Keller2011a,
author = {Keller, Peter E and Weber, Andreas and Engel, Annerose},
file = {:Users/gmac/mendeley/Keller, Weber, Engel/Keller, Weber, Engel - 2011 - Practice Makes Too Perfect Fluctuations in Loudness Indicate Spontaneity in Music Improvisation.pdf:pdf},
journal = {Music Perception},
month = {jan},
number = {1},
pages = {109--114},
title = {{Practice Makes Too Perfect: Fluctuations in Loudness Indicate Spontaneity in Music Improvisation}},
url = {papers3://publication/doi/10.1525/MP.2011.29.1.109},
volume = {29},
year = {2011}
}
@techreport{Perry2010,
author = {Perry, Anat and Troje, Nikolaus F and Bentin, Shlomo},
file = {:Users/gmac/mendeley/Perry, Troje, Bentin/Perry, Troje, Bentin - 2010 - Exploring motor system contributions to the perception of social information Evidence from EEG activity in.pdf:pdf},
keywords = {MNS,mu},
month = {may},
title = {{Exploring motor system contributions to the perception of social information: Evidence from EEG activity in the mu/alpha frequency range}},
url = {papers3://publication/uuid/1FE1DFDD-CFA9-4B1E-AD09-5F6AE0E28711},
year = {2010}
}
@article{Zhou2016,
abstract = {Brain activity can follow the rhythms of dynamic sensory stimuli, such as speech and music, a phenomenon called neural entrainment. It has been hypothesized that low-frequency neural entrainment in the neural delta and theta bands provides a potential mechanism to represent and integrate temporal information. Low-frequency neural entrainment is often studied using periodically changing stimuli and is analyzed in the frequency domain using the Fourier analysis. The Fourier analysis decomposes a periodic signal into harmonically related sinusoids. However, it is not intuitive how these harmonically related components are related to the response waveform. Here, we explain the interpretation of response harmonics, with a special focus on very low- frequency neural entrainment near 1 Hz. It is illustrated why neural responses repeating at f Hz do not necessarily generate any neural response at f Hz in the Fourier spectrum. A strong neural response at f Hz indicates that the time scales of the neural response waveform within each cycle match the time scales of the stimulus rhythm. Therefore, neural entrainment at very low frequency implies not only that the neural response repeats at f Hz but also that each period of the neural response is a slow wave matching the time scale of a f Hz sinusoid.},
author = {Zhou, Hong and Melloni, Lucia and Poeppel, David and Ding, Nai},
doi = {10.3389/fnhum.2016.00274},
file = {:Users/gmac/mendeley/Zhou et al/Zhou et al. - 2016 - Interpretations of Frequency Domain Analyses of Neural Entrainment Periodicity, Fundamental Frequency, and Harmonic.pdf:pdf},
isbn = {1662-5161},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
keywords = {harmonics,neural entrainment,oscillation,oscillations,periodicity,rhythm},
number = {274},
pages = {1--8},
pmid = {27375465},
title = {{Interpretations of Frequency Domain Analyses of Neural Entrainment: Periodicity, Fundamental Frequency, and Harmonics}},
volume = {10},
year = {2016}
}
@article{Morillon2014a,
abstract = {In temporal—or dynamic—attending theory, it is proposed that motor activity helps to synchronize temporal fluctuations of attention with the timing of events in a task-relevant stream, thus facilitating sensory selection. Here we develop a mechanistic behavioural account for this theory by asking human participants to track a slow reference beat, by noiseless finger pressing, while extracting auditory target tones delivered on-beat and interleaved with distractors. We find that overt rhythmic motor activity improves the segmentation of auditory information by enhancing sensitivity to target tones while actively suppressing distractor tones. This effect is triggered by cyclic fluctuations in sensory gain locked to individual motor acts, scales parametrically with the temporal predictability of sensory events and depends on the temporal alignment between motor and attention fluctuations. Together, these findings reveal how top-down influences associated with a rhythmic motor routine sharpen sensory representations, enacting auditory ‘active sensing'. 1},
author = {Morillon, Benjamin and Schroeder, Charles E and Wyart, Valentin},
doi = {10.1038/ncomms6255},
file = {:Users/gmac/mendeley/Morillon, Schroeder, Wyart/Morillon, Schroeder, Wyart - 2014 - Motor contributions to the temporal precision of auditory attention.pdf:pdf},
isbn = {doi:10.1038/ncomms6255},
issn = {2041-1723},
journal = {Nature Communications},
pages = {1--9},
pmid = {25314898},
publisher = {Nature Publishing Group},
title = {{Motor contributions to the temporal precision of auditory attention}},
url = {http://dx.doi.org/10.1038/ncomms6255%5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4199392&tool=pmcentrez&rendertype=abstract},
volume = {5},
year = {2014}
}
@article{Manning2013,
author = {Manning, Fiona and Schutz, Michael},
file = {:Users/gmac/mendeley/Manning, Schutz/Manning, Schutz - 2013 - “Moving to the beat” improves timing perception.pdf:pdf},
journal = {Psychonomic Bulletin & Review},
month = {may},
number = {6},
pages = {1133--1139},
title = {{“Moving to the beat” improves timing perception}},
url = {http://link.springer.com/10.3758/s13423-013-0439-7},
volume = {20},
year = {2013}
}
@article{Stumpf1895,
author = {Stumpf, Carl},
file = {:Users/gmac/mendeley/Stumpf/Stumpf - 1895 - Hermann von Helmholtz and the New Psychology.pdf:pdf},
journal = {The Psychological Review},
month = {jan},
pages = {1--12},
title = {{Hermann von Helmholtz and the New Psychology}},
url = {papers3://publication/uuid/9CCCFE3A-0352-4B1B-8035-208E0CABC400},
volume = {11},
year = {1895}
}
@article{Kamil2015,
abstract = {Background: Hearing impairment is highly prevalent in older adults and can affect the daily activities of a person who is hard of hearing (HOH). The impact of hearing impairment may also have collateral effects on the primary communication partner (CP; e.g., spouse, close family member, or caregiver) of the person who is HOH. Purpose: We aimed to characterize the impact of hearing loss in a person who is HOH on his or her CP. Research Design: We conducted a systematic review of manuscripts examining the consequences of hearing loss in a person who is HOH on the CP. We searched PubMed, Embase, Scopus, PyscINFO, CINAHL Pius with full text, and Web of Science for peer-reviewed articles using a predefined search string and hand-searched reference lists of relevant articles. Data Collection and Analysis: We initially screened abstracts blinded for author and journal to eliminate irrelevant and duplicate articles. Descriptive information on study populations, hearing assessments, outcome metrics, and study findings were extracted from full-length manuscripts. Results: Of the 1,047 abstracts retrieved from database searching and 5 hand-searched articles, 24 articles met inclusion criteria. These articles included observational clinical studies, randomized clinical trials, and epidemiologic studies. Overall, CPs experienced a restricted social life, increased burden of communication, and poorer quality of life (QOL) and relationship satisfaction. Effects of hearing impairment on a CP's mental health were unclear. Treatment of hearing loss in the person who is HOH tended to improve QOL, communication, feelings toward the person who is HOH, and activity participation of the CP. Conclusions: This review highlights the broad effects of hearing impairment and the importance of involving CPs in hearing loss treatment decisions. [ABSTRACT FROM AUTHOR]},
author = {Kamil, Rebecca J. and Lin, Frank R.},
doi = {10.3766/jaaa.26.2.6},
file = {:Users/gmac/mendeley/Kamil, Lin/Kamil, Lin - 2015 - The Effects of Hearing Impairment in Older Adults on Communication Partners A Systematic Review(2).pdf:pdf;:Users/gmac/mendeley/Kamil, Lin/Kamil, Lin - 2015 - The Effects of Hearing Impairment in Older Adults on Communication Partners A Systematic Review.pdf:pdf},
isbn = {2157-31071050-0545},
issn = {10500545},
journal = {Journal of the American Academy of Audiology},
keywords = {abbreviations,and throat,assessment of,assessment of difficulties index,cadi,cami,carers,central institute for the,cid,communication partner,cp,deaf,ear,ent,family relationships index,fri,hearing handicap and disability,hearing impairment,hhdi,management index,nose,older adults,quality of life},
number = {2},
pages = {155--182},
pmid = {25690776},
title = {{The Effects of Hearing Impairment in Older Adults on Communication Partners: A Systematic Review}},
url = {http://openurl.ingenta.com/content/xref?genre=article&issn=1050-0545&volume=26&issue=2&spage=155},
volume = {26},
year = {2015}
}
@article{Chemin2014,
abstract = {It is increasingly recognized that motor routines dynamically shape the processing of sensory inflow (e.g., when hand movements are used to feel a texture or identify an object). In the present research, we captured the shaping of auditory perception by movement in humans by taking advantage of a specific context: music. Participants listened to a repeated rhythmical sequence before and after moving their bodies to this rhythm in a specific meter. We found that the brain responses to the rhythm (as recorded with electroencephalography) after body movement were significantly enhanced at frequencies related to the meter to which the participants had moved. These results provide evidence that body movement can selectively shape the subsequent internal representation of auditory rhythms.},
address = {Institute of Neuroscience, System and Cognition Department, Universit{\'{e}} Catholique de Louvain.},
author = {Chemin, Baptiste and Mouraux, Andre and Nozaradan, Sylvie},
file = {:Users/gmac/mendeley/Chemin, Mouraux, Nozaradan/Chemin, Mouraux, Nozaradan - 2014 - Body Movement Selectively Shapes the Neural Representation of Musical Rhythms.pdf:pdf},
journal = {Psychological Science},
month = {oct},
pages = {0956797614551161},
publisher = {SAGE Publications},
title = {{Body Movement Selectively Shapes the Neural Representation of Musical Rhythms.}},
url = {http://pss.sagepub.com/lookup/doi/10.1177/0956797614551161 papers3://publication/doi/10.1177/0956797614551161},
year = {2014}
}
@article{Chanda2013,
abstract = {Trends in Cognitive Sciences, 17 (2013) 179-193. 10.1016/j.tics.2013.02.007},
annote = {REWARD
chill-inducing music
-- mescorticolimbic increase rCBF
-- nucleus accumbens (NAc)
-- dopamine in NAc; in caudate immediately before chills

pleasurable music
-- NAc, insula
-- VTA-mediated interactions between NAc and structures to regulate autonomic, emotional, cognitive functions
-- musical reward dependant on dopamine
-- deactivations in amyg, hippo parahippo, temporal poles

opioids
-- music listening lowers requirements for opiate drugs in postoperative pain
-- chills prevented by opioid antagonist

STRESS},
author = {Chanda, Mona Lisa and Levitin, Daniel J},
file = {:Users/gmac/mendeley/Chanda, Levitin/Chanda, Levitin - 2013 - The neurochemistry of music.pdf:pdf},
journal = {Trends in Cognitive Sciences},
month = {apr},
number = {4},
pages = {179--193},
publisher = {Elsevier Ltd},
title = {{The neurochemistry of music}},
url = {http://dx.doi.org/10.1016/j.tics.2013.02.007},
volume = {17},
year = {2013}
}
@book{Salsburg2001,
address = {New York},
author = {Salsburg, David},
keywords = {stats},
month = {jan},
publisher = {Owl Books},
title = {{No Title}},
url = {papers3://publication/uuid/16A2957A-A539-4441-A7D7-D5FC4EA01E18},
year = {2001}
}
@book{VanDijk,
editor = {van Dijk, Pim and Baskent, Deniz and Gaudrain, Etienne and de Kleine, Emile and Wagner, Anita and Lanting, Cris},
file = {:Users/gmac/mendeley/Unknown/Unknown - 2016 - Physiology, Psychoacoustics and Cognition in Normal and Impaired Hearing.pdf:pdf},
isbn = {9783319254722},
pages = {484},
publisher = {SpringerOpen},
title = {{Physiology, Psychoacoustics and Cognition in Normal and Impaired Hearing}},
url = {https://link.springer.com/content/pdf/10.1007/978-3-319-25474-6.pdf},
year = {2016}
}
@article{Brown2009,
author = {Brown, L A and de Bruin, N and Doan, Jon B and Suchowersky, O and Hu, B},
file = {:Users/gmac/mendeley/Brown et al/Brown et al. - 2009 - Novel Challenges to Gait in Parkinson's Disease The Effect of Concurrent Music in Single- and Dual-Task Contexts.pdf:pdf},
journal = {YAPMR},
month = {sep},
number = {9},
pages = {1578--1583},
publisher = {Elsevier Inc.},
title = {{Novel Challenges to Gait in Parkinson's Disease: The Effect of Concurrent Music in Single- and Dual-Task Contexts}},
url = {http://dx.doi.org/10.1016/j.apmr.2009.03.009 papers3://publication/doi/10.1016/j.apmr.2009.03.009},
volume = {90},
year = {2009}
}
@incollection{Hall1912,
address = {New York},
author = {Hall, G Stanley},
booktitle = {Founders of Modern Psychology},
file = {:Users/gmac/mendeley/Hall/Hall - 1912 - Rudolph Hermann Lotze BT - Founders of Modern Psychology.pdf:pdf},
month = {jan},
pages = {65--121},
publisher = {Appleton},
title = {{Rudolph Hermann Lotze BT  - Founders of Modern Psychology}},
url = {http://books1.scholarsportal.info.ezproxy.lib.ryerson.ca/viewdoc.html?id=/ebooks/ebooks0/apa/2010-03-04/1/200515317 papers3://publication/uuid/89775482-562F-425F-9B09-033CDACCA114},
year = {1912}
}
@article{Holube2006,
address = {Oldenburg, Germany},
author = {Holube, I and Group, EHIMA-ISMADHA Working},
journal = {Center of Competence H{\"{o}}rTech and Institute of Hearing Technology and Audiology},
title = {{Short description of the international speech test signal (ISTS)}},
year = {2006}
}
@article{Ekman1971,
abstract = {Investigated the question of whether any facial expressions of emotion are universal. Recent studies showing that members of literate cultures associated the same emotion concepts with the same facial behaviors could not demonstrate that at least some facial expressions of emotion are universal; the cultures compared had all been exposed to some of the same mass media presentations of facial expression, and these may have taught the people in each culture to recognize the unique facial expressions of other cultures. To show that members of a preliterate culture who had minimal exposure to literate cultures would associate the same emotion concepts with the same facial behaviors as do members of Western and Eastern literate cultures, data were gathered in New Guinea by telling 342 Ss a story, showing them a set of 3 faces, and asking them to select the face which showed the emotion appropriate to the story. Ss were members of the Fore linguistic-cultural group, which up until 12 yr. ago was an isolated, Neolithic, material culture. Results provide evidence in support of the hypothesis. (30 ref.) (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
author = {Ekman, Paul and Friesen, Wallace V},
doi = {10.1037/h0030377},
file = {:Users/gmac/mendeley/Ekman, Friesen/Ekman, Friesen - 1971 - Constants across cultures in the face and emotion.pdf:pdf},
isbn = {1939-1315(Electronic);0022-3514(Print)},
journal = {Journal of Personality and Social Psychology},
number = {2},
pages = {124--129},
pmid = {5542557},
title = {{Constants across cultures in the face and emotion.}},
volume = {17},
year = {1971}
}
@article{Tierney2013,
abstract = {Should music be a priority in public education? One argument for teaching music in school is that private music instruction relates to enhanced language abilities and neural function.},
annote = {- 15-year-olds did music or fitness training, measure FFR pre/post
- /da/ presented in multi-talker babble S/N of -10 dB relative to RMS of background noise},
author = {Tierney, Adam T and Krizman, Jennifer and Skoe, Erika and Johnston, Kathleen and Kraus, Nina},
file = {:Users/gmac/mendeley/Tierney et al/Tierney et al. - 2013 - High school music classes enhance the neural processing of speech.pdf:pdf},
journal = {Frontiers in Psychology},
month = {dec},
number = {855},
pages = {1--7},
title = {{High school music classes enhance the neural processing of speech}},
url = {papers3://publication/doi/10.3389/fpsyg.2013.00855/abstract},
volume = {4},
year = {2013}
}
@article{Caramazza1988,
author = {Caramazza, Alfonso and McCloskey, Michael},
file = {:Users/gmac/mendeley/Caramazza, McCloskey/Caramazza, McCloskey - 1988 - The case for single-patient studies.pdf:pdf},
journal = {Cognitive Neuropsychology},
month = {sep},
number = {5},
pages = {517--527},
title = {{The case for single-patient studies}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02643298808253271 papers3://publication/doi/10.1080/02643298808253271},
volume = {5},
year = {1988}
}
@article{Lambrecht2012,
author = {Lambrecht, Lena and Kreifelts, Benjamin and Wildgruber, Dirk},
doi = {10.1037/a0026827},
file = {:Users/gmac/mendeley/Lambrecht, Kreifelts, Wildgruber/Lambrecht, Kreifelts, Wildgruber - 2012 - Age-Related Decrease in Recognition of Emotional Facial and Prosodic Expressions.pdf:pdf},
journal = {Emotion},
number = {3},
pages = {529--539},
title = {{Age-Related Decrease in Recognition of Emotional Facial and Prosodic Expressions}},
volume = {12},
year = {2012}
}
@article{Vuoskoski2011,
author = {Vuoskoski, J K and Eerola, Tuomas},
file = {:Users/gmac/mendeley/Vuoskoski, Eerola/Vuoskoski, Eerola - 2011 - Measuring music-induced emotion A comparison of emotion models, personality biases, and intensity of experien.pdf:pdf},
journal = {Musicae Scientiae},
month = {jul},
number = {2},
pages = {159--173},
publisher = {European Society for the Cognitive Sciences of Music},
title = {{Measuring music-induced emotion: A comparison of emotion models, personality biases, and intensity of experiences}},
url = {http://msx.sagepub.com/lookup/doi/10.1177/1029864911403367 papers3://publication/doi/10.1177/1029864911403367},
volume = {15},
year = {2011}
}
@article{Lartillot2007,
abstract = {ABSTRACT We present MIRtoolbox, an integrated set of functions written in Matlab , dedicated to the extraction of musical features from audio files. The design is based on a modular framework: the different algorithms are decomposed into stages, formalized using ... \n},
author = {Lartillot, Olivier and Toiviainen, Petri},
file = {:Users/gmac/mendeley/Lartillot, Toiviainen/Lartillot, Toiviainen - 2007 - A matlab toolbox for musical feature extraction from audio.pdf:pdf},
isbn = {978385403218},
journal = {International Conference on Digital Audio {\ldots}},
number = {Ii},
pages = {1--8},
title = {{A matlab toolbox for musical feature extraction from audio}},
url = {http://dafx.labri.fr/main/papers/p237.pdf%5Cnpapers2://publication/uuid/840762A7-A43B-48F8-A50C-85BFCE586BDE},
year = {2007}
}
@article{Bargh1978,
author = {Bargh, John A and Cohen, Jerry L},
file = {:Users/gmac/mendeley/Bargh, Cohen/Bargh, Cohen - 1978 - Mediating Factors in the Arousal–Performance Relationship.pdf:pdf},
journal = {Motivation and Emotion},
keywords = {audience},
month = {jan},
number = {3},
pages = {243--257},
title = {{Mediating Factors in the Arousal–Performance Relationship}},
url = {papers3://publication/uuid/93E5F8B8-2330-43A4-B77F-729C2E8FD94C},
volume = {2},
year = {1978}
}
@article{Hassabis2007,
abstract = {Amnesic patients have a well established deficit in remembering their past experiences. Surprisingly, however, the question as to whether such patients can imagine new experiences has not been formally addressed to our knowledge. We tested whether a group of amnesic patients with primary damage to the hippocampus bilaterally could construct new imagined experiences in response to short verbal cues that outlined a range of simple commonplace scenarios. Our results revealed that patients were markedly impaired relative to matched control subjects at imagining new experiences. Moreover, we identified a possible source for this deficit. The patients' imagined experiences lacked spatial coherence, consisting instead of fragmented images in the absence of a holistic representation of the environmental setting. The hippocampus, therefore, may make a critical contribution to the creation of new experiences by providing the spatial context into which the disparate elements of an experience can be bound. Given how closely imagined experiences match episodic memories, the absence of this function mediated by the hippocampus, may also fundamentally affect the ability to vividly re-experience the past.},
address = {Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London, 12 Queen Square, London WC1N 3BG, United Kingdom.},
author = {Hassabis, Demis and Kumaran, Dharshan and Vann, Seralynne D and Maguire, Eleanor A},
file = {:Users/gmac/mendeley/Hassabis et al/Hassabis et al. - 2007 - Patients with hippocampal amnesia cannot imagine new experiences.pdf:pdf},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = {jan},
number = {5},
pages = {1726--1731},
title = {{Patients with hippocampal amnesia cannot imagine new experiences.}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0610561104 papers3://publication/doi/10.1073/pnas.0610561104},
volume = {104},
year = {2007}
}
@article{Stupacher2017,
abstract = {Music can be thought of as a dynamic path over time. In most cases, the rhythmic structure of this path, such as specific sequences of strong and weak beats or recurring patterns, allows us to predict what and particularly when sounds are going to happen. Without this ability we would not be able to entrain body movements to music, like we do when we dance. By combining EEG and behavioral measures, the current study provides evidence illustrating the importance of ongoing neural oscillations at beat-related frequencies – i.e., neural entrainment – for tracking and predicting musical rhythms. Participants (13 musicians and 13 non-musicians) listened to drum rhythms that switched from a quadruple rhythm to a 3-over-4 polyrhythm. After a silent period of approximately two to three seconds, participants had to decide whether a target stimulus was presented on time with the triple beat of the polyrhythm, too early, or too late. Results showed that neural oscillations reflected the rhythmic structure of both the simple quadruple rhythm and the more complex polyrhythm with no differences between musicians and non-musicians. During silent periods, the observation of time-frequency plots and more commonly used frequency spectra analyses suggest that beat-related neural oscillations were more pronounced in musicians compared to non-musicians. Neural oscillations during silent periods are not driven by an external input and therefore are thought to reflect top-down controlled endogenous neural entrainment. The functional relevance of endogenous neural entrainment was demonstrated by a positive correlation between the amplitude of task-relevant neural oscillations during silent periods and the number of correctly identified target stimuli. In sum, our findings add to the evidence supporting the neural resonance theory of pulse and meter. Furthermore, they indicate that beat-related top-down controlled neural oscillations can exist without external stimulation and suggest that those endogenous oscillations are strengthened by musical expertise. Finally, this study shows that the analysis of neural oscillations can be a useful tool to assess how we perceive and process complex auditory stimuli such as polyrhythms.},
author = {Stupacher, Jan and Wood, Guilherme and Witte, Matthias},
doi = {10.3389/fnins.2017.00208},
file = {:Users/gmac/mendeley/Stupacher, Wood, Witte/Stupacher, Wood, Witte - 2017 - Neural entrainment to polyrhythms A comparison of musicians and non-musicians.pdf:pdf},
isbn = {1662-453X},
issn = {1662453X},
journal = {Frontiers in Neuroscience},
keywords = {EEG,Entrainment,Music cognition,Musical training,Neural oscillations,Rhythm perception,Steady-state evoked potentials,Temporal prediction},
number = {208},
pages = {1--17},
pmid = {28446864},
title = {{Neural entrainment to polyrhythms: A comparison of musicians and non-musicians}},
volume = {11},
year = {2017}
}
@article{Russell2003a,
abstract = {A flurry of theoretical and empirical work concerning the production of and response to facial and vocal expressions has occurred in the past decade. That emotional expressions express emotions is a tautology but may not be a fact. Debates have centered on universality, the nature of emotion, and the link between emotions and expressions. Modern evolutionary theory is informing more models, emphasizing that expressions are directed at a receiver, that the interests of sender and receiver can conflict, that there are many determinants of sending an expression in addition to emotion, that expressions influence the receiver in a variety of ways, and that the receiver's response is more than simply decoding a message.},
address = {Department of Psychology, Boston College, Chestnut Hill, Massachusetts 02467, USA. james.russell@bc.edu},
author = {Russell, James A and Bachorowski, Jo-Anne and Fern{\'{a}}ndez-Dols, Jos{\'{e}} Miguel},
file = {:Users/gmac/mendeley/Russell, Bachorowski, Fern{\'{a}}ndez-Dols/Russell, Bachorowski, Fern{\'{a}}ndez-Dols - 2003 - Facial and vocal expressions of emotion.pdf:pdf},
journal = {Annual review of psychology},
month = {jan},
number = {1},
pages = {329--349},
title = {{Facial and vocal expressions of emotion.}},
url = {http://www.annualreviews.org/doi/abs/10.1146/annurev.psych.54.101601.145102 papers3://publication/doi/10.1146/annurev.psych.54.101601.145102},
volume = {54},
year = {2003}
}
@article{Senn2017,
abstract = {Microtiming has been assumed to be vital for the experience of groove, but past research presented conflicting results: some studies found that microtiming is irrelevant for groove, others reported that microtiming has a detrimental effect on the groove experience, yet others described circumstances under which microtiming has no negative impact on groove. The three studies in this paper aim at explaining some of these discrepancies by clarifying to what extent listeners' emotional responses to microtiming depend on the distribution of microtiming deviations across instrumental parts (voicing) or other moderating factors like tempo or rhythmic density. The studies use data from two listening experiments involving expert bass and drums duo recordings in swing and funk style. – Study A investigates the effect of fixed time displacements within and between the parts played by different musicians. Listeners (n = 160) reacted negatively to irregularities within the drum track, but the mutual displacement of bass vs. drums did not have an effect. – Study B develops three metrics to calculate the average microtiming magnitude in a musical excerpt. The experiment showed that listeners' (n = 160) emotional responses to expert performance microtiming aligned with each other across styles, when microtiming magnitude was adjusted for rhythmic density. This indicates that rhythmic density is a unifying moderator for listeners' emotional response to microtiming in swing and funk. – Study C used the data from both experiments in order to compare the effect of fixed microtiming displacements (from Study A) with scaled versions of the originally performed microtiming patterns (from Study B). It showed that fixed snare drum displacements irritated expert listeners more than the more flexible deviations occurring in the original performances. This provides some evidence that listeners' emotional response to microtiming deviations not only depends on the magnitude of the deviations, but also on the kind and origin of the microtiming patterns (fixed lab displacements vs. flexible performance microtiming).},
author = {Senn, Olivier and Bullerjahn, Claudia and Kilchenmann, Lorenz and von Georgi, Richard},
doi = {10.3389/fpsyg.2017.01709},
file = {:Users/gmac/mendeley/Senn et al/Senn et al. - 2017 - Rhythmic Density Affects Listeners' Emotional Response to Microtiming.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in Psychology},
keywords = {emotions,groove,microtiming,popular music,rhythmic density},
number = {October},
pages = {1--21},
title = {{Rhythmic Density Affects Listeners' Emotional Response to Microtiming}},
volume = {8},
year = {2017}
}
@article{Fazelpour2015,
abstract = {Current Opinion in Neurobiology, 31 (2015) 223-229. doi:10.1016/j.conb.2014.12.006},
author = {Fazelpour, Sina and Thompson, Evan},
file = {:Users/gmac/mendeley/Fazelpour, Thompson/Fazelpour, Thompson - 2015 - ScienceDirectThe Kantian brain brain dynamics from a neurophenomenological perspective.pdf:pdf},
journal = {Current Opinion in Neurobiology},
month = {apr},
pages = {223--229},
publisher = {Elsevier Ltd},
title = {{ScienceDirectThe Kantian brain: brain dynamics from a neurophenomenological perspective}},
url = {http://dx.doi.org/10.1016/j.conb.2014.12.006 papers3://publication/doi/10.1016/j.conb.2014.12.006},
volume = {31},
year = {2015}
}
@article{Madison2014b,
abstract = {Timing performance becomes less precise for longer intervals, which makes it difficult to achieve simultaneity in synchronisation with a rhythm. The metrical structure of music, characterised by hierarchical levels of binary or ternary subdivisions of time, may function to increase precision by providing additional timing information when the subdivisions are explicit. This hypothesis was tested by comparing synchronisation performance across different numbers of metrical levels conveyed by loudness of sounds, such that the slowest level was loudest and the fastest was softest. Fifteen participants moved their hand with one of 9 inter-beat intervals (IBIs) ranging from 524 to 3125. ms in 4 metrical level (ML) conditions ranging from 1 (one movement for each sound) to 4 (one movement for every 8th sound). The lowest relative variability (SD/IBI. <. 1.5%) was obtained for the 3 longest IBIs (1600-3125. ms) and MLs 3-4, significantly less than the smallest value (4-5% at 524-1024. ms) for any ML 1 condition in which all sounds are identical. Asynchronies were also more negative with higher ML. In conclusion, metrical subdivision provides information that facilitates temporal performance, which suggests an underlying neural multi-level mechanism capable of integrating information across levels. {\textcopyright} 2013 Elsevier B.V.},
author = {Madison, Guy},
doi = {10.1016/j.actpsy.2013.10.002},
file = {:Users/gmac/mendeley/Madison/Madison - 2014 - Sensori-motor synchronisation variability decreases as the number of metrical levels in the stimulus signal increases.pdf:pdf},
issn = {00016918},
journal = {Acta Psychologica},
keywords = {Auditory processing,Metre,Metrical levels,Music,Sensori-motor synchronisation,Timing},
pages = {10--16},
pmid = {24268879},
title = {{Sensori-motor synchronisation variability decreases as the number of metrical levels in the stimulus signal increases}},
volume = {147},
year = {2014}
}
@article{Vuust2014,
abstract = {Musical rhythm, consisting of apparently abstract intervals of accented temporal events, has a remarkable capacity to move our minds and bodies. How does the cognitive system enable our experiences of rhythmically complex music? In this paper, we describe some common forms of rhythmic complexity in music and propose the theory of predictive coding (PC) as a framework for understanding how rhythm and rhythmic complexity are processed in the brain. We also consider why we feel so compelled by rhythmic tension in music. First, we consider theories of rhythm and meter perception, which provide hierarchical and computational approaches to modeling. Second, we present the theory of PC, which posits a hierarchical organization of brain responses reflecting fundamental, survival-related mechanisms associated with predicting future events. According to this theory, perception and learning is manifested through the brain's Bayesian minimization of the error between the input to the brain and the brain's prior expectations. Third, we develop a PC model of musical rhythm, in which rhythm perception is conceptualized as an interaction between what is heard ("rhythm") and the brain's anticipatory structuring of music ("meter"). Finally, we review empirical studies of the neural and behavioral effects of syncopation, polyrhythm and groove, and propose how these studies can be seen as special cases of the PC theory. We argue that musical rhythm exploits the brain's general principles of prediction and propose that pleasure and desire for sensorimotor synchronization from musical rhythm may be a result of such mechanisms.},
author = {Vuust, Peter and Witek, Maria A G},
doi = {10.3389/fpsyg.2014.01111.},
file = {:Users/gmac/mendeley/Vuust, Witek/Vuust, Witek - 2014 - Rhythmic complexity and predictive coding A novel approach to modeling rhythm and meter perception in music.pdf:pdf},
isbn = {1664-1078 (Electronic)\r1664-1078 (Linking)},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Meter,Pleasure,Predictive coding,Rhythm,Rhythmic complexity},
number = {OCT},
pages = {1--14},
pmid = {25324813},
title = {{Rhythmic complexity and predictive coding: A novel approach to modeling rhythm and meter perception in music}},
volume = {5},
year = {2014}
}
@article{Cunningham2001,
abstract = {Objectives: Some children with learning problems (LP) experience speech -sound perception deficits that worsen in background noise. The first goal was to determine whether these impairments are associated with abnormal neurophysiologic representation of ... 
},
author = {Cunningham, J and Nicol, T and Zecker, S G and Bradlow, A and Kraus, Nina},
file = {:Users/gmac/mendeley/Cunningham et al/Cunningham et al. - 2001 - Neurobiologic responses to speech in noise in children with learning problems deficits and strategies for imp.pdf:pdf},
journal = {Clinical Neurophysiology},
month = {jan},
pages = {758--767},
title = {{Neurobiologic responses to speech in noise in children with learning problems: deficits and strategies for improvement}},
url = {http://www.sciencedirect.com/science/article/pii/S1388245701004655 papers3://publication/doi/10.1073/pnas.0901123106},
volume = {112},
year = {2001}
}
@article{Musacchia2008,
annote = {subcortical f0 synchrony correlates with evoked cortical P1-N1 slope and with musicianship},
author = {Musacchia, Gabriella and Strait, Dana and Kraus, Nina},
file = {:Users/gmac/mendeley/Musacchia, Strait, Kraus/Musacchia, Strait, Kraus - 2008 - Relationships between behavior, brainstem and cortical encoding of seen and heard speech in musicians.pdf:pdf},
journal = {Hearing Research},
month = {jul},
number = {1-2},
pages = {34--42},
publisher = {Elsevier B.V.},
title = {{Relationships between behavior, brainstem and cortical encoding of seen and heard speech in musicians and non-musicians}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378595508000798 papers3://publication/doi/10.1016/j.heares.2008.04.013},
volume = {241},
year = {2008}
}
@article{Konvalinka2011,
author = {Konvalinka, Ivana and Xygalatas, Dimitris and Bulbulia, Joseph and Schjodt, Uffe and Jegindo, Else-Marie and Wallot, Sebastian and {Van Orden}, Guy and Roepstorff, Andreas},
file = {:Users/gmac/mendeley/Konvalinka et al/Konvalinka et al. - 2011 - Synchronized arousal between performers and related spectators in a fire-walking ritual.pdf:pdf},
journal = {PNAS},
keywords = {audience},
month = {may},
number = {20},
pages = {8514--8519},
title = {{Synchronized arousal between performers and related spectators in a fire-walking ritual}},
url = {http://www.pnas.org/content/108/20/8514.full.pdf#page=1&view=FitH papers3://publication/doi/10.1073/pnas.1016955108/-/DCSupplemental},
volume = {108},
year = {2011}
}
@article{McDermott2009,
author = {McDermott, Josh H},
file = {:Users/gmac/mendeley/McDermott/McDermott - 2009 - What Can Experiments Reveal About the Origins of Music.pdf:pdf},
journal = {Current Directions in Psychological Science},
month = {jan},
number = {3},
pages = {164--168},
title = {{What Can Experiments Reveal About the Origins of Music?}},
url = {papers3://publication/uuid/4CE7A1ED-CE0A-4488-883C-E05B3AEB4CAD},
volume = {18},
year = {2009}
}
@article{Rezlescu2014,
abstract = {Face recognition is generally thought to rely on different neurocognitive mechanisms than most types of objects, but the specificity of these mechanisms is debated. One account suggests the mechanisms are specific to upright faces, whereas the expertise view proposes the mechanisms operate on objects of high within-class similarity with which an observer has become proficient at rapid individuation. Much of the evidence cited in support of the expertise view comes from laboratory-based training experiments involving computer-generated objects called greebles that are designed to place face-like demands on recognition mechanisms. A fundamental prediction of the expertise hypothesis is that recognition deficits with faces will be accompanied by deficits with objects of expertise. Here we present two cases of acquired prosopagnosia, Herschel and Florence, who violate this prediction: Both show normal performance in a standard greeble training procedure, along with severe deficits on a matched face training procedure. Herschel and Florence also meet several response time criteria that advocates of the expertise view suggest signal successful acquisition of greeble expertise. Furthermore, Herschel's results show that greeble learning can occur without normal functioning of the right fusiform face area, an area proposed to mediate greeble expertise. The marked dissociation between face and greeble expertise undermines greeble-based claims challenging face-specificity and indicates face recognition mechanisms are not necessary for object recognition after laboratory-based training.},
address = {Department of Psychology, Harvard University, Cambridge, MA 02138.},
author = {Rezlescu, Constantin and Barton, Jason J S and Pitcher, David and Duchaine, Bradley},
file = {:Users/gmac/mendeley/Rezlescu et al/Rezlescu et al. - 2014 - Normal acquisition of expertise with greebles in two cases of acquired prosopagnosia.pdf:pdf},
journal = {PNAS},
month = {apr},
number = {14},
pages = {5123--5128},
publisher = {National Acad Sciences},
title = {{Normal acquisition of expertise with greebles in two cases of acquired prosopagnosia.}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1317125111 papers3://publication/doi/10.1073/pnas.1317125111},
volume = {111},
year = {2014}
}
@article{Dalton2003,
abstract = {PURPOSE:The authors investigate the impact of hearing loss on quality of life in a large population of older adults. DESIGN AND METHODS:Data are from the 5-year follow-up Epidemiology of Hearing Loss Study, a population-based longitudinal study of age-related hearing impairment conducted in Beaver Dam, WI. Participants (N = 2,688) were 53-97 years old (mean = 69 years) and 42% were male. Difficulties with communication were assessed by using the Hearing Handicap for the Elderly-Screening version (HHIE-S), with additional questions regarding communication difficulties in specific situations. Health-related quality of life was assessed by using measures of activities of daily living (ADLs), instrumental ADLs (IADLs) and the Short Form 36 Health Survey (SF-36). Hearing loss measured by audiometry was categorized on the basis of the pure-tone average of hearing thresholds at 0.5, 1, 2, and 4 kHz. RESULTS:Of participants, 28% had a mild hearing loss and 24% had a moderate to severe hearing loss. Severity of hearing loss was significantly associated with having a hearing handicap and with self-reported communication difficulties. Individuals with moderate to severe hearing loss were more likely than individuals without hearing loss to have impaired ADLs and IADLs. Severity of hearing loss was significantly associated with decreased function in both the Mental Component Summary score and the Physical Component Summary score of the SF-36 as well as with six of the eight individual domain scores. IMPLICATIONS:Severity of hearing loss is associated with reduced quality of life in older adults.},
address = {Department of Ophthalmology and Visual Sciences, University of Wisconsin, Madison, 53726-2336, USA. dalton@epi.ophth.wisc.edu},
author = {Dalton, Dayna S and Cruickshanks, Karen J and Klein, Barbara E K and Klein, Ronald and Wiley, Terry L and Nondahl, David M},
file = {:Users/gmac/mendeley/Dalton et al/Dalton et al. - 2003 - The impact of hearing loss on quality of life in older adults.pdf:pdf},
journal = {The Gerontologist},
month = {oct},
number = {5},
pages = {661--668},
title = {{The impact of hearing loss on quality of life in older adults.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=14570962&retmode=ref&cmd=prlinks},
volume = {43},
year = {2003}
}
@article{Pearce2006,
abstract = {The implication-realization (IR) theory (Narmour, 1990) posits two cognitive systems involved in the generation of melodic expectations: The first consists of a limited number of symbolic rules that are held to be innate and universal; the second reflects the top-down influences of acquired stylistic knowledge. Aspects of both systems have been implemented as quantitative models in research which has yielded empirical support for both components of the theory (Cuddy & Lunny, 1995; Krumhansl, 1995a, 1995b; Schellenberg, 1996, 1997). However, there is also evidence that the imple- mented bottom-up rules constitute too inflexible a model to account for the influence of the musical experience of the listener and the melodic context in which expectations are elicited. A theory is presented, according to which both bottom-up and top-down descriptions of observed patterns of melodic expectation may be accounted for in terms of the induction of statistical regularities in existing musical repertoires. A computational model that embodies this theory is developed and used to rean- alyze existing experimental data on melodic expectancy. The results of three experiments with increasingly com- plex melodic stimuli demonstrate that this model is capa- ble of accounting for listeners' expectations as well as or better than the two-factor model of Schellenberg (1997).},
author = {Pearce, Marcus T. and Wiggins, Geraint A.},
doi = {10.1525/mp.2006.23.5.377},
file = {:Users/gmac/mendeley/Pearce, Wiggins/Pearce, Wiggins - 2006 - Expectation in Melody The Influence of Context and Learning.pdf:pdf},
isbn = {1064-8011 (Print)},
issn = {0730-7829},
journal = {Music Perception},
month = {jun},
number = {5},
pages = {377--405},
pmid = {18076268},
title = {{Expectation in Melody: The Influence of Context and Learning}},
url = {http://mp.ucpress.edu/cgi/doi/10.1525/mp.2006.23.5.377},
volume = {23},
year = {2006}
}
@book{Lewis2000,
address = {New York: Guilford},
editor = {Lewis, M and Haviland, J},
month = {jan},
title = {{No Title}},
url = {papers3://publication/uuid/3A1E3308-51B6-41C8-9B79-DF1A89B8E617},
year = {2000}
}
@article{Fitch2007,
author = {Fitch, W Tecumseh and Rosenfeld, Andrew J},
file = {:Users/gmac/mendeley/Fitch, Rosenfeld/Fitch, Rosenfeld - 2007 - Perception and Production of Syncopated Rhythms.pdf:pdf},
journal = {Music Perception},
keywords = {rhythm},
month = {sep},
number = {1},
pages = {43--58},
title = {{Perception and Production of Syncopated Rhythms}},
url = {http://www.jstor.org/stable/40286046 papers3://publication/doi/10.1525/mp.2007.25.1.43},
volume = {25},
year = {2007}
}
@book{Russell1997,
address = {Cambridge},
editor = {Russell, James A and Fern{\'{a}}ndez-Dols, Jos{\'{e}} Miguel},
month = {jan},
publisher = {Cambridge University Press},
title = {{No Title}},
url = {papers3://publication/uuid/98BD3AA7-0BCA-4664-A3CE-4B4C0AFF7211},
year = {1997}
}
@incollection{Patel2010,
address = {Houston, TX},
author = {Patel, Aniruddh D},
booktitle = {Emerging Disciplines},
editor = {M, Bailar},
file = {:Users/gmac/mendeley/Patel/Patel - 2010 - Music, biological evolution, and the brain.pdf:pdf},
month = {jun},
pages = {91--144},
publisher = {Rice University Press},
title = {{Music, biological evolution, and the brain.}},
url = {papers3://publication/uuid/1F045C28-EC09-45D7-AB9E-0BCC13DDC7F1},
year = {2010}
}
@article{Madison2011,
author = {Madison, Guy and Gouyon, Fabien and Ull{\'{e}}n, Fredrik and H{\"{o}}rnstr{\"{o}}m, Kalle},
file = {:Users/gmac/mendeley/Madison et al/Madison et al. - 2011 - Modeling the Tendency for Music to Induce Movement in Humans First Correlations With Low-Level Audio Descriptors.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
month = {oct},
number = {5},
pages = {1578--1594},
publisher = {American Psychological Association},
title = {{Modeling the Tendency for Music to Induce Movement in Humans: First Correlations With Low-Level Audio Descriptors Across Music Genres}},
url = {http://dx.doi.org/10.1037/a0024323 papers3://publication/doi/10.1037/a0024323},
volume = {37},
year = {2011}
}
@article{Huron1991,
author = {Huron, David},
file = {:Users/gmac/mendeley/Huron/Huron - 1991 - Book Review Auditory Scene Analysis The Perceptual Organization of Sound.pdf:pdf},
journal = {Psychology of Music},
month = {jan},
pages = {77--84},
title = {{Book Review: Auditory Scene Analysis: The Perceptual Organization of Sound}},
url = {papers3://publication/uuid/76BC8175-13F7-4C6E-B45F-25B1B83C1C55},
volume = {19},
year = {1991}
}
@article{Ragert2013,
abstract = {Expert ensemble musicians produce exquisitely coordinated sounds, but rehearsal is typically required to do so. Ensemble coordination may thus be influenced by the degree to which individuals are familiar with each other's parts. Such familiarity may affect the ability to predict and synchronize with co-performers' actions. Internal models related to action simulation and anticipatory musical imagery may be affected by knowledge of (1) the musical structure of a co-performer's part (e.g., in terms of its rhythm and phrase structure) and/or (2) the co-performer's idiosyncratic playing style (e.g., expressive micro-timing variations). The current study investigated the effects of familiarity on interpersonal coordination in piano duos. Skilled pianists were required to play several duets with different partners. One condition included duets for which co-performers had previously practiced both parts, while another condition included duets for which each performer had practiced only their own part. Each piece was recorded six times without joint rehearsal or visual contact to examine the effects of increasing familiarity. Interpersonal coordination was quantified by measuring asynchronies between pianists' keystroke timing and the correlation of their body (head and torso) movements, which were recorded with a motion capture system. The results suggest that familiarity with a co-performer's part, in the absence of familiarity with their playing style, engenders predictions about micro-timing variations that are based instead upon one's own playing style, leading to a mismatch between predictions and actual events at short timescales. Predictions at longer timescales-that is, those related to musical measures and phrases, and reflected in head movements and body sway-are, however, facilitated by familiarity with the structure of a co-performer's part. These findings point to a dissociation between interpersonal coordination at the level of keystrokes and body movements.},
author = {Ragert, Marie and Schroeder, Tim and Keller, Peter E.},
doi = {10.3389/fpsyg.2013.00368},
file = {:Users/gmac/mendeley/Ragert, Schroeder, Keller/Ragert, Schroeder, Keller - 2013 - Knowing too little or too much The effects of familiarity with a co-performer's part on interpersonal.pdf:pdf},
isbn = {1664-1078},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Body movement,Ensembles,Interpersonal coordination,Music,Sensorimotor synchronization},
number = {JUN},
pages = {1--15},
pmid = {23805116},
title = {{Knowing too little or too much: The effects of familiarity with a co-performer's part on interpersonal coordination in musical ensembles}},
volume = {4},
year = {2013}
}
@article{Teki2016,
abstract = {Time is an important dimension of brain function, but little is yet known about the underlying cognitive principles and neurobiological mechanisms. The field of timing and time perception has witnessed tremendous growth and multidisciplinary interest in the recent years with the advent of modern neuroimaging and neurophysiological approaches. In this article, I used a data mining approach to analyze the timing literature published by a select group of researchers (n = 202) during the period 2000-2015 and highlight important reviews as well as empirical articles that meet the criterion of a minimum of 100 citations. The qualifying articles (n = 150) are listed in a table along with key details such as number of citations, names of authors, year and journal of publication as well as a short summary of the findings of each study. The results of such a data-driven approach to literature review not only serve as a useful resource to any researcher interested in timing, but also provides a means to evaluate key papers that have significantly influenced the field and summarize recent progress and popular research trends in the field. Additionally, such analyses provides food for thought about future scientific directions and raises important questions about improving organizational structures to boost open science and progress in the field. I discuss exciting avenues for future research that have the potential to significantly advance our understanding of the neurobiology of timing, and propose the establishment of a new society to promote open science and collaborative work within the highly diverse and multidisciplinary community of researchers in the field of timing and time perception.},
author = {Teki, Sundeep},
doi = {10.3389/fnins.2016.00330},
file = {:Users/gmac/mendeley/Teki/Teki - 2016 - A citation-based analysis and review of significant papers on timing and time perception.pdf:pdf},
isbn = {1662-4548},
issn = {1662453X},
journal = {Frontiers in Neuroscience},
keywords = {Bibliometrics,Citations,Interval timing,Music perception,Rhythm perception,Temporal processing,Time perception,Timing},
number = {JUL},
pmid = {27471445},
title = {{A citation-based analysis and review of significant papers on timing and time perception}},
volume = {10},
year = {2016}
}
@article{Boucsein2012,
abstract = {Electrodermal activity isone of the most frequently used psychophysiological evaluations in psychology research. Based on the 1992 edition of this work Electrodermal Activity covers advances in the field since the first publication in 1992. The current volume includes updated information on brain imaging techniques such as PET and fMRI, which provide further insight into the brain mechanisms underlying EDA. In addition, this volume is able to describe more reliably hypotheses that have been successfully tested since the first publication.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Boucsein, Wolfram},
doi = {10.1007/978-1-4614-1126-0},
eprint = {arXiv:1011.1669v3},
file = {:Users/gmac/mendeley/Boucsein/Boucsein - 2012 - Electrodermal Activity(2).pdf:pdf;:Users/gmac/mendeley/Boucsein/Boucsein - 2012 - Electrodermal Activity(3).pdf:pdf;:Users/gmac/mendeley/Boucsein/Boucsein - 2012 - Electrodermal Activity(4).pdf:pdf;:Users/gmac/mendeley/Boucsein/Boucsein - 2012 - Electrodermal Activity(5).pdf:pdf;:Users/gmac/mendeley/Boucsein/Boucsein - 2012 - Electrodermal Activity.pdf:pdf},
isbn = {978-1-4614-1125-3},
issn = {09242708},
journal = {Electrodermal Activity},
number = {1973},
pages = {3--67},
pmid = {15991970},
title = {{Electrodermal Activity}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Electrodermal+Activity#0%5Cnhttp://link.springer.com/10.1007/978-1-4614-1126-0},
volume = {3},
year = {2012}
}
@article{Keidser2011,
abstract = {NAL-NL2 is the second generation of prescription procedures from The National Acoustic Laboratories (NAL) for fitting wide dynamic range compression (WDRC) instruments. Like its predecessor NALNL1 (Dillon, 1999), NAL-NL2 aims at making speech intelligible and overall loudness comfortable. This aim is mainly driven by a belief that these factors are most important for hearing aid users, but is also driven by the fact that less information is available about how to adjust gain to optimise other parameters that affect prescription such as localisation, tonal quality, detection of environmental sounds, and naturalness. In both formulas, the objective is achieved by combining a speech intelligibility model and a loudness model in an adaptive computer- controlled optimisation process. Adjustments have further been made to the theoretical component of NAL-NL2 that are directed by empirical data collected during the past decade with NAL-NL1. In this paper, the data underlying NAL-NL2 and the derivation procedure are presented, and the main differences from NAL-NL1 are outlined.},
author = {Keidser, G. and Dillon, H.R. and Flax, M. and Ching, T. and Brewer, S.},
doi = {10.4081/audiores.2011.e24},
file = {:Users/gmac/mendeley/Keidser et al/Keidser et al. - 2011 - The NAL-NL2 prescription procedure.pdf:pdf},
issn = {2039-4330},
journal = {Audiology Research},
keywords = {1,2011,audiology research 2011,copyright g,e24,hearing aids,italy,keidser et al,licensee pagepress,prescription procedures},
number = {1S},
pages = {1--3},
pmid = {26557309},
title = {{The NAL-NL2 prescription procedure}},
volume = {1},
year = {2011}
}
@incollection{Juslin2005,
author = {Juslin, Patrik N},
booktitle = {Musical Communication},
month = {jan},
pages = {85--115},
publisher = {Oxford University Press},
title = {{From mimesis to catharsis: expression, perception, and induction of emotion in music BT  - Musical Communication}},
url = {papers3://publication/uuid/794F6551-2E30-4BC1-8F92-3DD5E1BFD2F7},
year = {2005}
}
@article{Lindsey2011,
abstract = {Background: Learned associations between depressive behavior and environmental stimuli signaling low light availability and winter season may play a role in seasonal affective disorder (SAD). The purpose of this study was to determine whether light and season environmental cues elicit emotional responses that are distinct in individuals with SAD. Methods: Twenty-four currently depressed SAD participants were compared to 24 demographically-matched controls with no depression history on emotional responses to outdoor scenes captured under two light intensity (i.e., clear, sunny vs. overcast sky) and three season (i.e., summer with green leaves, fall with autumn foliage, and winter with bare trees) conditions. Emotion measures included surface facial electromyography (EMG) activity in the corrugator supercilii and zygomaticus major muscle regions, skin conductance, and self-reported mood state on the Profile of Mood States Depression-Dejection Subscale. Results: Light intensity was a more salient cue than season in determining emotional reactions among SAD participants. Relative to controls, SAD participants displayed more corrugator activity, more frequent significant skin conductance responses (SCR), greater SCR magnitude, and more self-reported depressed mood in response to overcast stimuli and less corrugator activity, lower SCR magnitude, and less self-reported depressed mood in response to sunny stimuli. Limitations: Study limitations include the single, as opposed to repeated, assessment and the lack of a nonseasonal depression group. Conclusions: These findings suggest that extreme emotional reactivity to light-relevant stimuli may be a correlate of winter depression; and future work should examine its potential onset or maintenance significance. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Lindsey, Kathryn Tierney and Rohan, Kelly J. and Roecklein, Kathryn A. and Mahon, Jennifer N.},
doi = {10.1016/j.jad.2011.04.016},
file = {:Users/gmac/mendeley/Lindsey et al/Lindsey et al. - 2011 - Surface facial electromyography, skin conductance, and self-reported emotional responses to light- and season-re.pdf:pdf},
isbn = {1573-2517},
issn = {01650327},
journal = {Journal of Affective Disorders},
keywords = {Conditioning,Depression,Psychophysiology,Seasonal affective disorder,Surface facial EMG},
number = {1-2},
pages = {311--319},
pmid = {21600661},
publisher = {Elsevier B.V.},
title = {{Surface facial electromyography, skin conductance, and self-reported emotional responses to light- and season-relevant stimuli in seasonal affective disorder}},
url = {http://dx.doi.org/10.1016/j.jad.2011.04.016},
volume = {133},
year = {2011}
}
@article{Large1999,
author = {Large, Edward W and Jones, Mari Riess},
file = {:Users/gmac/mendeley/Large, Jones/Large, Jones - 1999 - The Dynamics of Attending How People Track Time-Varying Events.pdf:pdf},
journal = {Psychological Review},
month = {jan},
number = {1},
pages = {119--159},
title = {{The Dynamics of Attending: How People Track Time-Varying Events}},
url = {papers3://publication/uuid/FD30FF05-EBFB-4498-A60D-A0E5CBF6560E},
volume = {106},
year = {1999}
}
@article{Micheyl2006,
author = {Micheyl, Christophe and Delhommeau, Karine and Perrot, Xavier and Oxenham, Andrew J},
file = {:Users/gmac/mendeley/Micheyl et al/Micheyl et al. - 2006 - Influence of musical and psychoacoustical training on pitch discrimination.pdf:pdf},
journal = {Hearing Research},
month = {sep},
number = {1-2},
pages = {36--47},
publisher = {Elsevier B.V.},
title = {{Influence of musical and psychoacoustical training on pitch discrimination}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S037859550600133X papers3://publication/doi/10.1016/j.heares.2006.05.004},
volume = {219},
year = {2006}
}
@article{Hove2014b,
abstract = {The auditory environment typically contains several sound sources that overlap in time, and the auditory system parses the complex sound wave into streams or voices that represent the various sound sources. Music is also often polyphonic. Interestingly, the main melody (spectral/pitch information) is most often carried by the highest-pitched voice, and the rhythm (temporal foundation) is most often laid down by the lowest-pitched voice. Previous work using electroencephalography (EEG) demonstrated that the auditory cortex encodes pitch more robustly in the higher of two simultaneous tones or melodies, and modeling work indicated that this high-voice superiority for pitch originates in the sensory periphery. Here, we investigated the neural basis of carrying rhythmic timing information in lower-pitched voices. We pre- sented simultaneous high-pitched and low-pitched tones in an isochronous stream and occasionally presented either the higher or the lower tone 50 ms earlier than expected, while leaving the other tone at the expected time. EEG recordings revealed that mismatch negativity responses were larger for timing deviants of the lower tones, indicating better timing encoding for lower- pitched compared with higher-pitch tones at the level of auditory cortex. A behavioral motor task revealed that tapping synchroni- zation was more influenced by the lower-pitched stream. Results from a biologically plausible model of the auditory periphery suggest that nonlinear cochlear dynamics contribute to the observed effect. The low-voice superiority effect for encoding timing explains the widespread musical practice of carrying rhythm in bass-ranged instruments and complements previously established high-voice superiority effects for pitch and melody.},
author = {Hove, Michael J and Marie, C. and Bruce, I. C. and Trainor, Laurel J},
doi = {10.1073/pnas.1402039111},
file = {:Users/gmac/mendeley/Hove et al/Hove et al. - 2014 - Superior time perception for lower musical pitch explains why bass-ranged instruments lay down musical rhythms.pdf:pdf},
isbn = {1091-6490 (Electronic)\r0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {auditory scene analysis,beat,rhythmic pulse,temporal perception},
number = {28},
pages = {10383--10388},
pmid = {24982142},
title = {{Superior time perception for lower musical pitch explains why bass-ranged instruments lay down musical rhythms}},
volume = {111},
year = {2014}
}
@article{Musacchia2014,
abstract = {Hearing Research, 308 (2014) 50-59. doi:10.1016/j.heares.2013.09.017},
author = {Musacchia, Gabriella and Large, Edward W and Schroeder, Charles E},
file = {:Users/gmac/mendeley/Musacchia, Large, Schroeder/Musacchia, Large, Schroeder - 2014 - Thalamocortical mechanisms for integrating musical tone and rhythm.pdf:pdf},
journal = {Hearing Research},
month = {feb},
number = {C},
pages = {50--59},
publisher = {Elsevier B.V.},
title = {{Thalamocortical mechanisms for integrating musical tone and rhythm}},
url = {http://dx.doi.org/10.1016/j.heares.2013.09.017 papers3://publication/doi/10.1016/j.heares.2013.09.017},
volume = {308},
year = {2014}
}
@article{Bidelman2011,
author = {Bidelman, Gavin M and Krishnan, Ananthanarayan},
file = {:Users/gmac/mendeley/Bidelman, Krishnan/Bidelman, Krishnan - 2011 - Brainstem correlates of behavioral and compositional preferences of musical harmony.pdf:pdf},
month = {mar},
number = {5},
pages = {212--216},
title = {{Brainstem correlates of behavioral and compositional preferences of musical harmony}},
url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00001756-201103300-00004},
volume = {22},
year = {2011}
}
@inproceedings{Stober2014,
abstract = {Electroencephalography (EEG) recordings of rhythm percep- tionmight contain enough information to distinguish different rhythm types/genres or even identify the rhythms themselves. In this paper, we present first classification results using deep learning techniques on EEG data recorded within a rhythm perception study in Kigali, Rwanda. We tested 13 adults, mean age 21, who performed three behavioral tasks using rhythmic tone sequences derived from either East African orWestern music. For the EEG testing, 24 rhythms – half EastAfrican and halfWesternwith identical tempo and based on a 2-bar 12/8 scheme – were each repeated for 32 sec- onds. During presentation, the participants' brain waves were recorded via 14 EEG channels. We applied stacked denois- ing autoencoders and convolutional neural networks on the collected data to distinguish African andWestern rhythms on a group and individual participant level. Furthermore, we in- vestigated how far these techniques can be used to recognize the individual rhythms.},
author = {Stober, Sebastian and Cameron, Daniel J and Grahn, Jessica A},
booktitle = {15th International Society for Music Information Retrieval Conference},
file = {:Users/gmac/mendeley/Stober, Cameron, Grahn/Stober, Cameron, Grahn - 2014 - Classifying EEG recordings of rhythm perception.pdf:pdf},
pages = {649--654},
title = {{Classifying EEG recordings of rhythm perception}},
url = {https://www.researchgate.net/profile/Sebastian_Stober/publication/269875055_Classifying_EEG_Recordings_of_Rhythm_Perception/links/549debb70cf2fedbc3119ada.pdf http://wwwiti.cs.uni-magdeburg.de/$\sim$stober/publ/ismir2014.pdf},
year = {2014}
}
@article{Stupacher2016,
abstract = {The experience of groove is associated with the urge to move to a musical rhythm. Here we focus on the relevance of audio features, obtained using music information retrieval (MIR) tools, for explaining the perception of groove and music-related movement. In Study 1 we extracted audio features from clips of real music previously rated on perceived groove. Measures of variability, such as the variance of the audio signal's RMS curve and spectral flux (particularly in low frequencies), predicted groove ratings. Additionally, we dissociated two forms of event density, showing that an algorithm that emphasizes variability between beats predicted groove ratings better. In Study 2 we manipulated RMS levels and groove category (low, mid, and high groove) to confirm that perceived groove is not a function of loudness. In Study 3 we utilized novel music clips that manipulated the frequency of bass and bass drum (low vs. high) and attack time (short vs. long). Groove ratings and tapping velocities tended to be higher and tapping variability tended to be lower when the bass instruments had lower frequencies. The present findings emphasize the multifaceted nature of groove by linking audio and musical qualities to subjective experience and motor behavior.},
author = {Stupacher, Jan and Hove, Michael J and Janata, Petr},
file = {:Users/gmac/mendeley/Stupacher, Hove, Janata/Stupacher, Hove, Janata - 2016 - Audio features underlying perceived groove and sensorimotor synchronization in music.pdf:pdf},
journal = {Music Perception},
keywords = {entrainment,experience of groove,information retrieval,loudness,music,variability},
number = {5},
pages = {571--589},
title = {{Audio features underlying perceived groove and sensorimotor synchronization in music}},
volume = {33},
year = {2016}
}
@article{Lartillot2008a,
abstract = {Pulse clarity is considered as a high-level musical dimension that conveys how easily in a given musical piece, or a particular moment during that piece, listeners can perceive the underlying rhythmic or metrical pulsation. The objective of this study is to es- tablish a composite model explaining pulse clarity judgments from the analysis of audio recordings, decomposed into a set of indepen- dent factors related to various musical dimensions. To evaluate the pulse clarity model, 25 participants have rated the pulse clarity of one hundred excerpts from movie soundtracks. The mapping be- tween the model predictions and the ratings was carried out via regressions. More than three fourth of listeners rating variance can be explained with a combination of periodicity-based and non- periodicity-based factors.},
author = {Lartillot, Olivier and Eerola, Tuomas and Toiviainen, Petri and Fornari, Jose},
file = {:Users/gmac/mendeley/Lartillot et al/Lartillot et al. - 2008 - Multi-feature modeling of pulse clarity Design, validation, and optimization.pdf:pdf},
isbn = {9780615248493},
journal = {ISMIR 2008},
pages = {521--526},
title = {{Multi-feature modeling of pulse clarity: Design, validation, and optimization}},
url = {http://ismir2008.ismir.net/papers/ISMIR2008_145.pdf},
year = {2008}
}
@article{Lang1993,
abstract = {Colored photographic pictures that varied widely across the affective dimensions of valence (pleasant-unpleasant) and arousal (excited-calm) were each viewed for a 6-s period while facial electromyographic (zygomatic and corrugator muscle activity) and visceral (heart rate and skin conductance) reactions were measured. Judgments relating to pleasure, arousal, interest, and emotional state were measured, as was choice viewing time. Significant covariation was obtained between (a) facial expression and affective valence judgments and (b) skin conductance magnitude and arousal ratings. Interest ratings and viewing time were also associated with arousal. Although differences due to the subject's gender and cognitive style were obtained, affective responses were largely independent of the personality factors investigated. Response specificity, particularly facial expressiveness, supported the view that specific affects have unique patterns of reactivity. The consistency of the dimensional relationships between evaluative judgments (i.e., pleasure and arousal) and physiological response, however, emphasizes that emotion is fundamentally organized by these motivational parameters.},
author = {Lang, Peter J and Greenwald, M K and Bradley, M M and Hamm, a O},
doi = {10.1111/j.1469-8986.1993.tb03352.x},
file = {:Users/gmac/mendeley/Lang et al/Lang et al. - 1993 - Looking at pictures Affective, facial, visceral, and behavioral reactions.pdf:pdf},
isbn = {0048-5772},
issn = {0048-5772},
journal = {Psychophysiology},
number = {3},
pages = {261--273},
pmid = {8497555},
title = {{Looking at pictures: Affective, facial, visceral, and behavioral reactions.}},
volume = {30},
year = {1993}
}
@article{Maidhof2013,
abstract = {Performing a piece of music involves the interplay of several cognitive and motor processes and requires extensive training to achieve a high skill level.},
author = {Maidhof, Clemens and Pitkaniemi, Anni and Tervaniemi, Mari},
file = {:Users/gmac/mendeley/Maidhof, Pitkaniemi, Tervaniemi/Maidhof, Pitkaniemi, Tervaniemi - 2013 - Predictive error detection in pianists a combined ERP and motion capture study.pdf:pdf},
journal = {Frontiers in Human Neuroscience},
month = {sep},
pages = {1--14},
title = {{Predictive error detection in pianists: a combined ERP and motion capture study}},
url = {papers3://publication/doi/10.3389/fnhum.2013.00587/abstract},
volume = {7},
year = {2013}
}
@article{Flaig2014,
abstract = {Is there something special about the way music communicates feelings? Theorists since Meyer (1956) have attempted to explain how music could stimulate varied and subtle affective experiences by violating learned expectancies, or by mimicking other forms of social interaction.},
author = {Flaig, Nicole K and Large, Edward W},
file = {:Users/gmac/mendeley/Flaig, Large/Flaig, Large - 2014 - Dynamic musical communication of core affect.pdf:pdf},
journal = {Frontiers in Psychology},
month = {mar},
pages = {1--12},
title = {{Dynamic musical communication of core affect}},
url = {papers3://publication/doi/10.3389/fpsyg.2014.00072/abstract},
volume = {5},
year = {2014}
}
@article{Benavides-Varela2012,
author = {Benavides-Varela, S and Hochmann, J R and Macagno, Francesco and Nespor, Marina and Mehler, Jacques},
file = {:Users/gmac/mendeley/Benavides-Varela et al/Benavides-Varela et al. - 2012 - Newborn's brain activity signals the origin of word memories.pdf:pdf},
journal = {Proceedings of the {\ldots}},
month = {oct},
pages = {17908--17913},
title = {{Newborn's brain activity signals the origin of word memories}},
url = {http://www.pnas.org/content/109/44/17908.short papers3://publication/doi/10.1073/pnas.1205413109/-/DCSupplemental},
volume = {109},
year = {2012}
}
@incollection{Davidson1994,
address = {New York},
author = {Davidson, Richard J},
booktitle = {The Nature of Emotion: Fundamental Questions},
editor = {Ekman, Paul and Davidson, Richard J},
pages = {51--55},
publisher = {Oxford University Press},
title = {{On Emotion, Mood, and Related Affective Constructs}},
year = {1994}
}
@article{Fujioka2012b,
author = {Fujioka, Takako and Ween, Jon Erik and Jamali, Shahab and Stuss, Donald T and Ross, Bernhard},
file = {:Users/gmac/mendeley/Fujioka et al/Fujioka et al. - 2012 - Changes in neuromagnetic beta-band oscillation after music-supported stroke rehabilitation.pdf:pdf},
journal = {Annals of the New York Academy of Sciences},
month = {apr},
pages = {294--304},
title = {{Changes in neuromagnetic beta-band oscillation after music-supported stroke rehabilitation}},
volume = {1252},
year = {2012}
}
@article{Chen2008a,
annote = {Using functional magnetic resonance imaging (fMRI), Chen, Penhune, and Zatorre {*Chen:2008ui} found greater recruitment of prefrontal areas in musicians compared to nonmusicians when tapping along to increasingly complex rhythms. They reason that prefrontal mediation of working memory underlies musicians' superior ability to deconstruct and synchronize with complex rhythms.},
author = {Chen, Joyce L and Penhune, Virginia B and Zatorre, Robert J},
file = {:Users/gmac/mendeley/Chen, Penhune, Zatorre/Chen, Penhune, Zatorre - 2008 - Moving on Time Brain Network for Auditory–Motor Synchronization is Modulated by Rhythm Complexity and.pdf:pdf},
journal = {Journal of Cognitive Neuroscience},
month = {jan},
number = {2},
pages = {226--239},
title = {{Moving on Time: Brain Network for Auditory–Motor Synchronization is Modulated by Rhythm Complexity and Musical Training}},
url = {papers3://publication/uuid/02D7FBE8-0EFD-4D98-9A28-27AE65F60E41},
volume = {20},
year = {2008}
}
@article{Grassi2009,
author = {Grassi, Massimo and Soranzo, Alessandro},
file = {:Users/gmac/mendeley/Grassi, Soranzo/Grassi, Soranzo - 2009 - MLP A MATLAB toolbox for rapid and reliable auditory threshold estimation.pdf:pdf},
journal = {Behavior Research Methods},
month = {feb},
number = {1},
pages = {20--28},
title = {{MLP: A MATLAB toolbox for rapid and reliable auditory threshold estimation}},
url = {http://www.springerlink.com/index/10.3758/BRM.41.1.20 papers3://publication/doi/10.3758/BRM.41.1.20},
volume = {41},
year = {2009}
}
@article{Hobson2016,
abstract = {Mu suppression has been proposed as a signature of the activity of the human mirror neuron system (MNS). However the mu frequency band (8–13 Hz) overlaps with the alpha frequency band, which is sensitive to attentional fluctuation, and thus mu suppression could potentially be confounded by changes in attentional engagement. The specific baseline against which mu suppression is assessed may be crucial, yet there is little consistency in how this is defined. We examined mu suppression in 61 typical adults, the largest mu suppression study so far conducted. We compared different methods of baselining, and examined activity at central and occipital electrodes, to both biological (hands) and non-biological (kaleidoscope) moving stimuli, to investigate the involvement of attention and alpha activity in mu suppression. We also examined changes in beta power, another candidate index of MNS engagement. We observed strong mu suppression restricted to central electrodes when participants performed hand movements, demonstrating that mu is indeed responsive to the activity of the motor cortex. However, when we looked for a similar signature of mu suppression to passively observed stimuli, the baselining method proved to be crucial. Selective suppression for biological versus non-biological stimuli was seen at central electrodes only when we used a within-trial baseline based on a static stimulus: this method greatly reduced trial-by-trial variation in the suppression measure compared with baselines based on blank trials presented in separate blocks. Even in this optimal condition, 16–21% of participants showed no mu suppression. Changes in beta power also did not match our predicted pattern for MNS engagement, and did not seem to offer a better measure than mu. Our conclusions are in contrast to those of a recent meta-analysis, which concluded that mu suppression is a valid means to examine mirror neuron activity. We argue that mu suppression can be used to index the human MNS, but the effect is weak and unreliable and easily confounded with alpha suppression.},
author = {Hobson, Hannah M. and Bishop, Dorothy V.M.},
doi = {10.1016/j.cortex.2016.03.019},
file = {:Users/gmac/mendeley/Hobson, Bishop/Hobson, Bishop - 2016 - Mu suppression – A good measure of the human mirror neuron system.pdf:pdf},
issn = {00109452},
journal = {Cortex},
pages = {1--21},
publisher = {Elsevier Ltd},
title = {{Mu suppression – A good measure of the human mirror neuron system?}},
url = {http://dx.doi.org/10.1016/j.cortex.2016.03.019},
year = {2016}
}
@article{Rauschecker2000,
abstract = {The functional specialization and hierarchical organization of multiple areas in rhesus monkey auditory cortex were examined with various types of complex sounds. Neurons in the lateral belt areas of the superior temporal gyrus were tuned to the best center frequency and bandwidth of band-passed noise bursts. They were also selective for the rate and direction of linear frequency modulated sweeps. Many neurons showed a preference for a limited number of species-specific vocalizations ("monkey calls"). These response selectivities can be explained by nonlinear spectral and temporal integration mechanisms. In a separate series of experiments, monkey calls were presented at different spatial locations, and the tuning of lateral belt neurons to monkey calls and spatial location was determined. Of the three belt areas the anterolateral area shows the highest degree of specificity for monkey calls, whereas neurons in the caudolateral area display the greatest spatial selectivity. We conclude that the cortical auditory system of primates is divided into at least two processing streams, a spatial stream that originates in the caudal part of the superior temporal gyrus and projects to the parietal cortex, and a pattern or object stream originating in the more anterior portions of the lateral belt. A similar division of labor can be seen in human auditory cortex by using functional neuroimaging.},
author = {Rauschecker, J P and Tian, B},
doi = {10.1073/pnas.97.22.11800},
file = {:Users/gmac/mendeley/Rauschecker, Tian/Rauschecker, Tian - 2000 - Mechanisms and streams for processing of what and where in auditory cortex.pdf:pdf},
isbn = {0027-8424},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Acoustic Stimulation,Animal Communication,Animals,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Humans,Macaca mulatta,Macaca mulatta: physiology},
number = {22},
pages = {11800--6},
pmid = {11050212},
title = {{Mechanisms and streams for processing of "what" and "where" in auditory cortex.}},
url = {http://www.pnas.org/content/97/22/11800.full},
volume = {97},
year = {2000}
}
@article{FernandezdelOlmo2006,
author = {{Fernandez del Olmo}, M and Arias, P and Furio, M C and Pozo, M A and Cudeiro, J},
file = {:Users/gmac/mendeley/Fernandez del Olmo et al/Fernandez del Olmo et al. - 2006 - Evaluation of the effect of training using auditory stimulation on rhythmic movement in Parkinsonia.pdf:pdf},
journal = {Parkinsonism & Related Disorders},
month = {apr},
number = {3},
pages = {155--164},
title = {{Evaluation of the effect of training using auditory stimulation on rhythmic movement in Parkinsonian patients—a combined motor and [18F]-FDG PET study}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1353802005002269 papers3://publication/doi/10.1016/j.parkreldis.2005.11.002},
volume = {12},
year = {2006}
}
@article{Hoeschele2012,
author = {Hoeschele, Marisa and Weisman, Ronald G and Sturdy, Christopher B},
file = {:Users/gmac/mendeley/Hoeschele, Weisman, Sturdy/Hoeschele, Weisman, Sturdy - 2012 - Pitch chroma discrimination, generalization, and transfer tests of octave equivalence in humans.pdf:pdf},
journal = {Attention, Perception, & Psychophysics},
month = {sep},
number = {8},
pages = {1742--1760},
title = {{Pitch chroma discrimination, generalization, and transfer tests of octave equivalence in humans}},
url = {http://www.springerlink.com/index/10.3758/s13414-012-0364-2 papers3://publication/doi/10.3758/s13414-012-0364-2},
volume = {74},
year = {2012}
}
@incollection{Ellsworth2003,
address = {New York, NY},
author = {Ellsworth, Phoebe C and Scherer, Klaus R},
booktitle = {Handbook of Affective Sciences},
editor = {Davidson, Richard J and Scherer, Klaus R and Goldsmith, H Hill},
file = {:Users/gmac/mendeley/Ellsworth, Scherer/Ellsworth, Scherer - 2003 - Appraisal Processes in Emotion.pdf:pdf},
month = {jan},
pages = {572--595},
title = {{Appraisal Processes in Emotion}},
url = {papers3://publication/uuid/D2D76917-94E9-4763-9432-90242CC4C63B},
year = {2003}
}
@article{Bell1995,
abstract = {We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech ...},
archivePrefix = {arXiv},
arxivId = {arXiv:1511.06440v1},
author = {Bell, Anthony J and Sejnowski, Terrence J},
doi = {10.1162/neco.1995.7.6.1129},
eprint = {arXiv:1511.06440v1},
file = {:Users/gmac/mendeley/Bell, Sejnowski/Bell, Sejnowski - 1995 - An Information-Maximization Approach to Blind Separation and Blind Deconvolution.pdf:pdf},
isbn = {0899-7667 (Print) 0899-7667 (Linking)},
issn = {0899-7667},
journal = {Neural Computation},
number = {6},
pages = {1129--1159},
pmid = {7584893},
title = {{An Information-Maximization Approach to Blind Separation and Blind Deconvolution}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1995.7.6.1129#.VbJaKPmqqko},
volume = {7},
year = {1995}
}
@book{Stumpf2012,
author = {Stumpf, Carl},
editor = {Trippett, David},
isbn = {9780199695737},
month = {jan},
publisher = {Oxford Scholarship Online},
title = {{No Title}},
url = {papers3://publication/doi/10.1093/acprof:oso/9780199695737.001.0001},
year = {2012}
}
@article{Trainor2009,
author = {Trainor, Laurel J and Gao, Xiaoqing and Lei, Jing-jiang and Lehtovaara, Karen and Harris, Laurence R},
doi = {doi:10.1016/j.cortex.2007.10.014},
file = {:Users/gmac/mendeley/Trainor et al/Trainor et al. - 2009 - The primal role of the vestibular system in determining musical rhythm.pdf:pdf},
journal = {Cortex},
number = {1},
pages = {35--43},
title = {{The primal role of the vestibular system in determining musical rhythm}},
volume = {45},
year = {2009}
}
@article{Bigdely-Shamlo2015,
abstract = {The technology to collect brain imaging and physiological measures has become portable and ubiquitous, opening the possibility of large-scale analysis of real-world human imaging.The technology to collect brain imaging and physiological measures has become portable and ubiquitous, opening the possibility of large-scale analysis of real-world human imaging.},
author = {Bigdely-Shamlo, Nima and Mullen, Tim and Kothe, Christian and Su, Kyung-Min and Robbins, Kay A},
file = {:Users/gmac/mendeley/Bigdely-Shamlo et al/Bigdely-Shamlo et al. - 2015 - The PREP pipeline standardized preprocessing for large-scale EEG analysis.pdf:pdf},
journal = {Frontiers in Neuroinformatics},
month = {jun},
pages = {1--20},
title = {{The PREP pipeline: standardized preprocessing for large-scale EEG analysis}},
volume = {9},
year = {2015}
}
@inproceedings{Henry2014a,
author = {Henry, Molly J and Herrmann, B and Obleser, Jonas},
booktitle = {Proceedings of the {\ldots}},
file = {:Users/gmac/mendeley/Henry, Herrmann, Obleser/Henry, Herrmann, Obleser - 2014 - Entrained neural oscillations in multiple frequency bands comodulate behavior.pdf:pdf},
month = {jan},
title = {{Entrained neural oscillations in multiple frequency bands comodulate behavior}},
url = {http://www.pnas.org/content/111/41/14935.short papers3://publication/doi/10.1073/pnas.1408741111},
year = {2014}
}
@article{Ruiz2009a,
annote = {- ELAN (early left anterior negativity): BA44, 100-350ms, taken to reflect initial syntactic structure building
- ERAN: right frontal, 200ms after onset of irregular chords, elicited in absence of direct attention, in musicians and non-musicians
- MMN: weird physical (sensory) things about a stimulus (ERAN is more learned things syntax)

Methods:
- 1-4-2-5 chord context, 1 (regular) or 2 (irregular) final chord
wavelet based TFR analysis [Tallon-Baudry et al., 1997]
- Evoked vs Induced: (i) evoked response or response phased-locked to the stimulus onset, and (ii) induced response or response not phased-locked to the stimulus onset [Galambos, 1992]. The former response was estimated by applying the wavelet transform to the averaged ERP profile, thus keeping the phase-locked information across epochs. The joint response (evoked + induced) was obtained by applying the wavelet transform to each trial followed by averaging. Thus, the induced activity was computed by subtracting the evoked response from the joint response (p.1210)
- phase coherence: use (non-common) non-mastoid ref (p.1212, ref analysis)


- ERAN disappeared after 8 Hz low-pass filtering
- processing regular chords elicits more phase-locked and non-phase locked activity in delta and theta compared to irregular
- in 100-300 ms time window comparing peaks:
-- no diffs for total spectral power
-- evoked theta latencies: reg 203 ms, irreg 189 ms
-- evoked delta latencies: reg 237 ms, irreg 260 ms

- alpha (8-10 Hz) phase desynchronization:
-- 185-250 ms after irregular chords
-- phase locking between right FC/F and left TP reduced
-- right FC/F also elicited strongest decrease in delta and larger amplitude ERAN
- alpha indicates top-down processing? aka fulfilled predictions; more alpha desynchronization during irregularities (bottom-up)

- decoupling of right anterior and left temporo-parietal reflects mismatch of long term memory and working memory},
author = {Ruiz, Mar{\'{i}}a Herrojo and Koelsch, Stefan and Bhattacharya, Joydeep},
file = {:Users/gmac/mendeley/Ruiz, Koelsch, Bhattacharya/Ruiz, Koelsch, Bhattacharya - 2009 - Decrease in early right alpha band phase synchronization and late gamma band oscillations in proces.pdf:pdf},
journal = {Human Brain Mapping},
keywords = {alpha,gamma},
month = {apr},
number = {4},
pages = {1207--1225},
title = {{Decrease in early right alpha band phase synchronization and late gamma band oscillations in processing syntax in music}},
volume = {30},
year = {2009}
}
@article{Russell1985,
abstract = {Structural models of emotion represent the fact that emotions are perceived as systematically interrelated. These interrelations may reveal a basic property of the human conception of emotions, or they may represent an artifact that is due to semantic relations learned along with the emotion lexicon. The 1st alternative was supported by results from a series of scalings of 20 emotional facial expressions, results that could not easily be attributed to word similarity. Similarity data on the facial expressions were obtained from 30 undergraduates and 42 4–5 yr olds. For both groups, similarity was measured without the use of emotion labels by asking Ss to group together people who appear to feel alike. The structure of emotions obtained from both children and adults was as predicted: a roughly circular order in a 2-dimensional space, the axes of which could be interpreted as pleasure–displeasure and arousal–sleepiness. The form and meaning of this structure was supported through 2 additional scalings of the facial expressions with adults: a multidimensional scaling based on direct ratings of similarity–dissimilarity and unidimensional scalings on the pleasure–displeasure and arousal–sleepiness dimensions},
author = {Russell, James A and Bullock, Merry},
doi = {10.1037/0022-3514.48.5.1290},
file = {:Users/gmac/mendeley/Russell, Bullock/Russell, Bullock - 1985 - Multidimensional scaling of emotional facial expressions Similarity from preschoolers to adults.pdf:pdf},
isbn = {1939-1315},
issn = {0022-3514},
journal = {Journal of Personality and Social Psychology},
number = {5},
pages = {1290--1298},
title = {{Multidimensional scaling of emotional facial expressions: Similarity from preschoolers to adults.}},
volume = {48},
year = {1985}
}
@article{Sandstrom2010,
abstract = {The purpose of this study was to investigate the effects of the valence and arousal dimensions of music over the time course of physiological (skin conductance level and heart rate) and subjective (Subjective Unit of Discomfort score) recovery from an acute stressor. Participants experienced stress after being told to prepare a speech, and were then exposed to happy, peaceful, sad, or agitated music. Music with a positive valence promoted both subjective and physiological recovery better than music with a negative valence, and low-arousal music was more effective than high-arousal music. Repeated measures analyses found that the emotion conveyed by the music affected skin conductance level recovery immediately following the stressor, whereas it affected heart rate recovery in a more sustained fashion. Follow-up tests found that positively valenced low-arousal (i.e., peaceful) music was more effective across the time course than an emotionally neutral control (white noise). (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)},
author = {Sandstrom, Gillian M and Russo, Frank A},
doi = {10.1177/1943862110371486},
file = {:Users/gmac/mendeley/Sandstrom, Russo/Sandstrom, Russo - 2010 - Music hath charms The effects of valence and arousal on recovery following an acute stressor.pdf:pdf},
isbn = {1943-8621\n1943-863X},
issn = {1943-8621},
journal = {Music and Medicine},
keywords = {ability of music to,arousal,chafin,counteract acute stress,emotion,gerin,interested in understanding the,music,researchers have long been,roy,stress,valence},
number = {3},
pages = {137--143},
title = {{Music hath charms: The effects of valence and arousal on recovery following an acute stressor}},
volume = {2},
year = {2010}
}
@article{Hickok2007,
author = {Hickok, Gregory and Poeppel, David},
file = {:Users/gmac/mendeley/Hickok, Poeppel/Hickok, Poeppel - 2007 - The cortical organization of speech processing.pdf:pdf},
journal = {Nature Reviews Neuroscience},
month = {may},
pages = {393--402},
title = {{The cortical organization of speech processing}},
url = {papers3://publication/uuid/904FC87D-428C-40DA-BF23-2261B0C8860E},
volume = {8},
year = {2007}
}
@article{Clark2007,
author = {Clark, C and Stansfeld, S A},
file = {:Users/gmac/mendeley/Clark, Stansfeld/Clark, Stansfeld - 2007 - The effect of transportation noise on heath and cognitive development A review of recent evidence.pdf:pdf},
journal = {Int J Comp Psychol},
pages = {145--158},
title = {{The effect of transportation noise on heath and cognitive development: A review of recent evidence}},
volume = {20},
year = {2007}
}
@inproceedings{Cameron2012,
address = {Thessaloniki, Greece},
author = {Cameron, Daniel and Lindsen, Job and Pearce, Marcus and Wiggins, Geraint and Potter, Keith and Bhattacharya, Joydeep},
booktitle = {12th International Conference on Music Perception and Cognition},
file = {:Users/gmac/mendeley/Cameron et al/Cameron et al. - 2012 - Entrainment of Premotor Cortex Activity by Ambiguity in Musical Metre.pdf:pdf},
keywords = {gamma,rhythm},
month = {jul},
title = {{Entrainment of Premotor Cortex Activity by Ambiguity in Musical Metre}},
url = {http://icmpc-escom2012.web.auth.gr/sites/default/files/papers/193_Proc.pdf papers3://publication/uuid/3B96C5D3-0428-4026-AE85-819E9FD67457},
year = {2012}
}
@incollection{Green2011,
address = {Cambridge},
author = {Green, Burdette and Butler, David},
booktitle = {The Cambridge History of Western Music Theory},
editor = {Christensen, Thomas},
file = {:Users/gmac/mendeley/Green, Butler/Green, Butler - 2011 - From acoustics to Tonpsychologie BT - The Cambridge History of Western Music Theory.pdf:pdf},
isbn = {9781139053471},
month = {jan},
number = {9},
pages = {246--271},
publisher = {Cambridge University Press},
title = {{From acoustics to Tonpsychologie BT  - The Cambridge History of Western Music Theory}},
url = {http://universitypublishingonline.org/ref/id/histories/CBO9781139053471 papers3://publication/doi/10.1017/CHOL9780521623711},
year = {2011}
}
@article{Yu2005,
author = {Yu, Yuguo and Romero, Richard and Lee, Tai},
file = {:Users/gmac/mendeley/Yu, Romero, Lee/Yu, Romero, Lee - 2005 - Preference of Sensory Neural Coding for 1f Signals.pdf:pdf},
journal = {Physical Review Letters},
keywords = {1/f},
month = {mar},
number = {10},
pages = {108103},
title = {{Preference of Sensory Neural Coding for 1/f Signals}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.94.108103 papers3://publication/doi/10.1103/PhysRevLett.94.108103},
volume = {94},
year = {2005}
}
@article{Levitin2012,
author = {Levitin, Daniel J and Chordia, Parag and Menon, Vinod},
file = {:Users/gmac/mendeley/Levitin, Chordia, Menon/Levitin, Chordia, Menon - 2012 - Musical rhythm spectra from Bach to Joplin obey a 1f power law.pdf:pdf},
journal = {PNAS},
keywords = {1/f},
month = {mar},
number = {10},
pages = {3716--3720},
title = {{Musical rhythm spectra from Bach to Joplin obey a 1/f power law}},
url = {papers3://publication/doi/10.1073/pnas.1113828109/-/DCSupplemental},
volume = {109},
year = {2012}
}
@article{Cohen1990,
author = {Cohen, Jacob},
file = {:Users/gmac/mendeley/Cohen/Cohen - 1990 - Things I Have Learned (So Far).pdf:pdf},
journal = {American Psychologist},
keywords = {stats},
month = {dec},
number = {12},
pages = {1304--1312},
publisher = {American Psychological Association},
title = {{Things I Have Learned (So Far)}},
url = {https://courses.ryerson.ca/@@/02AA674A58256817C754705A6B4AB3FF/courses/1/ps8101_f12_01/content/_1963092_1/Cohen %281990%29 - Things I have learned %28so far%29.pdf papers3://publication/uuid/861BB885-2D9C-4F52-9601-BE8C92E82F0E},
volume = {45},
year = {1990}
}
@article{Vlek2011,
abstract = {Objective: An auditory rhythm can be perceived as a sequence of accented (loud) and non-accented (soft) beats or it can be imagined. Subjective rhythmization refers to the induction of accenting patterns during the presentation of identical auditory pulses at an isochronous rate. It can be an automatic process, but it can also be voluntarily controlled. We investigated whether imagined accents can be decoded from brain signals on a single-trial basis, and if there is information shared between perception and imagery in the contrast of accents and non-accents. Methods: Ten subjects perceived and imagined three different metric patterns (two-, three-, and four-beat) superimposed on a steady metronome while electroencephalography (EEG) measurements were made. Shared information between perception and imagery EEG is investigated by means of principal component analysis and by means of single-trial classification. Results: Classification of accented from non-accented beats was possible with an average accuracy of 70% for perception and 61% for imagery data. Cross-condition classification yielded significant performance above chance level for a classifier trained on perception and tested on imagery data (up to 66%), and vice versa (up to 60%). Conclusions: Results show that detection of imagined accents is possible and reveal similarity in brain signatures relevant to distinction of accents from non-accents in perception and imagery. Significance: Our results support the idea of shared mechanisms in perception and imagery for auditory processing. This is relevant for a number of clinical settings, most notably by elucidating the basic mechanisms of rhythmic auditory cuing paradigms, e.g. as used in motor rehabilitation or therapy for Parkinson's disease. As a novel Brain-Computer Interface (BCI) paradigm, our results imply a reduction of the necessary BCI training in healthy subjects and in patients. ?? 2011 International Federation of Clinical Neurophysiology.},
author = {Vlek, R J and Schaefer, R S and Gielen, C C A M and Farquhar, J D R and Desain, P},
doi = {10.1016/j.clinph.2011.01.042},
file = {:Users/gmac/mendeley/Vlek et al/Vlek et al. - 2011 - Shared mechanisms in perception and imagery of auditory accents.pdf:pdf},
isbn = {1388-2457},
issn = {13882457},
journal = {Clinical Neurophysiology},
keywords = {Auditory imagery,Cross-condition classification,Electroencephalography,Perception and imagery,Rhythm processing,Single-trial classification,Subjective rhythmization},
number = {8},
pages = {1526--1532},
pmid = {21353631},
title = {{Shared mechanisms in perception and imagery of auditory accents}},
url = {https://pdfs.semanticscholar.org/ae94/ba03e9335c57c84d199990385ca4326b5536.pdf},
volume = {122},
year = {2011}
}
@article{Ekman1969a,
author = {Ekman, Paul and Friesen, Wallace V},
file = {:Users/gmac/mendeley/Ekman, Friesen/Ekman, Friesen - 1969 - The Repertoire of Nonverbal Behavior Categories, Origins, Usage, and Coding.pdf:pdf},
journal = {Semiotica},
number = {1},
pages = {49--98},
title = {{The Repertoire of Nonverbal Behavior: Categories, Origins, Usage, and Coding}},
volume = {1},
year = {1969}
}
@article{Nozaradan2016,
abstract = {The current study aims at characterizing the mechanisms that allow humans to entrain the mind and body to incoming rhythmic sensory inputs in real time. We addressed this unresolved issue by examining the relationship between covert neural processes and overt behavior in the context of musical rhythm. We measured temporal prediction abilities, sensorimotor synchronization accuracy and neural entrainment to auditory rhythms as captured using an EEG frequency-tagging approach. Importantly, movement synchronization accuracy with a rhythmic beat could be explained by the amplitude of neural activity selectively locked with the beat period when listening to the rhythmic inputs. Furthermore, stronger endogenous neural entrainment at the beat frequency was associated with superior temporal prediction abilities. Together, these results reveal a direct link between cortical and behavioral measures of rhythmic entrainment, thus providing evidence that frequency-tagged brain activity has functional relevance for beat perception and synchronization.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Nozaradan, Sylvie and Peretz, Isabelle and Keller, Peter E.},
doi = {10.1038/srep20612},
eprint = {arXiv:1011.1669v3},
file = {:Users/gmac/mendeley/Nozaradan, Peretz, Keller/Nozaradan, Peretz, Keller - 2016 - Individual Differences in Rhythmic Cortical Entrainment Correlate with Predictive Behavior in Sensori.pdf:pdf},
isbn = {9780874216561},
issn = {2045-2322},
journal = {Scientific Reports},
month = {aug},
number = {20612},
pages = {1--12},
pmid = {15991970},
publisher = {Nature Publishing Group},
title = {{Individual Differences in Rhythmic Cortical Entrainment Correlate with Predictive Behavior in Sensorimotor Synchronization}},
volume = {6},
year = {2016}
}
@article{Delorme2004,
author = {Delorme, Arnaud and Makeig, Scott},
file = {:Users/gmac/mendeley/Delorme, Makeig/Delorme, Makeig - 2004 - EEGLAB an open source toolbox for analysis of single-trial EEG dynamics including independent component analysi.pdf:pdf},
journal = {Journal of Neuroscience Methods},
month = {mar},
pages = {9--21},
publisher = {Elsevier B.V.},
title = {{EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis}},
volume = {134},
year = {2004}
}
@article{Anderson2010,
abstract = {Hearing Research, 270 (2010) 151-157. doi:10.1016/j.heares.2010.08.001},
author = {Anderson, Samira and Skoe, Erika and Chandrasekaran, Bharath and Zecker, Steven and Kraus, Nina},
file = {:Users/gmac/mendeley/Anderson et al/Anderson et al. - 2010 - Brainstem correlates of speech-in-noise perception in children.pdf:pdf},
journal = {Hearing Research},
month = {dec},
number = {1-2},
pages = {151--157},
publisher = {Elsevier B.V.},
title = {{Brainstem correlates of speech-in-noise perception in children}},
url = {http://dx.doi.org/10.1016/j.heares.2010.08.001},
volume = {270},
year = {2010}
}
@article{Baldwin1892,
annote = {- the child's first exhibition of will is its repeated effort to imitate movements seen and noises heard},
author = {Baldwin, J Mark},
file = {:Users/gmac/mendeley/Baldwin/Baldwin - 1892 - Origin of Volition in Childhood.pdf:pdf},
journal = {Science},
month = {nov},
pages = {286--287},
title = {{Origin of Volition in Childhood}},
url = {http://www.jstor.org.ezproxy.lib.ryerson.ca/stable/1766640 papers3://publication/uuid/D4C17551-FBA3-4B0C-B1E9-83D101D2DB6C},
volume = {20},
year = {1892}
}
@article{Overy2009,
abstract = {THE DISCOVERY OF INDIVIDUAL “MIRROR NEURONS” in the macaque brain that fire both when an action is executed and when that same action is observed or heard, and of a homologous system in humans, is lead- ing to an extraordinary conceptual shift in our under- standing of perception-action mechanisms, human communication, and empathy. In a recent model of emotional responses to music (Molnar-Szakacs & Overy, 2006), we proposed that music is perceived not only as an auditory signal, but also as intentional, hier- archically organized sequences of expressive motor acts behind the signal; and that the human mirror neu- ron system allows for corepresentation and sharing of a musical experience between agent and listener.Here, we expand upon this model of Shared Affective Motion Experience (SAME) and discuss its implica- tions for music therapy and special education.We hypoth- esize that imitation, synchronization, and shared experience may be key elements of successful work in these areas. Received},
author = {Overy, Katie and Molnar-Szakacs, Istvan},
doi = {10.1525/MP.2009.26.5.489},
file = {:Users/gmac/mendeley/Overy, Molnar-Szakacs/Overy, Molnar-Szakacs - 2009 - Being Together in Time Musical Experience and the Mirror Neuron System.pdf:pdf},
isbn = {0520057295},
journal = {Music Perception},
keywords = {emotion,imitation,insula,motor,therapy},
number = {5},
pages = {489--504},
title = {{Being Together in Time: Musical Experience and the Mirror Neuron System}},
volume = {26},
year = {2009}
}
@article{Juslin2008,
author = {Juslin, Patrik N and V{\"{a}}stfj{\"{a}}ll, Daniel},
file = {:Users/gmac/mendeley/Juslin, V{\"{a}}stfj{\"{a}}ll/Juslin, V{\"{a}}stfj{\"{a}}ll - 2008 - Emotional responses to music The need to consider underlying mechanisms.pdf:pdf},
journal = {Behavioral and Brain Sciences},
month = {oct},
number = {05},
title = {{Emotional responses to music: The need to consider underlying mechanisms}},
volume = {31},
year = {2008}
}
@article{Schmidt2016b,
author = {Schmidt, Juliane and Janse, Esther and Scharenborg, Odette},
doi = {10.3389/fpsyg.2016.00781},
file = {:Users/gmac/mendeley/Schmidt, Janse, Scharenborg/Schmidt, Janse, Scharenborg - 2016 - Perception of emotion in conversational speech by younger and older listeners.pdf:pdf},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Acoustic cues,Affective speech,Age,Hearing sensitivity,Natural speech},
number = {MAY},
pages = {1--11},
title = {{Perception of emotion in conversational speech by younger and older listeners}},
volume = {7},
year = {2016}
}
@article{Tierney2014,
abstract = {The neural resonance theory of musical meter explains musical beat tracking as the result of entrainment of neural oscillations to the beat frequency and its higher harmonics. This theory has gained empirical support from experiments using simple, abstract stimuli. However, to date there has been no empirical evidence for a role of neural entrainment in the perception of the beat of ecologically valid music. Here we presented participants with a single pop song with a super- imposed bassoon sound. This stimulus was either lined up with
the beat of the music or shifted away from the beat by 25% of the average interbeat interval. Both conditions elicited a neural response at the beat frequency. However, although the on-the- beat condition elicited a clear response at the first harmonic of the beat, this frequency was absent in the neural response to the off-the-beat condition. These results support a role for neural entrainment in tracking the metrical structure of real music and show that neural meter tracking can be disrupted by the pre- sentation of contradictory rhythmic cues.},
author = {Tierney, Adam T and Kraus, Nina},
doi = {10.1162/jocn_a_00704},
file = {:Users/gmac/mendeley/Tierney, Kraus/Tierney, Kraus - 2014 - Neural Entrainment to the Rhythmic Structure of Music.pdf:pdf},
journal = {Journal of Cognitive Neuroscience},
number = {2},
pages = {400--408},
title = {{Neural Entrainment to the Rhythmic Structure of Music}},
volume = {27},
year = {2014}
}
@article{Nozaradan2014,
abstract = {The ability to perceive a regular beat in music and synchronize to this beat is a widespread human skill. Fundamental to musical behaviour, beat and meter refer to the perception of periodicities while listening to musical rhythms and often involve spontaneous entrainment to move on these periodicities. Here, we present a novel experimental approach inspired by the frequency-tagging approach to understand the perception and production of rhythmic inputs. This approach is illustrated here by recording the human electroencephalogram responses at beat and meter frequencies elicited in various contexts: mental imagery of meter, spontaneous induction of a beat from rhythmic patterns, multisensory integration and sensorimotor synchronization. Collectively, our observations support the view that entrainment and resonance phenomena subtend the processing of musical rhythms in the human brain. More generally, they highlight the potential of this approach to help us understand the link between the phenomenology of musical beat and meter and the bias towards periodicities arising under certain circumstances in the nervous system. Entrainment to music provides a highly valuable framework to explore general entrainment mechanisms as embodied in the human brain.},
author = {Nozaradan, Sylvie},
doi = {10.1098/rstb.2013.0393},
file = {:Users/gmac/mendeley/Nozaradan/Nozaradan - 2014 - Exploring how musical rhythm entrains brain activity with electroencephalogram frequency-tagging.pdf:pdf},
isbn = {0962-8436},
issn = {1471-2970},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {behaviour,cognition,neuroscience},
number = {1658},
pages = {1--10},
pmid = {25385771},
title = {{Exploring how musical rhythm entrains brain activity with electroencephalogram frequency-tagging.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25385771},
volume = {369},
year = {2014}
}
@article{Rohrmeier2012,
annote = {- “Enculturated Western listeners presumably form expectations with respect to upcoming chords or harmonic structure from a small lexicon of tonal chords.”},
author = {Rohrmeier, Martin A and Koelsch, Stefan},
file = {:Users/gmac/mendeley/Rohrmeier, Koelsch/Rohrmeier, Koelsch - 2012 - Predictive information processing in music cognition. A critical review.pdf:pdf},
journal = {International Journal of Psychophysiology},
month = {feb},
number = {2},
pages = {164--175},
title = {{Predictive information processing in music cognition. A critical review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167876011003898 papers3://publication/doi/10.1016/j.ijpsycho.2011.12.010},
volume = {83},
year = {2012}
}
@article{Picton2000,
author = {Picton, T W and Bentin, S and Berg, P and Donchin, E and Hillyard, S A and Johnson, R and Miller, G A and Ritter, W and Ruchkin, D S and Rugg, M D and Taylor, M J},
file = {:Users/gmac/mendeley/Picton et al/Picton et al. - 2000 - Guidelines for using human event-related potentials to study cognition Recording standards and publication criter.pdf:pdf},
journal = {Psychophysiology},
month = {mar},
number = {2},
pages = {127--152},
title = {{Guidelines for using human event-related potentials to study cognition: Recording standards and publication criteria}},
url = {http://doi.wiley.com/10.1111/1469-8986.3720127 papers3://publication/doi/10.1111/1469-8986.3720127},
volume = {37},
year = {2000}
}
@article{Bhattacharya2005,
abstract = {... synchrony or phase  coherence between EEG signals was measured by a recently developed index, which is more suitable than classical indices, like correlation or coherence , when dealing with nonlinear and nonstationary signals like EEG. Comparing the music listening task ... 
},
author = {Bhattacharya, Joydeep and Petsche, Hellmuth},
file = {:Users/gmac/mendeley/Bhattacharya, Petsche/Bhattacharya, Petsche - 2005 - Phase synchrony analysis of EEG during music perception reveals changes in functional connectivity due to.pdf:pdf},
journal = {Signal processing},
keywords = {gamma},
month = {nov},
number = {11},
pages = {2161--2177},
title = {{Phase synchrony analysis of EEG during music perception reveals changes in functional connectivity due to musical expertise}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168405002070 papers3://publication/doi/10.1016/j.sigpro.2005.07.007},
volume = {85},
year = {2005}
}
@article{McManis2001,
abstract = {Many studies have shown a consistent pattern in adults' responses to affective pictures and there is growing evidence of gender differences, as well. Little is known, though, about children's verbal, behavioral, and physiological responses to affective pictures. Two experiments investigated children's responses to pictures. In Experiment 1, children, adolescents, and adults viewed pictures varying in affective content and rated them for pleasure, arousal, and dominance. Results indicated that children and adolescents rated the pictures similarly to adults. In Experiment 2, physiological responses, self-report, and viewing time were measured while children viewed affective pictures. As with adults, children's responses reflected the affective content of the pictures. Gender differences in affective evaluations, corrugator activity, skin conductance, startle modulation, and viewing time indicated that girls were generally more reactive to unpleasant materials.},
author = {McManis, Mark H. and Bradley, Margaret M and Berg, W. Keith and Cuthbert, Bruce N. and Lang, Peter J},
doi = {10.1111/1469-8986.3820222},
file = {:Users/gmac/mendeley/McManis et al/McManis et al. - 2001 - Emotional reactions in children Verbal, physiological, and behavioral responses to affective pictures.pdf:pdf},
isbn = {0048-5772},
issn = {0048-5772},
journal = {Psychophysiology},
number = {2},
pages = {222--231},
pmid = {11347868},
title = {{Emotional reactions in children: Verbal, physiological, and behavioral responses to affective pictures}},
volume = {38},
year = {2001}
}
@article{Chen2008,
annote = {- vPMC during listening (in anticipation of tapping along) and during tapping 
- dPMC during movement synchronization, also sensitive to meter 
- "mid-PMC, SMA, and cerebellum lobule VI resonate in response to sounds that do not bear any obvious significance for action implementation" // maybe it automatically prepares for movement when the sound lends itself to synchronization, i.e., groove},
author = {Chen, J L and Penhune, V B and Zatorre, R J},
file = {:Users/gmac/mendeley/Chen, Penhune, Zatorre/Chen, Penhune, Zatorre - 2008 - Listening to Musical Rhythms Recruits Motor Regions of the Brain.pdf:pdf},
journal = {Cerebral Cortex},
month = {nov},
number = {12},
pages = {2844--2854},
title = {{Listening to Musical Rhythms Recruits Motor Regions of the Brain}},
url = {http://www.cercor.oxfordjournals.org/cgi/doi/10.1093/cercor/bhn042},
volume = {18},
year = {2008}
}
@article{Teki2014,
abstract = {Time is a fundamental dimension of life. It is crucial for decisions about quantity, speed of movement and rate of return, as well as for motor control in walking, speech, playing or appreciating music, and participating in sports. Traditionally, the way in which time is perceived, represented and estimated has been explained using a pacemaker-accumulator model that is not only straightforward, but also surprisingly powerful in explaining behavioural and biological data. However, recent advances have challenged this traditional view. It is now proposed that the brain represents time in a distributed manner and tells the time by detecting the coincidental activation of different neural populations.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Teki, Sundeep},
doi = {10.3389/fnsys.2014.00155},
eprint = {NIHMS150003},
file = {:Users/gmac/mendeley/Teki/Teki - 2014 - Beta drives brain beats.pdf:pdf},
isbn = {1471-003X},
issn = {1662-5137},
journal = {Frontiers in Systems Neuroscience},
keywords = {Animals,Brain,Brain: physiology,Humans,Models,Neurological,Time Perception,Time Perception: physiology},
number = {10},
pages = {755--65},
pmid = {16163383},
title = {{Beta drives brain beats}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16163383%5Cnhttp://journal.frontiersin.org/article/10.3389/fnsys.2014.00155/abstract},
volume = {8},
year = {2014}
}
@article{Worden1968,
author = {Worden, F G and Marsh, James T},
file = {:Users/gmac/mendeley/Worden, Marsh/Worden, Marsh - 1968 - Frequency-Following (Microphonic-Like) Neural Responses Evoked by Sound.pdf:pdf},
journal = {Electroencephalography and Clinical Neurophysiology},
month = {jan},
pages = {42--52},
title = {{Frequency-Following (Microphonic-Like) Neural Responses Evoked by Sound}},
url = {papers3://publication/uuid/4D49322F-C050-412B-B83F-EC937265688A},
volume = {25},
year = {1968}
}
@article{Danziger1980,
author = {Danziger, Kurt},
file = {:Users/gmac/mendeley/Danziger/Danziger - 1980 - The History of Introspection Reconsidered.pdf:pdf},
journal = {Journal of the History of the Behavioral Sciences},
month = {jan},
pages = {241--262},
title = {{The History of Introspection Reconsidered}},
url = {papers3://publication/uuid/074407E5-3F74-4FE2-9B69-EB72048ED4C1},
volume = {16},
year = {1980}
}
@article{Staud2008,
author = {Staud, Roland and Koo, Eubee B},
file = {:Users/gmac/mendeley/Staud, Koo/Staud, Koo - 2008 - Are cannabinoids a new treatment option for pain in patients with fibromyalgia.pdf:pdf},
journal = {Nature Clinical Practice},
month = {jul},
pages = {348--349},
title = {{Are cannabinoids a new treatment option for pain in patients with fibromyalgia?}},
url = {papers3://publication/uuid/631711CE-9448-4BBD-8510-4AEEAEB7C38B},
volume = {4},
year = {2008}
}
@article{Jones1995,
author = {Jones, Mari Riess and Jagacinski, Richard J and Yee, William and Floyd, Richard L and Klapp, Stuart T},
file = {:Users/gmac/mendeley/Jones et al/Jones et al. - 1995 - Tests of Attentional Flexibility in Listening to Polyrhythmic Patters.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
month = {jan},
number = {2},
pages = {293--307},
publisher = {American Psychological Association},
title = {{Tests of Attentional Flexibility in Listening to Polyrhythmic Patters}},
url = {papers3://publication/uuid/93474D6A-54A0-4031-86AA-019ADD8ADC7E},
volume = {21},
year = {1995}
}
@article{Szalma2011,
archivePrefix = {arXiv},
arxivId = {arXiv:physics/0608246v3},
author = {Szalma, James L and Hancock, Peter A},
doi = {10.5811/westjem.2011.5.6700},
eprint = {0608246v3},
file = {:Users/gmac/mendeley/Szalma, Hancock/Szalma, Hancock - 2011 - Noise Effects on Human Performance A Meta-Analytic Synthesis(2).pdf:pdf},
isbn = {9780980200454},
journal = {Psychological Bulletin},
number = {4},
pages = {682--707},
pmid = {24696751},
primaryClass = {arXiv:physics},
title = {{Noise Effects on Human Performance: A Meta-Analytic Synthesis}},
volume = {137},
year = {2011}
}
@article{Zelaznik2002,
annote = {timing of movement initiation is explicit
timing of movement duration is implicit
If two tasks share a common timing process, variability in timing on one of those tasks will be predictive of variability in timing on the other task.
Moreover, variability in timing in finger tapping is correlated with duration-discrimination performance (Keele, Pokorny, Corcos, & Ivry, 1985)
Two important findings:
First, individual differences in timing variability in the tapping task were not significantly correlated with individual differences in timing variability in drawing
Second, when the cycle period was varied, the slopes of the variability function for tapping and circle drawing were not the same
So, not all timing tasks share the same explicit timing process

The overall pattern of positive correlations observed in this experiment suggests that there is a shared timing factor associated with all three tasks (and used to a lesser extent in continuous circle drawing) or that part of the individual-differences variation is related to general factors.

We believe that temporal regularities may emerge as a function of the higher level conceptualization of the task

We believe that participants meet this goal for continuous drawing in a manner in which an explicit representation of an individual temporal interval is not required.},
author = {Zelaznik, Howard N and Spencer, Rebecca M C and Ivry, Richard B},
file = {:Users/gmac/mendeley/Zelaznik, Spencer, Ivry/Zelaznik, Spencer, Ivry - 2002 - Dissociation of explicit and implicit timing in repetitive tapping and drawing movements.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
month = {jan},
number = {3},
pages = {575--588},
publisher = {American Psychological Association},
title = {{Dissociation of explicit and implicit timing in repetitive tapping and drawing movements.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-1523.28.3.575 papers3://publication/doi/10.1037//0096-1523.28.3.575},
volume = {28},
year = {2002}
}
@article{Fujioka2015,
abstract = {Dancing to music involves synchronized movements, which can be at the basic beat level or higher hierarchical metrical levels, as in a march (groups of two basic beats, one-two-one-two ...) or waltz (groups of three basic beats, one-two-three-one-two-three ...). Our previous human magnetoencephalography studies revealed that the subjective sense of meter influences auditory evoked responses phase locked to the stimulus. Moreover, the timing of metronome clicks was represented in periodic modulation of induced (non-phase locked) {beta}-band (13-30 Hz) oscillation in bilateral auditory and sensorimotor cortices. Here, we further examine whether acoustically accented and subjectively imagined metric processing in march and waltz contexts during listening to isochronous beats were reflected in neuromagnetic {beta}-band activity recorded from young adult musicians. First, we replicated previous findings of beat-related {beta}-power decrease at 200 ms after the beat followed by a predictive increase toward the onset of the next beat. Second, we showed that the {beta} decrease was significantly influenced by the metrical structure, as reflected by differences across beat type for both perception and imagery conditions. Specifically, the {beta}-power decrease associated with imagined downbeats (the count "one") was larger than that for both the upbeat (preceding the count "one") in the march, and for the middle beat in the waltz. Moreover, beamformer source analysis for the whole brain volume revealed that the metric contrasts involved auditory and sensorimotor cortices; frontal, parietal, and inferior temporal lobes; and cerebellum. We suggest that the observed {beta}-band activities reflect a translation of timing information to auditory-motor coordination. SIGNIFICANCE STATEMENT With magnetoencephalography, we examined {beta}-band oscillatory activities around 20 Hz while participants listened to metronome beats and imagined musical meters such as a march and waltz. We demonstrated that {beta}-band event-related desynchronization in the auditory cortex differentiates between beat positions, specifically between downbeats and the following beat. This is the first demonstration of {beta}-band oscillations related to hierarchical and internalized timing information. Moreover, the meter representation in the {beta} oscillations was widespread across the brain, including sensorimotor and premotor cortices, parietal lobe, and cerebellum. The results extend current understanding of the role of {beta} oscillations in neural processing of predictive timing.},
annote = {- beta activity is modulated by imagining a beat on an isochronous sequence
- involved auditory and sensorimotor cortices; frontal, parietal, and inferior temporal lobes; and cerebellum (used MEG beamformer)},
author = {Fujioka, Takako and Ross, B. and Trainor, Laurel J},
doi = {10.1523/JNEUROSCI.2397-15.2015},
file = {:Users/gmac/mendeley/Fujioka, Ross, Trainor/Fujioka, Ross, Trainor - 2015 - Beta-Band Oscillations Represent Auditory Beat and Its Metrical Hierarchy in Perception and Imagery.pdf:pdf},
isbn = {1529-2401 (Electronic)\r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {ERD,event-related desynchronization,magnetoencephalography,predictive coding,timing processing},
number = {45},
pages = {15187--15198},
pmid = {26558788},
title = {{Beta-Band Oscillations Represent Auditory Beat and Its Metrical Hierarchy in Perception and Imagery}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2397-15.2015%5Cnhttp://www.jneurosci.org/content/35/45/15187.abstract?etoc},
volume = {35},
year = {2015}
}
@article{Repp2013,
author = {Repp, Bruno H and London, Justin and Keller, Peter E},
file = {:Users/gmac/mendeley/Repp, London, Keller/Repp, London, Keller - 2013 - Systematic Distortions in Musicians' Reproduction of Cyclic Three-Interval Rhythms.pdf:pdf},
journal = {Music Perception: An Interdisciplinary Journal},
month = {feb},
number = {3},
pages = {291--305},
publisher = {University of California Press},
title = {{Systematic Distortions in Musicians' Reproduction of Cyclic Three-Interval Rhythms}},
url = {http://www.jstor.org/stable/info/10.1525/mp.2012.30.3.291 papers3://publication/doi/10.1525/mp.2012.30.3.291},
volume = {30},
year = {2013}
}
@article{Boyke2008,
author = {Boyke, J and Driemeyer, J and Gaser, C and Buchel, C and May, A},
file = {:Users/gmac/mendeley/Boyke et al/Boyke et al. - 2008 - Training-Induced Brain Structure Changes in the Elderly.pdf:pdf},
journal = {Journal of Neuroscience},
month = {jul},
number = {28},
pages = {7031--7035},
title = {{Training-Induced Brain Structure Changes in the Elderly}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0742-08.2008 papers3://publication/doi/10.1523/JNEUROSCI.0742-08.2008},
volume = {28},
year = {2008}
}
@article{Freud1910,
author = {Freud, Sigmund},
file = {:Users/gmac/mendeley/Freud/Freud - 1910 - The Origin and Development of Psychoanalysis.pdf:pdf},
journal = {The American Journal of Psychology},
month = {apr},
pages = {181--218},
title = {{The Origin and Development of Psychoanalysis}},
url = {http://www.jstor.org.ezproxy.lib.ryerson.ca/stable/1413001 papers3://publication/uuid/1A97A72F-CC7A-4040-B22C-4A062776E1F8},
volume = {21},
year = {1910}
}
@book{Merchant2014,
address = {New York},
booktitle = {October},
editor = {Merchant, Hugo and de Lafuente, Victor},
isbn = {9780387770635},
publisher = {Springer},
title = {{Neurobiology of Interval Timing}},
year = {2014}
}
@article{Giguere2012,
author = {Giguere, Christian and Behar, Alberto and Dajani, Hilmi R and Kelsall, Tim and Keith, Stephen E},
file = {:Users/gmac/mendeley/Giguere et al/Giguere et al. - 2012 - Direct and indirect methods for the measurement of occupational sound exposure from communication headsets.pdf:pdf},
journal = {Noise Control Engineering Journal},
month = {dec},
number = {6},
pages = {630--644},
title = {{Direct and indirect methods for the measurement of occupational sound exposure from communication headsets}},
url = {papers3://publication/uuid/5CB1C6E6-869A-49AE-81C9-11C3DEA054D6},
volume = {60},
year = {2012}
}
@article{Repp2010a,
abstract = {Differences between recorded repetitions of one's own movements are detected more readily than are differences between repetitions of others' movements, suggesting improved visual discrimination due to heightened resonance in the observer's action system and/or relatively accurate internal action simulation (Daprati et al. in Conscious Cogn 16:178-188, 2007). In Experiment 1, we attempted to replicate this finding in the auditory modality. Pianists were recorded playing musical excerpts three times and later judged whether pairs of recordings were the same take or different takes of the same excerpt. They were no better at distinguishing different takes of their own playing than those of other pianists' playing, even though discrimination and self-recognition were well above chance. In Experiment 2, the same pianists tried to detect small local timing deviations that had been introduced artificially. They were better at detecting such deviations in their own performances than in those of another pianist, but only if the deviations were placed at points of a pre-existing self-other difference in local timing. In that case, pianists' ability to predict their own characteristic action pattern did aid their perception of temporal irregularity. These results do not support the perceptual sharpening hypothesis of Daprati et al. in the musical domain, but they do suggest that pianists listening to performances generate idiosyncratic temporal expectations, probably through internal action simulation.},
author = {Repp, Bruno H. and Keller, Peter E.},
doi = {10.1007/s00221-009-2115-8},
file = {:Users/gmac/mendeley/Repp, Keller/Repp, Keller - 2010 - Self versus other in piano performance Detectability of timing perturbations depends on personal playing style.pdf:pdf},
isbn = {1432-1106 (Electronic)\n0014-4819 (Linking)},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Action simulation,Expectancy,Forward models,Motor resonance,Music performance,Self-recognition,Timing perception},
number = {1},
pages = {101--110},
pmid = {20012533},
title = {{Self versus other in piano performance: Detectability of timing perturbations depends on personal playing style}},
volume = {202},
year = {2010}
}
@article{Parsons2007,
abstract = {Principals who exercise favouritism towards certain agents may harm those who are not so favoured. We address this issue in the context of a natural experiment from English soccer. We study the effects of professional referees on a common measure of referee bias: length of injury time in close matches. We find that referees exercised a degree of favouritism prior to professionalism but not afterwards, having controlled for selection and soccer-wide effects. We also discuss the suitability of the variable that we, and others, use to measure favouritism, noting that alternative interpretations may be possible.},
author = {Parsons, CA and Sulaeman, J and Yates, MC and Hamermesh, DS},
doi = {10.3386/w13665},
file = {:Users/gmac/mendeley/Parsons et al/Parsons et al. - 2007 - Strike three Umpires' demand for discrimination.pdf:pdf},
keywords = {Labor Studies},
number = {3899},
title = {{Strike three: Umpires' demand for discrimination}},
year = {2007}
}
@article{Hevner1935a,
author = {Hevner, Kate},
file = {:Users/gmac/mendeley/Hevner/Hevner - 1935 - Expression in Music A Discussion of Experimental Studies and Theories.pdf:pdf},
journal = {Psychological Review},
month = {mar},
number = {2},
pages = {186--204},
title = {{Expression in Music: A Discussion of Experimental Studies and Theories}},
url = {papers3://publication/uuid/B9A78901-DE9F-4F02-A088-23D7BE64CD38},
volume = {42},
year = {1935}
}
@article{Mckinney1983,
author = {Mckinney, Cathy H and Tims, Frederick C},
file = {:Users/gmac/mendeley/Mckinney, Tims/Mckinney, Tims - 1983 - Differential Effects of Selected Classical Music on the Imagery of High Versus Low Imagers Two Studies '.pdf:pdf},
journal = {Journal of Music Therapy},
number = {1},
pages = {22--45},
title = {{Differential Effects of Selected Classical Music on the Imagery of High Versus Low Imagers : Two Studies '}},
volume = {32},
year = {1983}
}
@article{Chasin2004,
annote = {- most important sounds for speech clarity: above 1000 Hz
- loudness perception: below 1000 Hz

- crest factor: difference between peaks and RMS
-- speech is very damped (12 dB)
-- music is not (18-20 dB)

what is threshold knee (TK)},
author = {Chasin, Marshall and Russo, Frank A},
file = {:Users/gmac/mendeley/Chasin, Russo/Chasin, Russo - 2004 - Hearing Aids and Music.pdf:pdf},
journal = {Trends in Amplification},
month = {jun},
number = {2},
pages = {35--47},
title = {{Hearing Aids and Music}},
url = {http://tia.sagepub.com/cgi/doi/10.1177/108471380400800202 papers3://publication/doi/10.1177/108471380400800202},
volume = {8},
year = {2004}
}
@article{Caird1987,
author = {Caird, David M and Klinke, Rainer},
file = {:Users/gmac/mendeley/Caird, Klinke/Caird, Klinke - 1987 - The effect of inferior colliculus lesions on auditory evoked potentials.pdf:pdf},
journal = {Electroencephalography and Clinical Neurophysiology},
month = {jan},
pages = {237--240},
title = {{The effect of inferior colliculus lesions on auditory evoked potentials}},
url = {papers3://publication/uuid/D045F7E2-90FA-4A12-99D3-ED210A38E277},
volume = {68},
year = {1987}
}
@article{Clinard2010,
author = {Clinard, Christopher G and Tremblay, Kelly L and Krishnan, Ananthanarayan R},
file = {:Users/gmac/mendeley/Clinard, Tremblay, Krishnan/Clinard, Tremblay, Krishnan - 2010 - Aging alters the perception and physiological representation of frequency Evidence from human frequ.pdf:pdf},
journal = {Hearing Research},
month = {jun},
number = {1-2},
pages = {48--55},
publisher = {Elsevier B.V.},
title = {{Aging alters the perception and physiological representation of frequency: Evidence from human frequency-following response recordings}},
url = {http://dx.doi.org/10.1016/j.heares.2009.11.010},
volume = {264},
year = {2010}
}
@article{Temperley1999,
author = {Temperley, David},
file = {:Users/gmac/mendeley/Temperley/Temperley - 1999 - Syncopation in rock a perceptual perspective.pdf:pdf},
journal = {Popular Music},
month = {jan},
number = {1},
pages = {19--40},
title = {{Syncopation in rock: a perceptual perspective}},
url = {papers3://publication/uuid/7ADCA8BC-49AC-4706-9F17-57EF0EBD566A},
volume = {18},
year = {1999}
}
@article{Baldwin1896b,
author = {Baldwin, J Mark},
file = {:Users/gmac/mendeley/Baldwin/Baldwin - 1896 - Heredity and Instinct.pdf:pdf},
journal = {Science},
month = {mar},
pages = {438--441},
title = {{Heredity and Instinct}},
url = {http://www.jstor.org.ezproxy.lib.ryerson.ca/stable/1625148 papers3://publication/uuid/942C0145-250A-4418-86FC-483770E8B380},
volume = {3},
year = {1896}
}
@article{Goy2016,
annote = {- impaired < normal hearing for word recognition and emotion identification
- hearing aids improved performance more for word recognition (24%) than emotion identification (6%)},
author = {Goy, Huiwen and Pichora-Fuller, M Kathleen and Singh, Gurjit and Russo, Frank A},
file = {:Users/gmac/mendeley/Goy et al/Goy et al. - 2016 - Perception of Emotional Speech by Listeners with Hearing Aids.pdf:pdf},
journal = {Canadian Acoustics},
number = {3},
title = {{Perception of Emotional Speech by Listeners with Hearing Aids}},
volume = {44},
year = {2016}
}
@article{Shahin2010,
author = {Shahin, A J and Trainor, Laurel J and Roberts, L E and Backer, K C and Miller, L M},
file = {:Users/gmac/mendeley/Shahin et al/Shahin et al. - 2010 - Development of Auditory Phase-Locked Activity for Music Sounds.pdf:pdf},
journal = {Journal of Neurophysiology},
keywords = {rhythm},
month = {jan},
number = {1},
pages = {218--229},
title = {{Development of Auditory Phase-Locked Activity for Music Sounds}},
volume = {103},
year = {2010}
}
@article{Martin1984,
abstract = {Two experiments demonstrated that a conditioned emotional response can both be established and arouse responses without awareness in a dichotic paradigm. Right handed male subjects performed a complex verbal task presented to the right ear, while patterns of musical notes were presented to the left ear. For experimental subjects, one of the patterns was always followed by an aversive noise in the left ear; the noises were presented at random times to control subjects. In Study 1, latency of skin potential response to the noise decreased among experimental subjects relative to control subjects, indicating that the critical tone pattern was acting as a CS. Subject awareness was determined through both recall and recognition procedures, and only unaware subjects were used. Study 2 demonstrated the effect more powerfully by showing conditioned responses among experimental subjects on interpolated CS-alone trials and a lack of reportable awareness among all subjects.},
author = {Martin, D G and Stambrook, M and Tataryn, D J and Beihl, H},
file = {:Users/gmac/mendeley/Martin et al/Martin et al. - 1984 - Conditioning in the unattended left ear.pdf:pdf},
isbn = {0020-7454 (Print)\r0020-7454 (Linking)},
journal = {International Journal of Neuroscience},
keywords = {Adolescent,Adult,Arousal/physiology,Avoidance Learning/*physiology,Awareness/*physiology,Cognition/*physiology,Conditioning, Classical/*physiology,Dichotic Listening Tests,Dominance, Cerebral/*physiology,Galvanic Skin Response/physiology,Humans,Male,Noise,Speech Perception/*physiology,Sympathetic Nervous System/physiology},
number = {2},
pages = {95--102},
pmid = {6480247},
title = {{Conditioning in the unattended left ear}},
volume = {23},
year = {1984}
}
@article{Bohlman2013,
author = {Bohlman, P V},
file = {:Users/gmac/mendeley/Bohlman/Bohlman - 2013 - Book review Carl Stumpf, The Origins of Music.pdf:pdf},
journal = {Musicae Scientiae},
month = {dec},
number = {4},
pages = {515--518},
publisher = {European Society for the Cognitive Sciences of Music},
title = {{Book review: Carl Stumpf, The Origins of Music}},
url = {http://msx.sagepub.com/lookup/doi/10.1177/1029864913497634 papers3://publication/doi/10.1177/1029864913497634},
volume = {17},
year = {2013}
}
@article{Aucouturier2016a,
abstract = {ed unaware that their own voices were being manipulated. This finding indicates that people are not continuously monitoring their own voice to make sure that it meets a predetermined emotional target. Instead, as a consequence of listening to their altered voices, the emotional state of the participants changed in congruence with the emotion portrayed, which was measured by both self-report and skin conductance level. This change is the first evidence, to our knowledge, of peripheral feedback effects on emotional experience in the auditory domain},
author = {Aucouturier, Jean-Julien and Johansson, Petter and Hall, Lars and Segnini, Rodrigo and Mercadi{\'{e}}, Lolita and Watanabe, Katsumi},
doi = {10.1073/pnas.1506552113},
file = {:Users/gmac/mendeley/Aucouturier et al/Aucouturier et al. - 2016 - Covert digital manipulation of vocal emotion alter speakers' emotional states in a congruent direction.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {4},
pages = {948--953},
pmid = {26755584},
title = {{Covert digital manipulation of vocal emotion alter speakers' emotional states in a congruent direction}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1506552113},
volume = {113},
year = {2016}
}
@article{Gerloff1997,
abstract = {We used high-frequency repetitive transcranial magnetic stimulation (rTMS) to study the role of the mesial frontocentral cortex (including the supplementary motor area) in the organization of sequential finger movements of different complexity in humans. In 15 subjects, rTMS was randomly applied to the scalp overlying the region of the supplementary motor area and over other positions, including the contralateral primary motor cortex (hand area) during the performance of three overlearned finger sequences on an electronic piano. In all trials, rTMS (frequency 15-20 Hz) started 2 s after the first key press and lasted for approximately 2 s. All sequences were metronome-paced at 2 Hz and retrieved from memory. The 'simple' sequence consisted of 16 repeated index finger key presses, the 'scale' sequence of four times four sequential key presses of the little, ring, middle and index fingers, and the 'complex' sequence of a much less systematic and, therefore, more difficult series of 16 key presses. To measure the effects of rTMS interference with regional cortical function, we analysed rTMS-induced accuracy errors in the movement sequences. Stimulation over the supplementary motor area induced accuracy errors only in the complex sequence, while stimulation over the primary motor cortex induced errors in both the complex and scale sequences, and stimulation over other positions (e.g. F3, F4, FCz, P3, P4) did not interfere with sequence performance at all. Stimulation over the supplementary motor area interfered with the organization of subsequent elements in the complex sequence of movements, with error induction occurring approximately 1 s later than with stimulation over the primary motor cortex. Our findings are in keeping with recent results in non-human primates (Tanji J, Shima K. Nature, 1994; 371: 413-6) indicating a critical role of the supplementary motor area in the organization of forthcoming movements in complex motor sequences that are rehearsed from memory and fit into a precise timing plan.},
address = {Human Cortical Physiology Unit, National Institute of Neurological Disorders and Stroke, National Institutes of Health, Bethesda, MD 20892-1428, USA.},
author = {Gerloff, C and Corwell, B and Chen, R and Hallett, M and Cohen, L G},
file = {:Users/gmac/mendeley/Gerloff et al/Gerloff et al. - 1997 - Stimulation over the human supplementary motor area interferes with the organization of future elements in compl.pdf:pdf},
journal = {Brain},
month = {sep},
pages = {1587--1602},
title = {{Stimulation over the human supplementary motor area interferes with the organization of future elements in complex motor sequences.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=9313642&retmode=ref&cmd=prlinks papers3://publication/uuid/A6E7CC5A-EA6E-42D5-903F-48795A0D545A},
volume = {120 ( Pt 9},
year = {1997}
}
@article{Schaefer2009,
author = {Schaefer, Rebecca S and Desain, Peter and Suppes, Patrick},
file = {:Users/gmac/mendeley/Schaefer, Desain, Suppes/Schaefer, Desain, Suppes - 2009 - Structural decomposition of EEG signatures of melodic processing.pdf:pdf},
journal = {Biological Psychology},
keywords = {EEG,neuropsychology},
month = {dec},
number = {3},
pages = {253--259},
title = {{Structural decomposition of EEG signatures of melodic processing}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0301051109001616 papers3://publication/doi/10.1016/j.biopsycho.2009.08.004},
volume = {82},
year = {2009}
}
@article{Grahn2012,
author = {Grahn, Jessica A and Schuit, Dirk},
file = {:Users/gmac/mendeley/Grahn, Schuit/Grahn, Schuit - 2012 - Individual Differences in Rhythmic Ability Behavioral and Neuroimaging Investigations.pdf:pdf},
journal = {Psychomusicology: Music, Mind, and Brain},
month = {jan},
number = {2},
pages = {105--121},
title = {{Individual Differences in Rhythmic Ability: Behavioral and Neuroimaging Investigations}},
url = {http://supp.apa.org/psycarticles/supplemental/a0031188/a0031188_supp.html papers3://publication/doi/10.1037/a0031188.supp},
volume = {22},
year = {2012}
}
@article{Engel2010,
abstract = {In this review, we consider the potential functional role of beta-band oscillations, which at present is not yet well understood. We discuss evidence from recent studies on top-down mechanisms involved in cognitive processing, on the motor system and on the pathophysiology of movement disorders that suggest a unifying hypothesis: beta-band activity seems related to the maintenance of the current sensorimotor or cognitive state. We hypothesize that beta oscillations and/or coupling in the beta-band are expressed more strongly if the maintenance of the status quo is intended or predicted, than if a change is expected. Moreover, we suggest that pathological enhancement of beta-band activity is likely to result in an abnormal persistence of the status quo and a deterioration of flexible behavioural and cognitive control. ?? 2010 Elsevier Ltd.},
author = {Engel, Andreas K. and Fries, Pascal},
doi = {10.1016/j.conb.2010.02.015},
file = {:Users/gmac/mendeley/Engel, Fries/Engel, Fries - 2010 - Beta-band oscillations-signalling the status quo.pdf:pdf},
isbn = {1873-6882 (Electronic)\r0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
month = {apr},
number = {2},
pages = {156--165},
pmid = {20359884},
publisher = {Elsevier Ltd},
title = {{Beta-band oscillations-signalling the status quo?}},
url = {http://dx.doi.org/10.1016/j.conb.2010.02.015},
volume = {20},
year = {2010}
}
@article{Leocani1997,
author = {Leocani, L and Toro, C and Manganotti, P and Zhuang, P and Hallett, M},
file = {:Users/gmac/mendeley/Leocani et al/Leocani et al. - 1997 - Event-related coherence and event-related desynchronization synchronization in the 10 Hz and 20 Hz EEG during se.pdf:pdf},
journal = {Electroencephalography and Clinical Neurophysiology},
month = {jul},
number = {104},
pages = {199--206},
title = {{Event-related coherence and event-related desynchronization/ synchronization in the 10 Hz and 20 Hz EEG during self-paced movements}},
url = {papers3://publication/uuid/029ACA9C-935C-42EE-A83B-130CB9700880},
year = {1997}
}
@incollection{Debener2010,
author = {Debener, Stefan and Thorne, Jeremy and Schneider, Till R and Viola, Filipa Campos},
booktitle = {Simultaneous EEG and fMRI: Recording, Analysis, and Application},
chapter = {3},
publisher = {Oxford University Press},
title = {{Using ICA for the Analysis of Multi-Channel EEG Data}},
year = {2010}
}
@article{Doelling2015,
author = {Doelling, Keith B and Poeppel, David},
doi = {10.1073/pnas.1508431112},
file = {:Users/gmac/mendeley/Doelling, Poeppel/Doelling, Poeppel - 2015 - Cortical entrainment to music and its modulation by expertise.pdf:pdf},
journal = {PNAS},
pages = {1--10},
pmid = {26504238},
title = {{Cortical entrainment to music and its modulation by expertise}},
year = {2015}
}
@article{Nozaradan2017a,
abstract = {How specific brain networks track rhythmic sensory input over time remains a challenge in neuroimaging work. Here we show that subcortical areas, namely the basal ganglia and the cerebellum, specifically contribute to the neural tracking of rhythm. We tested patients with focal lesions in either of these areas and healthy controls by means of electroencephalography (EEG) while they listened to rhythmic sequences known to induce selective neural tracking at a frequency corresponding to the most-often perceived pulse-like beat. Both patients and controls displayed neural responses to the rhythmic sequences. However, these response patterns were different across groups, with patients showing reduced tracking at beat frequency, especially for the more challenging rhythms. In the cerebellar patients, this effect was specific to the rhythm played at a fast tempo, which places high demands on the temporally precise encoding of events. In contrast, basal ganglia patients showed more heterogeneous responses at beat frequency specifically for the most complex rhythm, which requires more internal generation of the beat. These findings provide electrophysiological evidence that these subcortical structures selectively shape the neural representation of rhythm. Moreover, they suggest that the processing of rhythmic auditory input relies on an extended cortico-subcortico-cortical functional network providing specific timing and entrainment sensitivities.},
author = {Nozaradan, Sylvie and Schwartze, Michael and Obermeier, Christian and Kotz, Sonja A.},
doi = {10.1016/j.cortex.2017.08.015},
file = {:Users/gmac/mendeley/Nozaradan et al/Nozaradan et al. - 2017 - Specific contributions of basal ganglia and cerebellum to the neural tracking of rhythm.pdf:pdf},
issn = {19738102},
journal = {Cortex},
keywords = {Auditory processing,Basal ganglia,Cerebellum,EEG,Frequency-tagging,Human brain lesion,Musical rhythm},
pages = {156--168},
publisher = {Elsevier Ltd},
title = {{Specific contributions of basal ganglia and cerebellum to the neural tracking of rhythm}},
url = {https://doi.org/10.1016/j.cortex.2017.08.015},
volume = {95},
year = {2017}
}
@article{Grahn2013a,
abstract = {Perception of temporal patterns is critical for speech, movement, and music. In the auditory domain, perception of a regular pulse, or beat, within a sequence of temporal intervals is associated with basal ganglia activity. Two alternative accounts of this striatal activity are possible: "searching" for temporal regularity in early stimulus processing stages or "prediction' of the timing of future tones after the beat is found (relying on continuation of an internally generated beat). To resolve between these accounts, we used functional magnetic resonance imaging (fMRI) to investigate different stages of beat perception. Participants heard a series of beat and nonbeat (irregular) monotone sequences. For each sequence, the preceding sequence provided a temporal beat context for the following sequence. Beat sequences were preceded by nonbeat sequences, requiring the beat to be found anew ("beat finding" condition), or by beat sequences with the same beat rate ("beat continuation"), or a different rate ("beat adjustment"). Detection of regularity is highest during beat finding, whereas generation and prediction are highest during beat continuation. We found the greatest striatal activity for beat continuation, less for beat adjustment, and the least for beat finding. Thus, the basal ganglia's response profile suggests a role in beat prediction, not in beat finding.},
address = {Centre for Brain and Mind, Department of Psychology, University of Western Ontario, London, Ontario N6A 5B7, Canada. jgrahn@uwo.ca},
author = {Grahn, Jessica A and Rowe, James B},
file = {:Users/gmac/mendeley/Grahn, Rowe/Grahn, Rowe - 2013 - Finding and feeling the musical beat striatal dissociations between detection and prediction of regularity.pdf:pdf},
journal = {Cerebral Cortex},
month = {apr},
number = {4},
pages = {913--921},
title = {{Finding and feeling the musical beat: striatal dissociations between detection and prediction of regularity.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=22499797&retmode=ref&cmd=prlinks papers3://publication/doi/10.1093/cercor/bhs083},
volume = {23},
year = {2013}
}
@article{Hatfield1993,
author = {Hatfield, Elaine and Cacioppo, John T and Rapson, Richard L},
file = {:Users/gmac/mendeley/Hatfield, Cacioppo, Rapson/Hatfield, Cacioppo, Rapson - 1993 - Emotional Contaigion.pdf:pdf},
journal = {Current Directions in Psychological Science},
number = {3},
pages = {96--99},
title = {{Emotional Contaigion}},
volume = {2},
year = {1993}
}
@inproceedings{Hornickel2012,
author = {Hornickel, J and Zecker, S G and Bradlow, Ann R and Kraus, Nina},
booktitle = {Proceedings of the {\ldots}},
file = {:Users/gmac/mendeley/Hornickel et al/Hornickel et al. - 2012 - Assistive listening devices drive neuroplasticity in children with dyslexia.pdf:pdf},
month = {jan},
title = {{Assistive listening devices drive neuroplasticity in children with dyslexia}},
url = {http://www.pnas.org/content/109/41/16731.short papers3://publication/doi/10.1073/pnas.1206628109/-/DCSupplemental},
year = {2012}
}
@article{Etcoff1992,
abstract = {Abstract People universally recognize facial expressions of happiness, sadness, fear, anger, disgust, and perhaps, surprise, suggesting a perceptual mechanism tuned to the facial configuration displaying each emotion. Sets of drawings were generated by computer, ... \n},
author = {Etcoff, Nancy L. and Magee, John J.},
doi = {10.1016/0010-0277(92)90002-Y},
file = {:Users/gmac/mendeley/Etcoff, Magee/Etcoff, Magee - 1992 - Categorical perception of facial expressions.pdf:pdf},
isbn = {0010-0277},
issn = {00100277},
journal = {Cognition},
number = {3},
pages = {227--240},
pmid = {1424493},
title = {{Categorical perception of facial expressions}},
volume = {44},
year = {1992}
}
@article{Abel1990,
author = {Abel, Jennifer L and Larkin, Kevin T},
file = {:Users/gmac/mendeley/Abel, Larkin/Abel, Larkin - 1990 - Anticipation of Performance Among Musicians Physiological Arousal, Confidence, and State-Anxiety.pdf:pdf},
journal = {Psychology of Music},
keywords = {audience},
month = {jan},
pages = {171--182},
title = {{Anticipation of Performance Among Musicians: Physiological Arousal, Confidence, and State-Anxiety}},
url = {papers3://publication/uuid/3A2309B6-7F9B-468F-A0AD-21EBA01261C0},
volume = {18},
year = {1990}
}
@article{Picton2003,
abstract = {Steady - state evoked potentials can be recorded from the human scalp in response to auditory stimuli presented at rates between 1 and 200 Hz or by periodic modulations of the amplitude and/or frequency of a continuous tone. Responses can be objectively detected ... 
},
author = {Picton, T W and John, M S and Dimitrijevic, A and Purcell, David},
file = {:Users/gmac/mendeley/Picton et al/Picton et al. - 2003 - Human auditory steady-state responses.pdf:pdf},
journal = {International Journal of Audiology},
month = {jan},
pages = {177--219},
title = {{Human auditory steady-state responses}},
url = {http://informahealthcare.com/doi/abs/10.3109/14992020309101316 papers3://publication/uuid/79F1F5AD-39D1-4582-96C4-FFA18F4C6B03},
volume = {42},
year = {2003}
}
@article{Besle2011,
abstract = {Previous studies raise the hypothesis that attentional bias in the phase of neocortical excitability fluctuations (oscillations) represents a fundamental mechanism for tuning the brain to the temporal dynamics of task-relevant event patterns. To evaluate this hypothesis, we recorded intracranial electrocortical activity in human epilepsy patients while they performed an audiovisual stream selection task. Consistent with our hypothesis, (1) attentional modulation of oscillatory entrainment operates in a distinct network of areas including auditory, visual, posterior parietal, inferior motor, inferior frontal and superior midline frontal cortex, (2) the degree of oscillatory entrainment depends on the predictability of the stimulus stream, and (3) the attentional phase shift of entrained oscillation cooccurs with classical attentional effects observed on phase-locked evoked activity in sensory-specific areas but seems to operate on entrained low-frequency oscillations that cannot be explained by sensory activity evoked at the rate of stimulation. Thus, attentional entrainment appears to tune a network of brain areas to the temporal dynamics of behaviorally relevant event streams, contributing to its perceptual and behavioral selection.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Besle, Julien and Schevon, Catherine a and Mehta, Ashesh D and Lakatos, Peter and Goodman, Robert R and McKhann, Guy M and Emerson, Ronald G and Schroeder, Charles E},
doi = {10.1523/JNEUROSCI.4518-10.2011},
eprint = {arXiv:1011.1669v3},
file = {:Users/gmac/mendeley/Besle et al/Besle et al. - 2011 - Tuning of the human neocortex to the temporal dynamics of attended events.pdf:pdf},
isbn = {1529-2401 (Electronic)\r0270-6474 (Linking)},
issn = {0270-6474},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
number = {9},
pages = {3176--3185},
pmid = {21368029},
title = {{Tuning of the human neocortex to the temporal dynamics of attended events.}},
volume = {31},
year = {2011}
}
@article{Palmer1989,
author = {Palmer, Caroline},
file = {:Users/gmac/mendeley/Palmer/Palmer - 1989 - Mapping Musical Thought to Musical Performance.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
keywords = {audience,performance},
month = {jan},
number = {12},
pages = {331--346},
publisher = {American Psychological Association},
title = {{Mapping Musical Thought to Musical Performance}},
url = {papers3://publication/uuid/52AC4CB0-B52E-4B3A-BF12-F41A14D4650C},
volume = {15},
year = {1989}
}
@article{Mitchell2014,
author = {Mitchell, Rachel L C and Kingston, Rachel A},
doi = {10.1027/1618-3169/a000241},
file = {:Users/gmac/mendeley/Mitchell, Kingston/Mitchell, Kingston - 2014 - Age-Related Decline in Emotional Prosody Discrimination Acoustic Correlates.pdf:pdf},
journal = {Experimental Psychology},
keywords = {acoustic discrimination,aging,an academic issue,appreciation that even healthy,brings with it age-related,impairment in social cognition,many people associ-,prosody,social cognition,there is now growing,this is not merely},
number = {3},
pages = {215--223},
title = {{Age-Related Decline in Emotional Prosody Discrimination: Acoustic Correlates}},
volume = {61},
year = {2014}
}
@article{Plante1988,
author = {Plante, Thomas G},
file = {:Users/gmac/mendeley/Plante/Plante - 1988 - Postdoctoral Training in Clinical Psychology As Amorphous as an Inkblot.pdf:pdf},
number = {3},
pages = {251--253},
title = {{Postdoctoral Training in Clinical Psychology: As Amorphous as an Inkblot}},
volume = {19},
year = {1988}
}
@article{Bradley2000,
abstract = {Emotional reactions to naturally occurring sounds (e.g., screams, erotica, bombs, etc.) were investigated in two studies. In Experiment 1, subjects rated the pleasure and arousal elicited when listening to each of 60 sounds, followed by an incidental free recall task. The shape of the two-dimensional affective space defined by the mean ratings for each sound was similar to that previously obtained for pictures, and, like memory for pictures, free recall was highest for emotionally arousing stimuli. In Experiment 2, autonomic and facial electromyographic (EMG) activity were recorded while a new group of subjects listened to the same set of sounds; the startle reflex was measured using visual probes. Listening to unpleasant sounds resulted in larger startle reflexes, more corrugator EMG activity, and larger heart rate deceleration compared with listening to pleasant sounds. Electrodermal reactions were larger for emotionally arousing than for neutral materials. Taken together, the data suggest that acoustic cues activate the appetitive and defensive motivational circuits underlying emotional expression in ways similar to pictures.},
author = {Bradley, Margaret M and Lang, Peter J},
doi = {10.1111/1469-8986.3720204},
file = {:Users/gmac/mendeley/Bradley, Lang/Bradley, Lang - 2000 - Affective reactions to acoustic stimuli.pdf:pdf},
isbn = {0048-5772 (Print)},
issn = {0048-5772},
journal = {Psychophysiology},
number = {2},
pages = {204--215},
pmid = {10731770},
title = {{Affective reactions to acoustic stimuli}},
volume = {37},
year = {2000}
}
@article{Iversen2008,
abstract = {Many aspects of perception are known to be shaped by experience, but others are thought to be innate universal properties of the brain. A specific example comes from rhythm perception, where one of the fundamental perceptual operations is the grouping of successive events into higher-level patterns, an operation critical to the perception of language and music. Grouping has long been thought to be governed by innate perceptual principles established a century ago. The current work demonstrates instead that grouping can be strongly dependent on culture. Native English and Japanese speakers were tested for their perception of grouping of simple rhythmic sequences of tones. Members of the two cultures showed different patterns of perceptual grouping, demonstrating that these basic auditory processes are not universal but are shaped by experience. It is suggested that the observed perceptual differences reflect the rhythms of the two languages, and that native language can exert an influence on general auditory perception at a basic level.},
author = {Iversen, John R and Patel, Aniruddh D and Ohgushi, Kengo},
doi = {10.1121/1.2973189},
file = {:Users/gmac/mendeley/Iversen, Patel, Ohgushi/Iversen, Patel, Ohgushi - 2008 - Perception of rhythmic grouping depends on auditory experience.pdf:pdf},
isbn = {1520-8524 (Electronic)\r0001-4966 (Linking)},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {4},
pages = {2263--2271},
pmid = {19062864},
title = {{Perception of rhythmic grouping depends on auditory experience.}},
volume = {124},
year = {2008}
}
@article{Merchant2015,
abstract = {Humans possess an ability to perceive and synchronize movements to the beat in music ('beat perception and synchronization'), and recent neuroscientific data have offered new insights into this beat-finding capacity at multiple neural levels. Here, we review and compare behavioural and neural data on temporal and sequential processing during beat perception and entrainment tasks in macaques (including direct neural recording and local field potential (LFP)) and humans (including fMRI, EEG and MEG). These abilities rest upon a distributed set of circuits that include the motor cortico-basal-ganglia-thalamo-cortical (mCBGT) circuit, where the supplementary motor cortex (SMA) and the putamen are critical cortical and subcortical nodes, respectively. In addition, a cortical loop between motor and auditory areas, connected through delta and beta oscillatory activity, is deeply involved in these behaviours, with motor regions providing the predictive timing needed for the perception of, and entrainment to, musical rhythms. The neural discharge rate and the LFP oscillatory activity in the gamma- and beta-bands in the putamen and SMA of monkeys are tuned to the duration of intervals produced during a beat synchronization-continuation task (SCT). Hence, the tempo during beat synchronization is represented by different interval-tuned cells that are activated depending on the produced interval. In addition, cells in these areas are tuned to the serial-order elements of the SCT. Thus, the underpinnings of beat synchronization are intrinsically linked to the dynamics of cell populations tuned for duration and serial order throughout the mCBGT. We suggest that a cross-species comparison of behaviours and the neural circuits supporting them sets the stage for a new generation of neurally grounded computational models for beat perception and synchronization.},
author = {Merchant, Hugo and Grahn, Jessica A and Trainor, Laurel J and Rohrmeier, Martin and Fitch, W Tecumseh},
doi = {10.1098/rstb.2014.0093},
file = {:Users/gmac/mendeley/Merchant et al/Merchant et al. - 2015 - Finding the beat a neural perspective across humans and non-human primates.pdf:pdf},
isbn = {1471-2970 (Electronic) 0962-8436 (Linking)},
issn = {1471-2970},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {computational biology,neuroscience},
pages = {20140093},
pmid = {25646516},
title = {{Finding the beat: a neural perspective across humans and non-human primates}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25646516},
volume = {370},
year = {2015}
}
@article{Gigerenzer2004,
author = {Gigerenzer, Gerd},
file = {:Users/gmac/mendeley/Gigerenzer/Gigerenzer - 2004 - Mindless statistics.pdf:pdf},
journal = {The Journal of Socio-Economics},
keywords = {stats},
month = {nov},
number = {5},
pages = {587--606},
title = {{Mindless statistics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1053535704000927 papers3://publication/doi/10.1016/j.socec.2004.09.033},
volume = {33},
year = {2004}
}
@article{Juslin1997,
author = {Juslin, Patrik N},
file = {:Users/gmac/mendeley/Juslin/Juslin - 1997 - Emotional Communication in Music Performance A Functionalist Perspective and Some Data.pdf:pdf},
journal = {Music Perception},
month = {jan},
pages = {383--418},
title = {{Emotional Communication in Music Performance: A Functionalist Perspective and Some Data}},
url = {papers3://publication/uuid/1A46B850-90B2-4C51-8767-9FFB1FCD1EAD},
volume = {14},
year = {1997}
}
@article{Seger2013,
author = {Seger, Carol A and Spiering, Brian J and Sares, Anastasia G and Quraini, Sarah I and Alpeter, Catherine and David, James and Thaut, Michael H},
file = {:Users/gmac/mendeley/Seger et al/Seger et al. - 2013 - Corticostriatal Contributions to Musical Expectancy Perception.pdf:pdf},
journal = {Multiple values selected},
month = {jul},
number = {7},
pages = {1062--1077},
title = {{Corticostriatal Contributions to Musical Expectancy Perception}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/jocn_a_00371 papers3://publication/doi/10.1038/nrn2152},
volume = {25},
year = {2013}
}
@article{Stupacher2013,
abstract = {Groove is often described as a musical quality that can induce movement in a listener. This study examines the effects of listening to groove music on corticospinal excitability. Musicians and non-musicians listened to high-groove music, low-groove music, and spectrally matched noise, while receiving single-pulse transcranial magnetic stimulation (TMS) over the primary motor cortex either on-beat or off-beat. We examined changes in the amplitude of the motor-evoked potentials (MEPs), recorded from hand and arm muscles, as an index of activity within the motor system. Musicians and non-musicians rated groove similarly. MEP results showed that high-groove music modulated corticospinal excitability, whereas no difference occurred between low-groove music and noise. More specifically, musicians' MEPs were larger with high-groove than low-groove music, and this effect was especially pronounced for on-beat compared to off-beat pulses. These results indicate that high-groove music increasingly engages the motor system, and the temporal modulation of corticospinal excitability with the beat could stem from tight auditory-motor links in musicians. Conversely, non-musicians' MEPs were smaller for high-groove than low-groove music, and there was no effect of on- versus off-beat pulses, potentially stemming from suppression of overt movement. In sum, high-groove music engages the motor system, and previous training modulates how listening to music with a strong groove activates the motor system. {\textcopyright} 2013 Elsevier Inc.},
author = {Stupacher, Jan and Hove, Michael J and Novembre, Giacomo and Sch{\"{u}}tz-Bosbach, Simone and Keller, Peter E},
doi = {10.1016/j.bandc.2013.03.003},
file = {:Users/gmac/mendeley/Stupacher et al/Stupacher et al. - 2013 - Musical groove modulates motor cortex excitability A TMS investigation.pdf:pdf},
isbn = {0278-2626},
issn = {02782626},
journal = {Brain and Cognition},
month = {jul},
number = {2},
pages = {127--136},
pmid = {23660433},
title = {{Musical groove modulates motor cortex excitability: A TMS investigation}},
url = {http://dx.doi.org/10.1016/j.bandc.2013.03.003},
volume = {82},
year = {2013}
}
@article{Pfurtscheller1999,
author = {Pfurtscheller, G and {Lopes da Silva}, F H},
file = {:Users/gmac/mendeley/Pfurtscheller, Lopes da Silva/Pfurtscheller, Lopes da Silva - 1999 - Event-related EEGMEG synchronization and desynchronization basic principles.pdf:pdf},
journal = {Clinical Neurophysiology},
month = {jan},
pages = {1842--1857},
title = {{Event-related EEG/MEG synchronization and desynchronization: basic principles}},
url = {papers3://publication/uuid/EA072609-2E08-434F-B4D1-5BD79464E019},
volume = {110},
year = {1999}
}
@article{Patel2005,
annote = {beat—a perceived pulse that marks equally spaced points in time
meter—multiple levels of periodicity in rhythmic structure, i.e., periodicity at multiple time scales

A metrical sequence, however, excites several oscillators with periods which are multiples of the basic beat period. Due to the coupling, these different oscil- lators are drawn into a stable relationship with each other.},
author = {Patel, Aniruddh D and Iversen, John R and Chen, Yanqing and Repp, Bruno H},
file = {:Users/gmac/mendeley/Patel et al/Patel et al. - 2005 - The influence of metricality and modality on synchronization with a beat.pdf:pdf},
journal = {Experimental Brain Research},
month = {jan},
number = {2},
pages = {226--238},
title = {{The influence of metricality and modality on synchronization with a beat}},
url = {http://link.springer.com/10.1007/s00221-004-2159-8 papers3://publication/doi/10.1007/s00221-004-2159-8},
volume = {163},
year = {2005}
}
@article{Mehu2015,
author = {Mehu, Marc and Scherer, Klaus R},
file = {:Users/gmac/mendeley/Mehu, Scherer/Mehu, Scherer - 2015 - Emotion Emotion Categories and Dimensions in the Facial Communication of Affect An Integrated Approach Emotion C.pdf:pdf},
keywords = {10,1037,a0039416,discrete emotions,doi,dx,emotional communication,emotional dimensions,facial behavior,facs,http,org,supp,supplemental materials},
number = {6},
pages = {798--811},
title = {{Emotion Emotion Categories and Dimensions in the Facial Communication of Affect : An Integrated Approach Emotion Categories and Dimensions in the Facial Communication of Affect : An Integrated Approach}},
volume = {15},
year = {2015}
}
@article{Grahn2009,
abstract = {Little is known about the underlying neurobiology of rhythm and beat perception, despite its universal cultural importance. Here we used functional magnetic resonance imaging to study rhythm perception in musicians and nonmusicians. Three conditions varied in the degree to which external reinforcement versus internal generation of the beat was required. The “volume” condition strongly externally marked the beat with volume changes, the “duration” condition marked the beat with weaker accents arising from duration changes,and the “unaccented” condition required the beat to be entirely internally generated. In all conditions, beat rhythms compared with nonbeat control rhythms revealed putamen activity.The presence of a beat was also associated with greater connectivity between the putamen and the supplementary motor area (SMA), the premotor cortex (PMC), and auditory cortex. In contrast, the type of accent within the beat conditions modulated the coupling between premotor and auditory cortex, with greater modulation for musicians than nonmusicians. Importantly, the response of the putamen to beat conditions was not attributable to differences in temporal complexity between the three rhythm conditions. We propose that a cortico-subcortical network including the putamen, SMA, and PMC is engaged for the analysis of temporal sequences and prediction or generation of putative beats, especially under conditions that may require internal generation of the beat. The importance of this system for auditory–motor interaction and development of precisely timed movement is suggested here by its facilitation in musicians.},
author = {Grahn, Jessica A and Rowe, James B},
file = {:Users/gmac/mendeley/Grahn, Rowe/Grahn, Rowe - 2009 - Feeling the Beat Premotor and Striatal Interactions in Musicians and Nonmusicians during Beat Perception.pdf:pdf},
journal = {Journal of Neuroscience},
month = {jun},
number = {23},
pages = {7540--7548},
title = {{Feeling the Beat: Premotor and Striatal Interactions in Musicians and Nonmusicians during Beat Perception}},
url = {http://www.jneurosci.org/cgi/content/abstract/29/23/7540 papers3://publication/doi/10.1523/JNEUROSCI.2018-08.2009},
volume = {29},
year = {2009}
}
@article{Ben-Haim2013,
author = {Ben-Haim, Moshe Shay and Eitan, Zohar and Chajut, Eran},
file = {:Users/gmac/mendeley/Ben-Haim, Eitan, Chajut/Ben-Haim, Eitan, Chajut - 2013 - Pitch Memory and Exposure Effects.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
month = {jan},
publisher = {American Psychological Association},
title = {{Pitch Memory and Exposure Effects}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0033583 papers3://publication/doi/10.1037/a0033583},
year = {2013}
}
@article{Chapin2010a,
abstract = {The aim of this study was to explore the role of attention in pulse and meter perception using complex rhythms. We used a selective attention paradigm in which participants attended to either a complex auditory rhythm or a visually presented word list. Performance on a reproduction task was used to gauge whether participants were attending to the appropriate stimulus. We hypothesized that attention to complex rhythms - which contain no energy at the pulse frequency - would lead to activations in motor areas involved in pulse perception. Moreover, because multiple repetitions of a complex rhythm are needed to perceive a pulse, activations in pulse-related areas would be seen only after sufficient time had elapsed for pulse perception to develop. Selective attention was also expected to modulate activity in sensory areas specific to the modality. We found that selective attention to rhythms led to increased BOLD responses in basal ganglia, and basal ganglia activity was observed only after the rhythms had cycled enough times for a stable pulse percept to develop. These observations suggest that attention is needed to recruit motor activations associated with the perception of pulse in complex rhythms. Moreover, attention to the auditory stimulus enhanced activity in an attentional sensory network including primary auditory cortex, insula, anterior cingulate, and prefrontal cortex, and suppressed activity in sensory areas associated with attending to the visual stimulus.},
author = {Chapin, Heather L and Zanto, Theodore P and Jantzen, Kelly J and Kelso, Scott J a and Steinberg, Fred and Large, Edward W},
doi = {10.3389/fpsyg.2010.00224},
file = {:Users/gmac/mendeley/Chapin et al/Chapin et al. - 2010 - Neural responses to complex auditory rhythms the role of attending.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in psychology},
keywords = {attention,auditory perception,fmri,rhythm,timing},
month = {jan},
number = {December},
pages = {224},
pmid = {21833279},
title = {{Neural responses to complex auditory rhythms: the role of attending.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3153829&tool=pmcentrez&rendertype=abstract},
volume = {1},
year = {2010}
}
@article{Rogalsky2011,
author = {Rogalsky, Corianne and Rong, Feng and Saberi, Kourosh and Hickok, Gregory},
file = {:Users/gmac/mendeley/Rogalsky et al/Rogalsky et al. - 2011 - Functional Anatomy of Language and Music Perception Temporal and Structural Factors Investigated Using Function.pdf:pdf},
journal = {The Journal of Neuroscience},
month = {mar},
number = {10},
pages = {3843--3852},
title = {{Functional Anatomy of Language and Music Perception: Temporal and Structural Factors Investigated Using Functional Magnetic Resonance Imaging}},
url = {papers3://publication/doi/10.1523/JNEUROSCI.4515-10.2011},
volume = {31},
year = {2011}
}
@article{Teki2012,
abstract = {Accurate timing is an integral aspect of sensory and motor processes such as the perception of speech and music and the execution of skilled movement.},
annote = {- movement is time, expressed
- duration-based timing: measurement of the absolute duration of discrete time intervals ($\Delta$Ti)
- beat-based timing: measurement of the duration of time intervals relative to a temporal regularity such as beats ($\Delta$Ti / T beat)

- functional dissociation (Teki et al., 2011) -->
-- duration-based timing (each interval has to be measured anew): olivocerebellar network comprising the inferior olive and the cerebellum, including the dentate nucleus and vermis
-- beat-based timing: striato-thalamo-cortical network comprising the putamen, caudate, thalamus, pre-SMA/SMA, premotor, and dorsolateral prefrontal cortex

- The unified model is asymmetrical in that the absolute timing mechanisms in the cerebellum finesse the more adaptive relative timing mechanisms in the striatum},
author = {Teki, Sundeep and Grube, Manon and Griffiths, Timothy D},
file = {:Users/gmac/mendeley/Teki, Grube, Griffiths/Teki, Grube, Griffiths - 2012 - A unified model of time perception accounts for duration-based and beat-based timing mechanisms.pdf:pdf},
journal = {Frontiers in Integrative Neuroscience},
month = {jan},
number = {90},
pages = {1--7},
title = {{A unified model of time perception accounts for duration-based and beat-based timing mechanisms}},
url = {http://www.frontiersin.org/Integrative_Neuroscience/10.3389/fnint.2011.00090/abstract papers3://publication/doi/10.3389/fnint.2011.00090/abstract},
volume = {5},
year = {2012}
}
@article{Nagai2004,
abstract = {We examined neural activity related to modulation of skin conductance level (SCL), an index of sympathetic tone, using functional magnetic resonance imaging (fMRI) while subjects performed biofeedback arousal and relaxation tasks. Neural activity within the ventromedial prefrontal cortex (VMPFC) and the orbitofrontal cortex (OFC) covaried with skin conductance level (SCL), irrespective of task. Activity within striate and extrastriate cortices, anterior cingulate and insular cortices, thalamus, hypothalamus and lateral regions of prefrontal cortex reflected the rate of change in electrodermal activity, highlighting areas supporting transient skin conductance responses (SCRs). Successful performance of either biofeedback task (where SCL changed in the intended direction) was associated with enhanced activity in mid-OFC. The findings point to a dissociation between neural systems controlling basal sympathetic tone (SCL) and transient skin conductance responses (SCRs). The level of activity in VMPFC has been related to a default mode of brain function and our findings provide a physiological account of this state, indicating that activity within VMPFC and OFC reflects a dynamic between exteroceptive and interoceptive deployment of attention. {\textcopyright} 2004 Elsevier Inc. All rights reserved.},
author = {Nagai, Y. and Critchley, H. D. and Featherstone, E. and Trimble, M. R. and Dolan, R. J.},
doi = {10.1016/j.neuroimage.2004.01.019},
file = {:Users/gmac/mendeley/Nagai et al/Nagai et al. - 2004 - Activity in ventromedial prefrontal cortex covaries with sympathetic skin conductance level A physiological accoun.pdf:pdf},
isbn = {1053-8119 (Print)\n1053-8119 (Linking)},
issn = {10538119},
journal = {NeuroImage},
keywords = {Biofeedback,Skin conductance,fMRI},
number = {1},
pages = {243--251},
pmid = {15110014},
title = {{Activity in ventromedial prefrontal cortex covaries with sympathetic skin conductance level: A physiological account of a "default mode" of brain function}},
volume = {22},
year = {2004}
}
@article{Leveque2015,
abstract = {Neuropsychologia, 70 + (2015) 58-63. doi:10.1016/j.neuropsychologia.2015.02.012},
author = {L{\'{e}}v{\^{e}}que, Yohana and Sch{\"{o}}n, Daniele},
file = {:Users/gmac/mendeley/L{\'{e}}v{\^{e}}que, Sch{\"{o}}n/L{\'{e}}v{\^{e}}que, Sch{\"{o}}n - 2015 - Modulation of the motor cortex during singing-voice perception.pdf:pdf},
journal = {Neuropsychologia},
month = {apr},
number = {C},
pages = {58--63},
publisher = {Elsevier Ltd},
title = {{Modulation of the motor cortex during singing-voice perception}},
url = {http://dx.doi.org/10.1016/j.neuropsychologia.2015.02.012 papers3://publication/doi/10.1016/j.neuropsychologia.2015.02.012},
volume = {70},
year = {2015}
}
@article{Ekman1976,
abstract = {A procedure has been developed for measuring visibly different facial movements. The Facial Action Code was derived from an analysis of the anatomical basis of facial movement. The method can be used to describe any facial movement (observed in photographs, motion picture film or videotape) in terms of anatomically based action units. The development of the method is explained, contrasting it to other methods of measuring facial behavior. An example of how facial behavior is measured is provided, and ideas about research applications are discussed. {\textcopyright} 1976 Human Sciences Press.},
author = {Ekman, Paul and Friesen, Wallace V.},
doi = {10.1007/BF01115465},
file = {:Users/gmac/mendeley/Ekman, Friesen/Ekman, Friesen - 1976 - Measuring facial movement.pdf:pdf},
isbn = {03613496 (ISSN)},
issn = {03613496},
journal = {Environmental Psychology and Nonverbal Behavior},
pages = {56--75},
title = {{Measuring facial movement}},
volume = {1},
year = {1976}
}
@article{Krigolson2017,
author = {Krigolson, Olave E. and Williams, Chad C. and Norton, Angela and Hassall, Cameron D. and Colino, Francisco L.},
doi = {10.3389/fnins.2017.00109},
file = {:Users/gmac/mendeley/Krigolson et al/Krigolson et al. - 2017 - Choosing MUSE Validation of a Low-Cost, Portable EEG System for ERP Research.pdf:pdf},
issn = {1662-453X},
journal = {Frontiers in Neuroscience},
keywords = {EEG, ERP, portable electronics, cognitive science,,cognitive science,eeg,erp,executive function,portable electronics},
number = {March},
pages = {1--10},
title = {{Choosing MUSE: Validation of a Low-Cost, Portable EEG System for ERP Research}},
url = {http://journal.frontiersin.org/article/10.3389/fnins.2017.00109/full},
volume = {11},
year = {2017}
}
@article{Parbery-Clark2009,
author = {Parbery-Clark, A and Skoe, E and Kraus, Nina},
file = {:Users/gmac/mendeley/Parbery-Clark, Skoe, Kraus/Parbery-Clark, Skoe, Kraus - 2009 - Musical Experience Limits the Degradative Effects of Background Noise on the Neural Processing of So.pdf:pdf},
journal = {Journal of Neuroscience},
month = {nov},
number = {45},
pages = {14100--14107},
title = {{Musical Experience Limits the Degradative Effects of Background Noise on the Neural Processing of Sound}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3256-09.2009 papers3://publication/doi/10.1523/JNEUROSCI.3256-09.2009},
volume = {29},
year = {2009}
}
@article{Henry2014,
author = {Henry, Molly J and Herrmann, Bjorn},
file = {:Users/gmac/mendeley/Henry, Herrmann/Henry, Herrmann - 2014 - Low-Frequency Neural Oscillations Support Dynamic Attending in Temporal Context.pdf:pdf},
journal = {Timing & Time Perception},
month = {jan},
number = {1},
pages = {62--86},
title = {{Low-Frequency Neural Oscillations Support Dynamic Attending in Temporal Context}},
url = {http://booksandjournals.brillonline.com/content/journals/10.1163/22134468-00002011 papers3://publication/doi/10.1163/22134468-00002011},
volume = {2},
year = {2014}
}
@article{Makeig2004,
author = {Makeig, Scott and Debener, Stefan and Onton, Julie and Delorme, Arnaud},
file = {:Users/gmac/mendeley/Makeig et al/Makeig et al. - 2004 - Mining event-related brain dynamics.pdf:pdf},
journal = {Trends in Cognitive Sciences},
month = {may},
number = {5},
pages = {204--210},
publisher = {Elsevier Ltd},
title = {{Mining event-related brain dynamics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661304000816 papers3://publication/doi/10.1016/j.tics.2004.03.008},
volume = {8},
year = {2004}
}
@article{Russo2013,
abstract = {Listening to music often leads to physiological responses.},
author = {Russo, Frank A and Vempala, Naresh N and Sandstrom, Gillian M},
file = {:Users/gmac/mendeley/Russo, Vempala, Sandstrom/Russo, Vempala, Sandstrom - 2013 - Predicting musically induced emotions from physiological inputs linear and neural network models.pdf:pdf},
journal = {Frontiers in Psychology},
month = {aug},
pages = {1--8},
title = {{Predicting musically induced emotions from physiological inputs: linear and neural network models}},
url = {https://doi.org/10.3389/fpsyg.2013.00468},
volume = {4},
year = {2013}
}
@article{Dalton2003a,
abstract = {Purpose:The authors investigate the impact of hearing loss on quality of life in a large population of older adults.Design and Methods:Data are from the 5-year follow-up Epidemiology of Hearing Loss Study, a population-based longitudinal study of age-related hearing impairment conducted in Beaver Dam, WI. Participants (N = 2,688) were 53-97 years old (mean = 69 years) and 42% were male. Difficulties with communication were assessed by using the Hearing Handicap for the Elderly--Screening version (HHIE-S), with additional questions regarding communication difficulties in specific situations. Health-related quality of life was assessed by using measures of activities of daily living (ADLs), instrumental ADLs (IADLs) and the Short Form 36 Health Survey (SF-36). Hearing loss measured by audiometry was categorized on the basis of the pure-tone average of hearing thresholds at 0.5, 1, 2, and 4 kHz.Results:Of participants, 28% had a mild hearing loss and 24% had a moderate to severe hearing loss. Severity of hearing loss was significantly associated with having a hearing handicap and with self-reported communication difficulties. Individuals with moderate to severe hearing loss were more likely than individuals without hearing loss to have impaired ADLs and IADLs. Severity of hearing loss was significantly associated with decreased function in both the Mental Component Summary score and the Physical Component Summary score of the SF-36 as well as with six of the eight individual domain scores.Implications:Severity of hearing loss is associated with reduced quality of life in older adults.},
author = {Dalton, D. S. and Cruickshanks, K. J. and Klein, B. E. K. and Klein, R. and Wiley, T. L. and Nondahl, D. M.},
doi = {10.1093/geront/43.5.661},
file = {:Users/gmac/mendeley/Dalton et al/Dalton et al. - 2003 - The impact of hearing loss on quality of life in older adults(2).pdf:pdf},
isbn = {0016-9013 (Print) 0016-9013 (Linking)},
issn = {0016-9013},
journal = {The Gerontologist},
keywords = {activities,aging,epidemiology,sf-36},
number = {5},
pages = {661--668},
pmid = {14570962},
title = {{The impact of hearing loss on quality of life in older adults}},
url = {http://gerontologist.oxfordjournals.org/content/43/5/661.short%5Cnhttp://gerontologist.oxfordjournals.org/cgi/doi/10.1093/geront/43.5.661},
volume = {43},
year = {2003}
}
@article{Brown2010,
author = {Brown, Lesley A and de Bruin, Natalie and Doan, Jon B and Suchowersky, Oksana and Hu, Bin},
file = {:Users/gmac/mendeley/Brown et al/Brown et al. - 2010 - Obstacle crossing among people with Parkinson disease is influenced by concurrent music.pdf:pdf},
journal = {The Journal of Rehabilitation Research and Development},
month = {jan},
number = {3},
pages = {225},
title = {{Obstacle crossing among people with Parkinson disease is influenced by concurrent music}},
url = {http://www.rehab.research.va.gov/jour/10/473/pdf/brown.pdf papers3://publication/doi/10.1682/JRRD.2009.10.0171},
volume = {47},
year = {2010}
}
@article{Ward2010,
author = {Ward, Lawrence M and MacLean, Shannon E and Kirschner, Aaron},
editor = {Valdes-Sosa, Pedro Antonio},
file = {:Users/gmac/mendeley/Ward, MacLean, Kirschner/Ward, MacLean, Kirschner - 2010 - Stochastic Resonance Modulates Neural Synchronization within and between Cortical Sources.pdf:pdf},
journal = {PLoS ONE},
month = {dec},
number = {12},
pages = {e14371},
title = {{Stochastic Resonance Modulates Neural Synchronization within and between Cortical Sources}},
url = {http://dx.plos.org/10.1371/journal.pone.0014371 papers3://publication/doi/10.1371/journal.pone.0014371},
volume = {5},
year = {2010}
}
@article{Shahin2008,
author = {Shahin, Antoine J and Roberts, Larry E and Chau, Wilkin and Trainor, Laurel J and Miller, Lee M},
file = {:Users/gmac/mendeley/Shahin et al/Shahin et al. - 2008 - Music training leads to the development of timbre-specific gamma band activity.pdf:pdf},
journal = {NeuroImage},
month = {may},
number = {1},
pages = {113--122},
title = {{Music training leads to the development of timbre-specific gamma band activity}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811908001092 papers3://publication/doi/10.1016/j.neuroimage.2008.01.067},
volume = {41},
year = {2008}
}
@article{Ezzyat2011,
author = {Ezzyat, Y and Davachi, L},
file = {:Users/gmac/mendeley/Ezzyat, Davachi/Ezzyat, Davachi - 2011 - What Constitutes an Episode in Episodic Memory.pdf:pdf},
journal = {Psychological Science},
month = {feb},
number = {2},
pages = {243--252},
title = {{What Constitutes an Episode in Episodic Memory?}},
url = {http://pss.sagepub.com/lookup/doi/10.1177/0956797610393742 papers3://publication/doi/10.1177/0956797610393742},
volume = {22},
year = {2011}
}
@article{Arefi2017,
abstract = {Background and Aim: Understanding emotion is crucial for human social interactions. Ampli- tude compression in hearing aids affects acous- tical characteristics of incoming sound, which is necessary for emotion recognition. The present study investigated this effect(s). Methods: Hearing aid amplitude compression on Persian emotional speech database (ESD) was simulated using MATLAB software. Three types of hearing loss including high tone loss (HTL), low tone loss (LTL), and flat were sim- ulated using three amplification methods, i.e. fast-acting compression (FAC), slow-acting compression (SAC), and linear. Forty normal hearing young adult subjects (aged 20-35 years, mean and SD: 26.98±4.50) with no depression participated in this study. Emotion recognition before and after hearing aid compression simu- lation was compared statistically using indepen- dent t-test considering p<0.05 as the signifi- cance level. Results: Fear, sad, angry, and happy emotion recognition are statistically different in all three types of simulated hearing loss, whereas disgustemotion recognition is affected only in LTL. There is no statistical difference in neutral emotion recognition in all three types of sim- ulated hearing loss. There are significant diff- erences in sad, angry, and happy emotion reco- gnition in FAC while SAC does not affect statistical differences in all emotions except in happy utterance. Fear, sad, and angry emotion recognition are statistically different in linear amplification. Conclusion: Emotion recognition reduces hear- ing aid amplitude compression simulation. Sta- tistically significant differences in emotion reco- gnition depend on emotions such as happy, fear, angry, type of simulated hearing loss such as HTL, LTL, and flat; amplification methods such as FAC, SAC, and linear.},
author = {Arefi, Hossein Namvar and Sameni, Seyed Jalal and Jalilvand, Hamid and Kamali, Mohammad},
file = {:Users/gmac/mendeley/Arefi et al/Arefi et al. - 2017 - Effect of hearing aid amplitude compression on emotional speech recognition.pdf:pdf},
isbn = {0098212222},
journal = {Auditory and Vestibular Research},
keywords = {Emotional speech,amplitude compression,emotion,emotion perception,emotional speech,hearing aid,perception},
mendeley-tags = {Emotional speech,amplitude compression,emotion perception,hearing aid},
number = {4},
pages = {1--8},
title = {{Effect of hearing aid amplitude compression on emotional speech recognition}},
volume = {26},
year = {2017}
}
@book{Lerdahl1983,
address = {Cambridge, MA},
author = {Lerdahl, F A and Jackendoff, R S},
month = {jan},
publisher = {MIT Press},
title = {{A Generative Theory of Tonal Music}},
year = {1983}
}
@article{Parncutt1994,
abstract = {In Experiment 1, six cyclically repeating interonset interval patterns (1,2:1,2:1:1,3:2:1,3:1:2, and 2:1:1:2) were each presented at six different note rates (very slow to very fast). Each trial began at a random point in the rhythmic cycle. Listeners were asked to tap along with the underlying beat or pulse. The number of times a given pulse (period, phase) was selected was taken as a measure of its perceptual salience. Responses gravitated toward a moderate pulse period of about 700 ms. At faster tempi, taps coincided more often with events followed by longer interonset intervals. In Experiment 2, listeners heard the same set of rhythmic patterns, plus a single sound in a different timbre, and were asked whether the extra sound fell on or off the beat. The position of the downbeat was found to be quite ambiguous. A quantitative model was developed from the following assumptions. The phenomenal accent of an event depends on the interonset interval that follows it, saturating for interonset intervals greater than about 1 s. The salience of a pulse sensation depends on the number of events matching a hypothetical isochronous template, and on the period of the template—pulse sensations are most salient in the vicinity of roughly 100 events per minute (moderate tempo). The metrical accent of an event depends on the saliences of pulse sensations including that event. Calculated pulse saliences and metrical accents according to the model agree well with experimental results (r > 0.85). The model may be extended to cover perceived meter, perceptible subdivisions of a beat, categorical perception, expressive timing, temporal precision and discrimination, and primacy/recency effects. The sensation of pulse may be the essential factor distinguishing musical rhythm from nonrhythm.},
author = {Parncutt, Richard},
doi = {10.2307/40285633},
file = {:Users/gmac/mendeley/Parncutt/Parncutt - 1994 - A perceptual model of pulse salience and metrical accent in musical rhythms.pdf:pdf},
isbn = {0730-7829},
issn = {07307829},
journal = {Music Perception},
number = {4},
pages = {409--464},
title = {{A perceptual model of pulse salience and metrical accent in musical rhythms}},
url = {http://www.jstor.org/stable/10.2307/40285633},
volume = {11},
year = {1994}
}
@article{Likowski2012,
abstract = {Numerous studies have shown that humans automatically react with congruent facial reactions, i.e., facial mimicry, when seeing a vis-{\'{a}}-vis' facial expressions. The current experiment is the first investigating the neuronal structures responsible for differences in the occurrence of such facial mimicry reactions by simultaneously measuring BOLD and facial EMG in an MRI scanner. Therefore, 20 female students viewed emotional facial expressions (happy, sad, and angry) of male and female avatar characters. During picture presentation, the BOLD signal as well as M. zygomaticus major and M. corrugator supercilii activity were recorded simultaneously. Results show prototypical patterns of facial mimicry after correction for MR-related artifacts: enhanced M. zygomaticus major activity in response to happy and enhanced M. corrugator supercilii activity in response to sad and angry expressions. Regression analyses show that these congruent facial reactions correlate significantly with activations in the IFG, SMA, and cerebellum. Stronger zygomaticus reactions to happy faces were further associated to increased activities in the caudate, MTG, and PCC. Corrugator reactions to angry expressions were further correlated with the hippocampus, insula, and STS. Results are discussed in relation to core and extended models of the mirror neuron system (MNS).},
author = {Likowski, Katja U and M{\"{u}}hlberger, Andreas and Gerdes, Antje B M and Wieser, Matthias J and Pauli, Paul and Weyers, Peter},
doi = {10.3389/fnhum.2012.00214},
file = {:Users/gmac/mendeley/Likowski et al/Likowski et al. - 2012 - Facial mimicry and the mirror neuron system simultaneous acquisition of facial electromyography and functional.pdf:pdf},
isbn = {1662-5161},
issn = {1662-5161},
journal = {Frontiers in human neuroscience},
keywords = {emg,fmri,mimicry,mimicry, EMG, fMRI, mirror neuron system,mirror neuron system},
number = {July},
pages = {214},
pmid = {22855675},
title = {{Facial mimicry and the mirror neuron system: simultaneous acquisition of facial electromyography and functional magnetic resonance imaging.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3405279&tool=pmcentrez&rendertype=abstract},
volume = {6},
year = {2012}
}
@article{Large2009,
annote = {- "When participants tapped the pulse of complex rhythms containing embedded phase and tempo perturbations, ...adaptation to perturbations at each tapping frequency reflected information from other metrical levels."
- "...listeners attend to multiple levels of temporal structure under a wide variety of task conditions."
- "Interaction of excitatory and inhibitory neural populations can give rise to neural oscillation"
- "Oscillatory brain activity ... can reflect object representations as opposed to mere sensory encoding of stimulus features"
- "We propose that anticipatory rhythmic bursts of beta activity may enable communication between auditory and motor cortices in rhythm perception and motor coordination. Rhythmic bursts of higher-frequency gamma activity may also enable functional communication between different cortical regions."
- Such oscillations may embody dynamic attending to a rhythmic stimulus, such that the oscillations at both timescales serve to configure the neural network responsible for responding in a given task situation},
author = {Large, Edward W and Snyder, Joel S},
file = {:Users/gmac/mendeley/Large, Snyder/Large, Snyder - 2009 - Pulse and Meter as Neural Resonance.pdf:pdf},
journal = {Annals of the New York Academy of Sciences},
month = {jul},
pages = {46--57},
title = {{Pulse and Meter as Neural Resonance}},
url = {http://doi.wiley.com/10.1111/j.1749-6632.2009.04550.x},
volume = {1169},
year = {2009}
}
@article{Cirelli2014,
author = {Cirelli, Laura K. and Bosnyak, Dan and Manning, Fiona C. and Spinelli, Christina and Marie, C{\~{A}}{\textcopyright}line and Fujioka, Takako and Ghahremani, Ayda and Trainor, Laurel J},
doi = {10.3389/fpsyg.2014.00742},
file = {:Users/gmac/mendeley/Cirelli et al/Cirelli et al. - 2014 - Beat-induced fluctuations in auditory cortical beta-band activity using EEG to measure age-related changes.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in Psychology},
keywords = {child development,eeg,electroenceph,electroencephalography,musical rhythm,neural oscillation,time perception},
number = {July},
pages = {1--9},
title = {{Beat-induced fluctuations in auditory cortical beta-band activity: using EEG to measure age-related changes}},
url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2014.00742/abstract},
volume = {5},
year = {2014}
}
@article{Thut2011a,
abstract = {Current Biology, 21 (2011) 1176-1185. doi:10.1016/j.cub.2011.05.049},
author = {Thut, Gregor and Veniero, Domenica and Romei, Vincenzo and Miniussi, Carlo and Schyns, Philippe and Gross, Joachim},
file = {:Users/gmac/mendeley/Thut et al/Thut et al. - 2011 - Rhythmic TMS Causes Local Entrainment of Natural Oscillatory Signatures.pdf:pdf},
journal = {Current Biology},
month = {jul},
number = {14},
pages = {1176--1185},
publisher = {Elsevier Ltd},
title = {{Rhythmic TMS Causes Local Entrainment of Natural Oscillatory Signatures}},
url = {http://dx.doi.org/10.1016/j.cub.2011.05.049 papers3://publication/doi/10.1016/j.cub.2011.05.049},
volume = {21},
year = {2011}
}
@article{Novembre2012,
abstract = {The capacity to distinguish between one's own and others' behavior is a cognitive prerequisite for successful joint action. We employed a musical joint action task to investigate how the brain achieves this distinction. Pianists performed the right-hand part of piano pieces, previously learned bimanually, while the complementary left-hand part either was not executed or was (believed to be) played by a co-performer. This experimental setting served to induce a co-representation of the left-hand part reflecting either the self or the co-performer. Single-pulse transcranial magnetic stimulation was applied to the right primary motor cortex and motor-evoked potentials (MEPs) were recorded from the resting left forearm. Results show that corticospinal excitability was modulated by whether the representation of the left hand was associated with the self or the other, with the MEP amplitude being low and high, respectively. This result remained unchanged in a separate session where participants could neither see nor hear the other but still infer his presence by means of contextual information. Furthermore, the amplitude of MEPs associated with co-performer presence increased with pianists' self-reported empathy. Thus, the sociality of the context modulates action attribution at the level of the motor control system.},
author = {Novembre, Giacomo and Ticini, Luca F. and Sch{\"{u}}tz-Bosbach, Simone and Keller, Peter E.},
doi = {10.1093/cercor/bhr364},
file = {:Users/gmac/mendeley/Novembre et al/Novembre et al. - 2012 - Distinguishing self and other in joint action. Evidence from a musical paradigm.pdf:pdf},
isbn = {1460-2199 (Electronic) 1047-3211 (Linking)},
issn = {10473211},
journal = {Cerebral Cortex},
keywords = {agency,corticospinal excitability,joint action,music,social context},
number = {12},
pages = {2894--2903},
pmid = {22235034},
title = {{Distinguishing self and other in joint action. Evidence from a musical paradigm}},
volume = {22},
year = {2012}
}
@article{Lewin1937,
author = {Lewin, Kurt},
file = {:Users/gmac/mendeley/Lewin/Lewin - 1937 - Carl Stumpf.pdf:pdf},
journal = {The Psychological Review},
month = {may},
pages = {189--194},
title = {{Carl Stumpf}},
url = {papers3://publication/uuid/98DDE059-BC6E-4DC2-9BD4-5744E3A0EB08},
volume = {44},
year = {1937}
}
@article{Akerlind2010,
abstract = {Discussions of the nature and purpose of postdoctoral contract research positions is an area where assumptions and stereotypes tend to predominate. This is due to (a) recent changes in the higher education sector that have impacted on postdoctoral positions in a way that conflicts with traditional expectations, and (b) a relative lack of data and publications on postdoctoral positions, which creates a climate in which stereotypes can continue relatively unchallenged. This is unfortunate, because it limits the ability of supervisors to provide sound career advice to their postdocs as well as the ability of postdocs to make informed career decisions. Based on an extensive study of PDRs in Australia, this paper challenges four commonly held assumptions: 1. that postdoctoral researchers want an academic career; 2. that postdoctoral research positions provide a stepping stone to academic careers; 3. that postdoctoral research positions provide an opportunity for novice researchers to become increasingly independent; and 4. that postdoctoral research positions provide an opportunity for the incumbents to concentrate solely on research.},
author = {{\AA}kerlind, Gerlese S.},
doi = {10.1108/1759751X201100006},
file = {:Users/gmac/mendeley/{\AA}kerlind/{\AA}kerlind - 2010 - Postdoctoral research positions as preparation for an academic career.pdf:pdf},
isbn = {2048-8696},
journal = {International Journal for Researcher Development},
pages = {84--97},
title = {{Postdoctoral research positions as preparation for an academic career}},
url = {http://www.dspace.cam.ac.uk/handle/1810/224920},
volume = {1},
year = {2010}
}
@article{Cohen1994,
author = {Cohen, Jacob},
file = {:Users/gmac/mendeley/Cohen/Cohen - 1994 - The Earth Is Round (p.05).pdf:pdf},
journal = {American Psychologist},
keywords = {stats},
month = {dec},
number = {12},
pages = {997--1003},
publisher = {American Psychological Association},
title = {{The Earth Is Round (p<.05)}},
url = {papers3://publication/uuid/2CDE7B82-206C-4D0A-9411-F4A4CA9C80E6},
volume = {49},
year = {1994}
}
@inproceedings{Frigo2005,
author = {Frigo, M and Johnson, S G},
booktitle = {Proceedings of the IEEE},
file = {:Users/gmac/mendeley/Frigo, Johnson/Frigo, Johnson - 2005 - The Design and Implementation of FFTW3.pdf:pdf},
month = {jan},
number = {2},
pages = {216--231},
title = {{The Design and Implementation of FFTW3}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1386650 papers3://publication/doi/10.1109/JPROC.2004.840301},
volume = {93},
year = {2005}
}
@article{Vastfjall2002,
abstract = {This article reviews research showing that music can alter peoples' moods and emotions. The so called “musical mood induction procedure” (MMIP) relies on music to produce changes in experienced affective processes. The fact that music can have this effect on subjective experience has been utilized to study the effect of mood on cognitive processes and behavior by a large number of researchers in social, clinical, and personality psychology. This extensive body of literature, while little known among music psychologists, is likely to further help music psychologists' understand affective responses to music. With this in mind, the present article aims at providing an extensive overview of the methodology behind a number of studies using the MMIP. The effectiveness of music as a mood-inducing stimulus is discussed in terms of self-reports, physiological and behavioral indices. The discussion focuses on how findings from the MMIP literature may extend into current research and debate on the complex interplay of music and emotional responses.},
author = {V{\"{a}}stfj{\"{a}}ll, Daniel},
doi = {10.1177/10298649020050S107},
file = {:Users/gmac/mendeley/V{\"{a}}stfj{\"{a}}ll/V{\"{a}}stfj{\"{a}}ll - 2002 - Emotion Induction Through Music A review of the Musical Mood Induction Procedure.pdf:pdf},
issn = {1029-8649(Print)},
journal = {Musicae Scientiae},
number = {2001},
pages = {173--212},
title = {{Emotion Induction Through Music: A review of the Musical Mood Induction Procedure}},
volume = {Special Is},
year = {2002}
}
@article{Broughton2009,
author = {Broughton, M and Stevens, C},
file = {:Users/gmac/mendeley/Broughton, Stevens/Broughton, Stevens - 2009 - Music, movement and marimba an investigation of the role of movement and gesture in communicating musical ex.pdf:pdf},
journal = {Psychology of Music},
month = {apr},
number = {2},
pages = {137--153},
publisher = {SAGE Publications},
title = {{Music, movement and marimba: an investigation of the role of movement and gesture in communicating musical expression to an audience}},
url = {http://pom.sagepub.com/cgi/doi/10.1177/0305735608094511 papers3://publication/doi/10.1177/0305735608094511},
volume = {37},
year = {2009}
}
@article{Bakan1966,
author = {Bakan, David},
file = {:Users/gmac/mendeley/Bakan/Bakan - 1966 - The Test of Significance in Psychological Research.pdf:pdf},
journal = {Psychological Bulletin},
keywords = {stats},
month = {dec},
number = {6},
pages = {423--437},
title = {{The Test of Significance in Psychological Research}},
url = {http://search.proquest.com/psycinfo/docview/614435064/fulltextPDF/13A469B22905FB6B883/2?accountid=13631 papers3://publication/uuid/0E3A4474-C85C-45DC-8DB6-3FA07EA0FFAF},
volume = {66},
year = {1966}
}
@article{Kornysheva2010,
author = {Kornysheva, Katja and von Anshelm-Schiffer, Anne-Marike and Schubotz, Ricarda I},
file = {:Users/gmac/mendeley/Kornysheva, von Anshelm-Schiffer, Schubotz/Kornysheva, von Anshelm-Schiffer, Schubotz - 2010 - Inhibitory stimulation of the ventral premotor cortex temporarily interferes with mu.pdf:pdf},
journal = {Human Brain Mapping},
month = {aug},
number = {8},
pages = {1300--1310},
publisher = {Wiley Subscription Services, Inc., A Wiley Company},
title = {{Inhibitory stimulation of the ventral premotor cortex temporarily interferes with musical beat rate preference}},
url = {http://doi.wiley.com/10.1002/hbm.21109 papers3://publication/doi/10.1002/hbm.21109},
volume = {32},
year = {2010}
}
@article{Campbell2012,
abstract = {OBJECTIVE:To reduce stimulus transduction artifacts in EEG while using insert earphones.

DESIGN:Reference Equivalent Threshold SPLs were assessed for Etymotic ER-4B earphones in 15 volunteers. Auditory brainstem responses (ABRs) and middle latency responses (MLRs)-as well as long-duration complex ABRs-to click and /d$\alpha$/ speech stimuli were recorded in a single-case design.

RESULTS:Transduction artifacts occurred in raw EEG responses, but they were eliminated by shielding, counter-phasing (averaging across stimuli 180° out of phase), or rereferencing.

CONCLUSIONS:Clinical grade ABRs, MLRs, and cABRs can be recorded with a standard digital EEG system and high-fidelity insert earphones, provided one or more techniques are used to remove the stimulus transduction artifact.},
address = {Center for Mind and Brain, University of California, Davis, CA 95618, USA. tom.campbell@ndsu.edu},
author = {Campbell, Tom and Kerlin, Jess R and Bishop, Christopher W and Miller, Lee M},
file = {:Users/gmac/mendeley/Campbell et al/Campbell et al. - 2012 - Methods to eliminate stimulus transduction artifact from insert earphones during electroencephalography.pdf:pdf},
journal = {Ear & Hearing},
month = {jan},
number = {1},
pages = {144--150},
title = {{Methods to eliminate stimulus transduction artifact from insert earphones during electroencephalography.}},
url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00003446-201201000-00015 papers3://publication/doi/10.1097/AUD.0b013e3182280353},
volume = {33},
year = {2012}
}
@article{Delorme2012,
author = {Delorme, Arnaud and Palmer, Jason and Onton, Julie and Oostenveld, Robert and Makeig, Scott},
file = {:Users/gmac/mendeley/Delorme et al/Delorme et al. - 2012 - Independent EEG Sources Are Dipolar.pdf:pdf},
journal = {PLoS ONE},
month = {feb},
number = {2},
pages = {1--14},
title = {{Independent EEG Sources Are Dipolar}},
volume = {7},
year = {2012}
}
@article{Smith1975,
annote = {- onset latency of FFR is 6 ms
- paper seeks to reconcile this latency as coming from a brainstem source
- stimuli presented binaurally, 25-30 ms duration
- bandpass 200-1000 Hz
- mean of 2000-7000 responses
- simultaneously measured FFR from brain and scalp electrodes in cats
-- latency from short to long: cochlear nucleus > medial superior olive > inferior colliculus (same latency as scalp recording)},
author = {Smith, James C and Marsh, James T and Brown, Warren S},
file = {:Users/gmac/mendeley/Smith, Marsh, Brown/Smith, Marsh, Brown - 1975 - Far-Field Recorded Frequency-Following Responses Evidence for the Locus of Brainstem Sources.pdf:pdf},
journal = {Electroencephalography and Clinical Neurophysiology},
month = {jan},
pages = {465--472},
title = {{Far-Field Recorded Frequency-Following Responses: Evidence for the Locus of Brainstem Sources}},
url = {papers3://publication/uuid/9AFE9198-C551-4DDC-B99A-6F2D6FFC1049},
volume = {39},
year = {1975}
}
@article{Thaut2010,
author = {Thaut, Michael H and Abiru, Mutsumi},
file = {:Users/gmac/mendeley/Thaut, Abiru/Thaut, Abiru - 2010 - Rhythmic Auditory Stimulation in Rehabilitation of Movement Disorders A Review Of Current Research.pdf:pdf},
journal = {Music Perception},
month = {apr},
number = {4},
pages = {263--269},
title = {{Rhythmic Auditory Stimulation in Rehabilitation of Movement Disorders: A Review Of Current Research}},
url = {http://www.jstor.org/stable/10.1525/mp.2010.27.4.263 papers3://publication/doi/10.1525/mp.2010.27.4.263},
volume = {27},
year = {2010}
}
@article{Makous1995,
author = {Makous, James C and Friedman, Robert M and Vierck, Charles J},
file = {:Users/gmac/mendeley/Makous, Friedman, Vierck/Makous, Friedman, Vierck - 1995 - A Critical Band Filter in Touch.pdf:pdf},
journal = {The Journal of Neuroscience},
month = {apr},
number = {4},
pages = {2808--2818},
title = {{A Critical Band Filter in Touch}},
url = {http://www.jneurosci.org/content/15/4/2808.full.pdf papers3://publication/uuid/6530F235-43CD-40EF-81E2-FD9C9A233191},
volume = {15},
year = {1995}
}
@misc{Lykken1971,
abstract = {A provisional standard method of measuring tonic skin conductance (SCL) and GSR (SCR) is advocated, using a constant-voltage method for which circuits are provided useable with Beckman, Grass, and other common polygraphs. A standard electrode methodology is also presented. The problem of units of measurement is considered in detail with an analysis of the so-called Law of Initial Values. Methods are given for correcting both tonic SC and SCRs for individual differences in their respective ranges of variation and the purpose and relative advantages of these range-correction methods are discussed.},
author = {Lykken, David T. and Venables, Peter H.},
booktitle = {Psychophysiology},
doi = {10.1111/j.1469-8986.1971.tb00501.x},
file = {:Users/gmac/mendeley/Lykken, Venables/Lykken, Venables - 1971 - Direct Measurement of Skin Conductance a Proposal for Standardization.pdf:pdf},
isbn = {00485772},
issn = {14698986},
keywords = {GSR,Range correction. (D. T. Lykken),SCL,SCR,Units of measurement,electrodes},
number = {5},
pages = {656--672},
pmid = {5116830},
title = {{Direct Measurement of Skin Conductance: a Proposal for Standardization}},
volume = {8},
year = {1971}
}
@article{Bidelman2014,
author = {Bidelman, Gavin M and Weiss, Michael W and Moreno, Sylvain and Alain, Claude},
file = {:Users/gmac/mendeley/Bidelman et al/Bidelman et al. - 2014 - Coordinated plasticity in brainstem and auditory cortex contributes to enhanced categorical speech perception i.pdf:pdf},
journal = {European Journal of Neuroscience},
month = {jun},
pages = {n/a--n/a},
title = {{Coordinated plasticity in brainstem and auditory cortex contributes to enhanced categorical speech perception in musicians}},
url = {http://doi.wiley.com/10.1111/ejn.12627 papers3://publication/doi/10.1111/ejn.12627},
year = {2014}
}
@incollection{Christensen1991,
address = {Chicago},
author = {Christensen, Dieter},
booktitle = {Comparative Musicology and Anthropology of Music: Essays on the History of Ethnomusicology},
editor = {Nettl, Bruno and Bohlman, Philip V},
month = {jan},
pages = {201--209},
publisher = {The University of Chicago Press},
title = {{Erich M. von Hornbostel Carl Stumpf, and the Institutionalization of Comparative Musicology BT  - Comparative Musicology and Anthropology of Music: Essays on the History of Ethnomusicology}},
url = {papers3://publication/uuid/B59A71A3-E95D-423E-9A3E-E4F7B0961ECF},
year = {1991}
}
@article{Lin,
author = {Lin, Yuan-Pin and Wang, Chi-Hong and Jung, Tzyy-Ping and Wu, Tien-Lin and Jeng, Shyh-Kang and Duann, Jeng-Ren and Chen, Jyh-Horng},
file = {:Users/gmac/mendeley/Lin et al/Lin et al. - Unknown - EEG-Based Emotion Recognition in Music Listening.pdf:pdf},
journal = {IEEE Transactions on Biomedical Engineering},
keywords = {emotion},
number = {7},
pages = {1798--1806},
title = {{EEG-Based Emotion Recognition in Music Listening}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5458075},
volume = {57}
}
@article{Khalsa2009a,
abstract = {Aging has been shown to increase sensory thresholds for a variety of exteroceptive and proprioceptive stimuli. However, the influence of aging on interoceptive awareness has received relatively little empirical attention. Here we report an inverse association between aging and interoception, as indexed by the ability to sense the heartbeat at rest. In a group of 59 participants ranging in age from 22 to 63 years, age inversely predicted heartbeat detection ability, both within and across several measurement sessions. On average, age accounted for 30% of the variance in heartbeat detection accuracy. Other attribute variables including body mass index and sex were not related to heartbeat detection ability. These findings provide clear empirical evidence that interoception, much like exteroception and proprioception, declines with age.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Khalsa, Sahib S. and Rudrauf, David and Tranel, Daniel},
doi = {10.1111/j.1469-8986.2009.00859.x},
eprint = {NIHMS150003},
file = {:Users/gmac/mendeley/Khalsa, Rudrauf, Tranel/Khalsa, Rudrauf, Tranel - 2009 - Interoceptive awareness declines with age.pdf:pdf},
isbn = {1540-5958 (Electronic)\n0048-5772 (Linking)},
issn = {00485772},
journal = {Psychophysiology},
keywords = {Aging,Heartbeat detection,Normal volunteers,Sensation/perception},
number = {6},
pages = {1130--1136},
pmid = {19602175},
title = {{Interoceptive awareness declines with age}},
volume = {46},
year = {2009}
}
@manual{R,
address = {Vienna, Austria},
author = {{R Core Team}},
organization = {R Foundation for Statistical Computing},
title = {{R: A Language and Environment for Statistical Computing (https://www.r-project.org/)}},
year = {2017}
}
@article{Sandstrom2013,
author = {Sandstrom, G M and Russo, Frank A},
file = {:Users/gmac/mendeley/Sandstrom, Russo/Sandstrom, Russo - 2013 - Absorption in music Development of a scale to identify individuals with strong emotional responses to music.pdf:pdf},
journal = {Psychology of Music},
month = {mar},
number = {2},
pages = {216--228},
title = {{Absorption in music: Development of a scale to identify individuals with strong emotional responses to music}},
url = {http://pom.sagepub.com/cgi/doi/10.1177/0305735611422508 papers3://publication/doi/10.1177/0305735611422508},
volume = {41},
year = {2013}
}
@article{Steinbeis2006,
abstract = {The purpose of the present study was to investigate the effect of harmonic expectancy violations on emotions. Subjective response measures for tension and emotionality, as well as electrodermal activity (EDA) and heart rate (HR), were recorded from 24 subjects (12 musicians and 12 nonmusicians) to observe the effect of expectancy violations on subjective and physiological measures of emotions. In addition, an electro-encephalogram was recorded to observe the neural correlates for detecting these violations. Stimuli consisted of three matched versions of six Bach chorales, which differed only in terms of one chord (harmonically either expected, unexpected or very unexpected). Musicians' and nonmusicians' responses were also compared. Tension, overall subjective emotionality, and EDA increased with an increase in harmonic unexpectedness. Analysis of the event-related potentials revealed an early negativity (EN) for both the unexpected and the very unexpected harmonies, taken to reflect the detection of the unexpected event. The EN in response to very unexpected chords was significantly larger in amplitude than the EN in response to merely unexpected harmonic events. The ENs did not differ in amplitude between the two groups but peaked earlier for musicians than for nonmusicians. Both groups also showed a P3 component in response to the very unexpected harmonies, which was considerably larger for musicians and may reflect the processing of stylistic violations of Western classical music.},
author = {Steinbeis, Nikolaus and Koelsch, Stefan and Sloboda, John a},
doi = {10.1162/jocn.2006.18.8.1380},
file = {:Users/gmac/mendeley/Steinbeis, Koelsch, Sloboda/Steinbeis, Koelsch, Sloboda - 2006 - The role of harmonic expectancy violations in musical emotions evidence from subjective, physiologi.pdf:pdf},
isbn = {0898-929X},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
number = {8},
pages = {1380--1393},
pmid = {16859422},
title = {{The role of harmonic expectancy violations in musical emotions: evidence from subjective, physiological, and neural responses.}},
volume = {18},
year = {2006}
}
@article{Berens2009,
author = {Berens, Philipp},
file = {:Users/gmac/mendeley/Berens/Berens - 2009 - CircStat A MATLAB Toolbox for Circular Statistics.pdf:pdf},
journal = {Journal of Statistical Software},
month = {sep},
number = {10},
pages = {1--21},
title = {{CircStat: A MATLAB Toolbox for Circular Statistics}},
url = {papers3://publication/uuid/F1E03BCE-F576-4837-8B00-62BDF5780F02},
volume = {31},
year = {2009}
}
@article{Oostenveld2011,
abstract = {Computational Intelligence and Neuroscience},
author = {Oostenveld, Robert and Fries, Pascal and Maris, Eric and Schoffelen, Jan-Mathijs},
file = {:Users/gmac/mendeley/Oostenveld et al/Oostenveld et al. - 2011 - FieldTrip Open Source Software for Advanced Analysis of MEG, EEG, and Invasive Electrophysiological Data.pdf:pdf},
journal = {Computational Intelligence and Neuroscience},
month = {jan},
number = {1},
pages = {1--9},
title = {{FieldTrip: Open Source Software for Advanced Analysis of MEG, EEG, and Invasive Electrophysiological Data}},
volume = {2011},
year = {2011}
}
@article{Franz2011,
author = {Franz, Elizabeth A and Miller, Jeff O},
file = {:Users/gmac/mendeley/Franz, Miller/Franz, Miller - 2011 - Are the basal ganglia critical in producing redundancy gain effects on simple sensorimotor responses An investiga.pdf:pdf},
journal = {Neuropsychologia},
month = {apr},
number = {5},
pages = {1267--1274},
publisher = {Elsevier Ltd},
title = {{Are the basal ganglia critical in producing redundancy gain effects on simple sensorimotor responses? An investigation on the effects of Parkinson's disease}},
url = {http://dx.doi.org/10.1016/j.neuropsychologia.2011.02.011 papers3://publication/doi/10.1016/j.neuropsychologia.2011.02.011},
volume = {49},
year = {2011}
}
@article{Bhatara2011,
abstract = {Expression in musical performance is largely communicated by the <xh:i xmlns:search="http://marklogic.com/appservices/search" xmlns="http://apa.org/pimain" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xh="http://www.w3.org/1999/xhtml">manner</xh:i> in which a piece is played; interpretive aspects that supplement the written score. In piano performance, timing and amplitude are the principal parameters the performer can vary. We examined the way in which such variation serves to communicate emotion by manipulating timing and amplitude in performances of classical piano pieces. Over three experiments, listeners rated the emotional expressivity of performances and their manipulated versions. In Experiments 1 and 2, timing and amplitude information were covaried; judgments were monotonically decreasing with performance variability, demonstrating that the rank ordering of acoustical manipulations was captured by participants' responses. Further, participants' judgments formed an S-shaped (sigmoidal) function in which greater sensitivity was seen for musical manipulations in the middle of the range than at the extremes. In Experiment 3, timing and amplitude were manipulated independently; timing variation was found to provide more expressive information than did amplitude. Across all three experiments, listeners demonstrated sensitivity to the expressive cues we manipulated, with sensitivity increasing as a function of musical experience. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
author = {Bhatara, Anjali and Tirovolas, Anna K and Duan, Lilu Marie and Levy, Bianca and Levitin, Daniel J},
file = {:Users/gmac/mendeley/Bhatara et al/Bhatara et al. - 2011 - Perception of emotional expression in musical performance.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
month = {jan},
number = {3},
pages = {921--934},
publisher = {American Psychological Association},
title = {{Perception of emotional expression in musical performance.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0021922 papers3://publication/doi/10.1037/a0021922},
volume = {37},
year = {2011}
}
@article{Baumgartner2006a,
abstract = {Most previous neurophysiological studies evoked emotions by presenting visual stimuli. Models of the emotion circuits in the brain have for the most part ignored emotions arising from musical stimuli. To our knowledge, this is the first emotion brain study which examined the influence of visual and musical stimuli on brain processing. Highly arousing pictures of the International Affective Picture System and classical musical excerpts were chosen to evoke the three basic emotions of happiness, sadness and fear. The emotional stimuli modalities were presented for 70 s either alone or combined (congruent) in a counterbalanced and random order. Electroencephalogram (EEG) Alpha-Power-Density, which is inversely related to neural electrical activity, in 30 scalp electrodes from 24 right-handed healthy female subjects, was recorded. In addition, heart rate (HR), skin conductance responses (SCR), respiration, temperature and psychometrical ratings were collected. Results showed that the experienced quality of the presented emotions was most accurate in the combined conditions, intermediate in the picture conditions and lowest in the sound conditions. Furthermore, both the psychometrical ratings and the physiological involvement measurements (SCR, HR, Respiration) were significantly increased in the combined and sound conditions compared to the picture conditions. Finally, repeated measures ANOVA revealed the largest Alpha-Power-Density for the sound conditions, intermediate for the picture conditions, and lowest for the combined conditions, indicating the strongest activation in the combined conditions in a distributed emotion and arousal network comprising frontal, temporal, parietal and occipital neural structures. Summing up, these findings demonstrate that music can markedly enhance the emotional experience evoked by affective pictures. {\textcopyright} 2005 Elsevier B.V. All rights reserved.},
author = {Baumgartner, Thomas and Esslen, Michaela and J{\"{a}}ncke, Lutz},
doi = {10.1016/j.ijpsycho.2005.04.007},
file = {:Users/gmac/mendeley/Baumgartner, Esslen, J{\"{a}}ncke/Baumgartner, Esslen, J{\"{a}}ncke - 2006 - From emotion perception to emotion experience Emotions evoked by pictures and classical music(2).pdf:pdf},
isbn = {0167-8760 (Print)\r0167-8760 (Linking)},
issn = {01678760},
journal = {International Journal of Psychophysiology},
keywords = {EEG,Emotion,Feelings,Music,Perception,Picture,Psychophysiology},
number = {1},
pages = {34--43},
pmid = {15993964},
title = {{From emotion perception to emotion experience: Emotions evoked by pictures and classical music}},
volume = {60},
year = {2006}
}
@article{Fujioka2009,
author = {Fujioka, Takako and Trainor, Laurel J and Large, Edward W and Ross, Bernhard},
file = {:Users/gmac/mendeley/Fujioka et al/Fujioka et al. - 2009 - Beta and Gamma Rhythms in Human Auditory Cortex during Musical Beat Processing.pdf:pdf},
journal = {Annals of the New York Academy of Sciences},
month = {jul},
number = {1},
pages = {89--92},
title = {{Beta and Gamma Rhythms in Human Auditory Cortex during Musical Beat Processing}},
url = {http://doi.wiley.com/10.1111/j.1749-6632.2009.04779.x papers3://publication/doi/10.1111/j.1749-6632.2009.04779.x},
volume = {1169},
year = {2009}
}
@article{Rankin2009,
author = {Rankin, Summer K and Large, Edward W and Fink, Philip W},
file = {:Users/gmac/mendeley/Rankin, Large, Fink/Rankin, Large, Fink - 2009 - Fractal Tempo Fluctuation and Pulse Prediction.pdf:pdf},
journal = {Music Perception},
keywords = {1/f},
month = {jun},
number = {5},
pages = {401--413},
title = {{Fractal Tempo Fluctuation and Pulse Prediction}},
url = {http://www.jstor.org/stable/40286129 papers3://publication/doi/10.1525/mp.2009.26.5.401},
volume = {26},
year = {2009}
}
@article{Higgins2012,
author = {Higgins, K M},
file = {:Users/gmac/mendeley/Higgins/Higgins - 2012 - Biology and Culture in Musical Emotions.pdf:pdf},
journal = {Emotion Review},
month = {jul},
number = {3},
pages = {273--282},
title = {{Biology and Culture in Musical Emotions}},
url = {http://emr.sagepub.com/cgi/doi/10.1177/1754073912439762 papers3://publication/doi/10.1177/1754073912439762},
volume = {4},
year = {2012}
}
@article{Parbery-Clark2011,
abstract = {Neuropsychologia, 49 (2011) 3338-3345. 10.1016/j.neuropsychologia.2011.08.007},
author = {Parbery-Clark, A and Strait, D L and Kraus, Nina},
file = {:Users/gmac/mendeley/Parbery-Clark, Strait, Kraus/Parbery-Clark, Strait, Kraus - 2011 - Context-dependent encoding in the auditory brainstem subserves enhanced speech-in-noise perception.pdf:pdf},
month = {oct},
number = {12},
pages = {3338--3345},
title = {{Context-dependent encoding in the auditory brainstem subserves enhanced speech-in-noise perception in musicians}},
url = {http://dx.doi.org/10.1016/j.neuropsychologia.2011.08.007 papers3://publication/doi/10.1016/j.neuropsychologia.2011.08.007},
volume = {49},
year = {2011}
}
@article{Hehman2017a,
abstract = {Models of person perception have long asserted that our impressions of others are guided by characteristics of both the target and perceiver. However, research has not yet quantified to what extent perceivers and targets contribute to different impressions. This quantification is theoretically critical, as it addresses how much an impression arises from “our minds” versus “others' faces.” Here, we apply cross-classified random effects models to address this fundamental question in social cognition, using approximately 700,000 ratings of faces. With this approach, we demonstrate that (a) different trait impressions have unique causal processes, meaning that some impressions are largely informed by perceiver-level characteristics whereas others are driven more by physical target-level characteristics; (b) modeling of perceiver- and target-variance in impressions informs fundamental models of social perception; (c) Perceiver × Target interactions explain a substantial portion of variance in impressions; (d) greater emotional intensity in stimuli decreases the influence of the perceiver; and (e) more variable, naturalistic stimuli increases variation across perceivers. Important overarching patterns emerged. Broadly, traits and dimensions representing inferences of character (e.g., dominance) are driven more by perceiver characteristics than those representing appearance-based appraisals (e.g., youthful-attractiveness). Moreover, inferences made of more ambiguous traits (e.g., creative) or displays (e.g., faces with less extreme emotions, less-controlled stimuli) are similarly driven more by perceiver than target characteristics. Together, results highlight the large role that perceiver and target variability play in trait impressions, and develop a new topography of trait impressions that considers the source of the impression.},
author = {Hehman, Eric and Sutherland, Clare A. M. and Flake, Jessica K. and Slepian, Michael L.},
doi = {10.1037/pspa0000090},
file = {:Users/gmac/mendeley/Hehman et al/Hehman et al. - 2017 - The Unique Contributions of Perceiver and Target Characteristics in Person Perception.pdf:pdf;:Users/gmac/mendeley/Hehman et al/Hehman et al. - 2017 - The Unique Contributions of Perceiver and Target Characteristics in Person Perception(2).pdf:pdf},
isbn = {1939-1315(Electronic),0022-3514(Print)},
issn = {1939-1315},
journal = {Journal of Personality and Social Psychology},
number = {4},
pages = {513--529},
pmid = {28481616},
title = {{The Unique Contributions of Perceiver and Target Characteristics in Person Perception.}},
volume = {113},
year = {2017}
}
@misc{Tierney2011,
author = {Tierney, A. and Parbery-Clark, A. and Skoe, E. and Kraus, N.},
booktitle = {Hearing Research},
doi = {10.1016/j.heares.2011.08.014},
file = {:Users/gmac/mendeley/Tierney et al/Tierney et al. - 2011 - Frequency-dependent effects of background noise on subcortical response timing.pdf:pdf},
isbn = {1878-5891 (Electronic)\r0378-5955 (Linking)},
issn = {03785955},
pages = {145--150},
pmid = {21907782},
title = {{Frequency-dependent effects of background noise on subcortical response timing}},
volume = {282},
year = {2011}
}
@inproceedings{Li2005,
author = {Li, Chengjun and Gong, Hui and Zeng, Shaoqun and Luo, Qingming},
booktitle = {SPIE 5696},
month = {jan},
title = {{Verbal working memory load affects prefrontal cortices activation: evidence from a functional NIRS study in humans}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=858944 papers3://publication/doi/10.1117/12.590222},
volume = {32},
year = {2005}
}
@incollection{Schneider1997,
address = {Berlin},
annote = {Tonpsychologie addresses general questions
- how are coherent objects constituted in perception and in thinking?
- what is the relation between parts and wholes?

Fusion is not the idea that the parts fuse into a whole such that the parts lose their own identity or quality. They CAN fuse so much that it is more difficult to recognize the parts. He did not mean that there is no mental act of discrimination. The expert or attentive listener will notice the notes in a certain spatial arrangement

Three notes simultaneously form one chord. Stumpf saw this as a problem to theories of tone and of chord perception.

Stumpf noticed that fusion persists even after analysis into constituent parts has been completed.

Stumpf held that fusion was a property of the simultaneous notes that would have to be recognized, not established, by the listener. This seems a temporary lapse back to Helmholtz's more physical explanations. Fusion can only be experienced because of the combination of stimulus features and the structural organization of the auditory system and brain.

Interesting that he defined fusion in contrast to Helmholtz's more physical and physiological explanations, but ultimately, in addressing the question of why fusion occurs, had to resort to more (neuro)physiological explanations. Namely that the brain is built for certain pattern recognition that is consistent with patterns seen in physical stimuli.},
author = {Schneider, Albrecht},
booktitle = {Music, Gestalt, and Computing: Studies in Cognitive and Systematic Musicology},
editor = {Leman, Marc},
month = {jun},
pages = {117--143},
publisher = {Springer-Verlag},
title = {{"Verschmelzung", Tonal Fusion, and Consonance: Carl Stumpf Revisited BT  - Music, Gestalt, and Computing: Studies in Cognitive and Systematic Musicology}},
url = {papers3://publication/uuid/9BB1EDCD-07F5-4E95-A711-B931492BB4FE},
year = {1997}
}
@article{Schilbach2008,
author = {Schilbach, Leo and Eickhoff, Simon B and Rotarska-Jagiela, Anna and Fink, Gereon R and Vogeley, Kai},
file = {:Users/gmac/mendeley/Schilbach et al/Schilbach et al. - 2008 - Minds at rest Social cognition as the default mode of cognizing and its putative relationship to the “defa.pdf:pdf},
journal = {Consciousness and Cognition},
keywords = {DMN},
month = {jun},
number = {2},
pages = {457--467},
title = {{Minds at rest? Social cognition as the default mode of cognizing and its putative relationship to the “default system” of the brain}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1053810008000378 papers3://publication/doi/10.1016/j.concog.2008.03.013},
volume = {17},
year = {2008}
}
@article{Buchanan2012,
author = {Buchanan, Tony W and Bagley, Sara L and Stansfield, R Brent and Preston, Stephanie D},
file = {:Users/gmac/mendeley/Buchanan et al/Buchanan et al. - 2012 - The empathic, physiological resonance of stress.pdf:pdf},
journal = {Social Neuroscience},
month = {mar},
number = {2},
pages = {191--201},
title = {{The empathic, physiological resonance of stress}},
url = {http://www.tandfonline.com/doi/abs/10.1080/17470919.2011.588723 papers3://publication/doi/10.1080/17470919.2011.588723},
volume = {7},
year = {2012}
}
@article{Bidelman2011a,
abstract = {Brain and Cognition, 77 (2011) 1-10. doi:10.1016/j.bandc.2011.07.006},
author = {Bidelman, Gavin M and Gandour, Jackson T and Krishnan, Ananthanarayan},
file = {:Users/gmac/mendeley/Bidelman, Gandour, Krishnan/Bidelman, Gandour, Krishnan - 2011 - Musicians and tone-language speakers share enhanced brainstem encoding but not perceptual benefits.pdf:pdf},
journal = {Brain and Cognition},
month = {oct},
number = {1},
pages = {1--10},
publisher = {Elsevier Inc.},
title = {{Musicians and tone-language speakers share enhanced brainstem encoding but not perceptual benefits for musical pitch}},
url = {http://dx.doi.org/10.1016/j.bandc.2011.07.006},
volume = {77},
year = {2011}
}
@article{Mendes2010,
abstract = {As neuroscience methods begin to dominate emotion research it is critical for researchers to remember that peripheral embodi-ments are critical to understanding emotional experience and emotion–behavior links. Much of modern emotion research assumes reliable mind–body connections that suggest that changes in emotional states influence bodily responses and, vice versa, that somatovisceral information shapes emotional experiences. However, there may be important qualifications to the link between the mind and the (peripheral) body. For example, the ability to sense internal and external bodily states declines in older age as does activation of physiological systems, all of which may contribute to an impairment in emotional experiences and how emotions influence behavior. I describe this phenomenon as maturational dualism and suggest implications of this for emotion in older adults.},
author = {Mendes, Wendy Berry},
doi = {10.1177/1754073910364149},
file = {:Users/gmac/mendeley/Mendes/Mendes - 2010 - Weakened Links Between Mind and Body in Older Age The Case for Maturational Dualism in the Experience of Emotion.pdf:pdf},
isbn = {1754-0739\r1754-0747},
issn = {1754-0739},
journal = {Emotion Review},
keywords = {aging,cognitive declines such as,deterioration in,emotion experience,how aging influences,interoception,maturation,our brains and bodies,psychophysiology,there is little reason,to be optimistic about},
number = {3},
pages = {240--244},
title = {{Weakened Links Between Mind and Body in Older Age: The Case for Maturational Dualism in the Experience of Emotion}},
volume = {2},
year = {2010}
}
@article{Lakatos2008,
author = {Lakatos, Peter and Karmos, George and Mehta, Ashesh D and Ulbert, Istvan and Schroeder, Charles E},
file = {:Users/gmac/mendeley/Lakatos et al/Lakatos et al. - 2008 - Entrainment of Neuronal Oscillations as a Mechanism of Attentional Selection.pdf:pdf},
journal = {Science},
month = {apr},
pages = {110--113},
title = {{Entrainment of Neuronal Oscillations as a Mechanism of Attentional Selection}},
url = {http://www.jstor.org/stable/20054942 papers3://publication/uuid/1B1FE884-DE36-4A3C-913A-4CE8DAF2398F},
volume = {320},
year = {2008}
}
@article{Cantlon2013,
abstract = {It is not currently possible to measure the real-world thought process that a child has while observing an actual school lesson. However, if it could be done, children's neural processes would presumably be predictive of what they know. Such neural measures would shed new light on children's real-world thought. Toward that goal, this study examines neural processes that are evoked naturalistically, during educational television viewing. Children and adults all watched the same Sesame Street video during functional magnetic resonance imaging (fMRI). Whole-brain intersubject correlations between the neural timeseries from each child and a group of adults were used to derive maps of "neural maturity" for children. Neural maturity in the intraparietal sulcus (IPS), a region with a known role in basic numerical cognition, predicted children's formal mathematics abilities. In contrast, neural maturity in Broca's area correlated with children's verbal abilities, consistent with prior language research. Our data show that children's neural responses while watching complex real-world stimuli predict their cognitive abilities in a content-specific manner. This more ecologically natural paradigm, combined with the novel measure of "neural maturity," provides a new method for studying real-world mathematics development in the brain.},
address = {Department of Brain and Cognitive Sciences, Rochester Center for Brain Imaging, University of Rochester, New York, New York, United States of America. jcantlon@rcbi.rochester.edu},
author = {Cantlon, Jessica F and Li, Rosa},
editor = {Posner, Michael},
file = {:Users/gmac/mendeley/Cantlon, Li/Cantlon, Li - 2013 - Neural activity during natural viewing of Sesame Street statistically predicts test scores in early childhood.pdf:pdf},
journal = {PLoS Biology},
month = {jan},
number = {1},
pages = {e1001462},
title = {{Neural activity during natural viewing of Sesame Street statistically predicts test scores in early childhood.}},
url = {http://dx.plos.org/10.1371/journal.pbio.1001462 papers3://publication/doi/10.1371/journal.pbio.1001462},
volume = {11},
year = {2013}
}
@article{Husain2014,
abstract = {We investigated the impact of hearing loss (HL) on emotional processing using task- and rest-based functional magnetic resonance imaging. Two age-matched groups of middle-aged participants were recruited: one with bilateral high-frequency HL and a control group with normal hearing (NH). During the task-based portion of the experiment, participants were instructed to rate affective stimuli from the International Affective Digital Sounds (IADS) database as pleasant, unpleasant, or neutral. In the resting state experiment, participantswere told to fixate on a “+” sign on a screen for 5 min. The results of both the task-based and resting state studies suggest that NH and HL patients differ in their emotional response. Specifically, in the task-based study, we found slower response to affective but not neutral sounds by the HL group compared to the NH group. This was reflected in the brain activation patterns, with the NH group employing the expected limbic and auditory regions including the left amygdala, left parahippocampus, right middle temporal gyrus and left superior temporal gyrus to a greater extent in processing affective stimuli when compared to the HL group. In the resting state study, we observed no significant differences in connectivity of the auditory network between the groups. In the dorsal attention network (DAN), HL patients exhibited decreased connectivity between seed regions and left insula and left postcentral gyrus compared to controls. The default mode network (DMN) was also altered, showing increased connectivity between seeds and left middle frontal gyrus in the HL group. Further targeted analysis revealed increased intrinsic connectivity between the right middle temporal gyrus and the right precentral gyrus. The results from both studies suggest neuronal reorganization as a consequence of HL, most notably in networks responding to emotional sounds.},
author = {Husain, Fatima T and Carpenter-Thompson, Jake R and Schmidt, Sara A and Peelle, Jonathan E},
doi = {10.3389/fnsys.2014.00010},
file = {:Users/gmac/mendeley/Husain et al/Husain et al. - 2014 - The effect of mild-to-moderate hearing loss on auditory and emotion processing networks.pdf:pdf},
journal = {Frontiers in Systems Neuroscience},
keywords = {IADS,emotion,fMRI,fmri,functional connectivity,hearing loss,iads,resting-state fMRI,resting-state fmri},
number = {February},
pages = {1--13},
title = {{The effect of mild-to-moderate hearing loss on auditory and emotion processing networks}},
volume = {8},
year = {2014}
}
@article{Redgrave2010,
author = {Redgrave, Peter and Rodriguez, Manuel and Smith, Yoland and Rodriguez-Oroz, Maria C and Lehericy, Stephane and Bergman, Hagai and Agid, Yves and DeLong, Mahlon R and Obeso, Jose A},
file = {:Users/gmac/mendeley/Redgrave et al/Redgrave et al. - 2010 - Goal-directed and habitual control in the basal ganglia implications for Parkinson's disease.pdf:pdf},
journal = {Nature Reviews Neuroscience},
month = {oct},
pages = {760--772},
publisher = {Nature Publishing Group},
title = {{Goal-directed and habitual control in the basal ganglia: implications for Parkinson's disease}},
url = {http://dx.doi.org/10.1038/nrn2915 papers3://publication/doi/10.1038/nrn2915},
volume = {11},
year = {2010}
}
@article{Wozniak2009,
author = {Wozniak, Robert H},
file = {:Users/gmac/mendeley/Wozniak/Wozniak - 2009 - Consciousness, Social Heredity, and Development The Evolutionary Thought of James Mark Baldwin.pdf:pdf},
journal = {American Psychologist},
month = {mar},
number = {2},
pages = {93--101},
publisher = {American Psychological Association},
title = {{Consciousness, Social Heredity, and Development: The Evolutionary Thought of James Mark Baldwin}},
url = {http://dx.doi.org/10.1037/a0013850 papers3://publication/doi/10.1037/a0013850},
volume = {64},
year = {2009}
}
@article{Palmer2009,
author = {Palmer, Caroline and Koopmans, Erik and Loehr, Janeen D and Carter, Christine},
file = {:Users/gmac/mendeley/Palmer et al/Palmer et al. - 2009 - Movement-Related Feedback and Temporal Accuracy in Clarinet Performance.pdf:pdf},
journal = {Music Perception},
month = {jan},
number = {5},
pages = {439--450},
title = {{Movement-Related Feedback and Temporal Accuracy in Clarinet Performance}},
url = {papers3://publication/doi/10.1525/MP.2009.26.5.439},
volume = {26},
year = {2009}
}
@article{Fujioka2012a,
author = {Fujioka, Takako and Trainor, Laurel J and Large, Edward W and Ross, B},
file = {:Users/gmac/mendeley/Fujioka et al/Fujioka et al. - 2012 - Internalized Timing of Isochronous Sounds Is Represented in Neuromagnetic Beta Oscillations.pdf:pdf},
journal = {Journal of Neuroscience},
keywords = {beta,rhythm},
month = {feb},
number = {5},
pages = {1791--1802},
title = {{Internalized Timing of Isochronous Sounds Is Represented in Neuromagnetic Beta Oscillations}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4107-11.2012},
volume = {32},
year = {2012}
}
@article{Drake2000,
author = {Drake, Carolyn and Penel, Amandine and Bigand, Emmanuel},
file = {:Users/gmac/mendeley/Drake, Penel, Bigand/Drake, Penel, Bigand - 2000 - Tapping in Time With Mechanically and Expressively Performed Music.pdf:pdf},
journal = {Music Perception},
month = {oct},
pages = {1--23},
title = {{Tapping in Time With Mechanically and Expressively Performed Music}},
url = {papers3://publication/uuid/E96CF371-E82C-4C52-9DAD-2D881520B1CC},
volume = {18},
year = {2000}
}
@article{Nozaradan2012,
author = {Nozaradan, Sylvie and Peretz, I and Mouraux, A},
file = {:Users/gmac/mendeley/Nozaradan, Peretz, Mouraux/Nozaradan, Peretz, Mouraux - 2012 - Selective Neuronal Entrainment to the Beat and Meter Embedded in a Musical Rhythm.pdf:pdf},
journal = {Journal of Neuroscience},
month = {dec},
number = {49},
pages = {17572--17581},
title = {{Selective Neuronal Entrainment to the Beat and Meter Embedded in a Musical Rhythm}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3203-12.2012 papers3://publication/doi/10.1523/JNEUROSCI.3203-12.2012},
volume = {32},
year = {2012}
}
@article{Stevens1998a,
abstract = {Detection thresholds to warming and cooling were measured in 13 regions of the body in 60 adults aged between 18 and 88 years. From these thresholds were constructed maps of thermal sensitivity homologous to body maps of spatial acuity (in the older literature two-point discrimination), long known to the somatosensory scientist. Maps of cold and warm sensitivity for young, middle-aged and elderly adults, show how sensitivity changes with age in the various body regions. Three characteristics emerge, irrespective of age: (1) sensitivity varies approximately 100-fold over the body surface. The face, especially near the mouth, is exquisitely sensitive, the extremities, by comparison, poor, other regions, intermediate. (2) All body regions are more sensitive to cold than to warm. (3) The better a region is at detecting cold, the better it is at detecting warm. With age, thermal sensitivity declines. The greatest changes take place in the extremities, especially the foot, where thresholds often become too large to measure. Central regions give up their sensitivity with age more slowly, and even (as in the lips) inconsequentially. Similar age-related changes have also previously been shown to characterize spatial acuity.},
author = {Stevens, J C and Choo, K K},
doi = {10.1080/08990229870925},
file = {:Users/gmac/mendeley/Stevens, Choo/Stevens, Choo - 1998 - Temperature sensitivity of the body surface over the life span.pdf:pdf},
isbn = {0899-0220},
issn = {0899-0220},
journal = {Somatosensory & motor research},
keywords = {80 and over,Adolescent,Adult,Age Distribution,Aged,Analysis of Variance,Animals,Female,Humans,Life Cycle Stages,Life Cycle Stages: physiology,Linear Models,Logistic Models,Male,Middle Aged,Psychophysics,Sensory Thresholds,Skin Physiological Phenomena,Temperature},
number = {1},
pages = {13--28},
pmid = {9583574},
title = {{Temperature sensitivity of the body surface over the life span.}},
volume = {15},
year = {1998}
}
@article{Hietanen1998,
abstract = {In this study we investigated facial electromyographic (EMG) responses to vocal affect expressions. We also measured emotion-related action tendencies by requesting the subjects to indicate their tendency to approach or withdraw from the person uttering the stimulus word. In addition, emotional contagion (EC) was measured with a questionnaire-based scale. The results showed that hearing the expression of anger increased EMG activity in the subjects' brow region more than hearing contentment. In contrast, the expression of contentment activated the periocular muscle region more than anger. The expressions of anger elicited behavioral withdrawal responses, whereas the neutral expressions and contentment evoked approach responses. Subjects scoring low and high on EC exhibited different patterns of EMG responses. The results support the view that negative and positive affects are contagious from hearing human vocal affect expressions.},
address = {Department of Physiology, University of Helsinki, Finland. psjahi@uta.fi},
author = {Hietanen, J K and Surakka, V and Linnankoski, I},
file = {:Users/gmac/mendeley/Hietanen, Surakka, Linnankoski/Hietanen, Surakka, Linnankoski - 1998 - Facial electromyographic responses to vocal affect expressions.pdf:pdf},
journal = {Psychophysiology},
month = {sep},
number = {5},
pages = {530--536},
title = {{Facial electromyographic responses to vocal affect expressions.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=9715097&retmode=ref&cmd=prlinks papers3://publication/uuid/2E9B3DB0-441C-49FB-955D-3B09E0B49D8F},
volume = {35},
year = {1998}
}
@article{Livingstone2017,
author = {Livingstone, Steven R and Russo, Frank A},
journal = {PLoS ONE},
title = {{The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English}}
}
@article{Koffka1922,
author = {Koffka, Kurt},
file = {:Users/gmac/mendeley/Koffka/Koffka - 1922 - Perception An Introduction to the Gestalt Theorie.pdf:pdf},
journal = {The Psychological Bulletin},
month = {oct},
pages = {531--585},
title = {{Perception: An Introduction to the Gestalt Theorie}},
url = {papers3://publication/uuid/CA9D46BB-FC0D-4C91-BC23-00FA0623DB89},
volume = {19},
year = {1922}
}
@article{Gilbertson2005,
author = {Gilbertson, T},
file = {:Users/gmac/mendeley/Gilbertson/Gilbertson - 2005 - Existing Motor State Is Favored at the Expense of New Movement during 13-35 Hz Oscillatory Synchrony in the Human Co.pdf:pdf},
journal = {Journal of Neuroscience},
month = {aug},
number = {34},
pages = {7771--7779},
title = {{Existing Motor State Is Favored at the Expense of New Movement during 13-35 Hz Oscillatory Synchrony in the Human Corticospinal System}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1762-05.2005 papers3://publication/doi/10.1523/JNEUROSCI.1762-05.2005},
volume = {25},
year = {2005}
}
@article{Schroeder2009,
abstract = {Neuroelectric oscillations reflect rhythmic shifting of neuronal ensembles between high and low excitability states. In natural settings, important stimuli often occur in rhythmic streams, and when oscillations entrain to an input rhythm their high excitability phases coincide with events in the stream, effectively amplifying neuronal input responses. When operating in a 'rhythmic mode', attention can use these differential excitability states as a mechanism of selection by simply enforcing oscillatory entrainment to a task-relevant input stream. When there is no low-frequency rhythm that oscillations can entrain to, attention operates in a 'continuous mode', characterized by extended increase in gamma synchrony. We review the evidence for early sensory selection by oscillatory phase-amplitude modulations, its mechanisms and its perceptual and behavioral consequences. ?? 2008 Elsevier Ltd. All rights reserved.},
author = {Schroeder, Charles E. and Lakatos, Peter},
doi = {10.1016/j.tins.2008.09.012},
file = {:Users/gmac/mendeley/Schroeder, Lakatos/Schroeder, Lakatos - 2009 - Low-frequency neuronal oscillations as instruments of sensory selection.pdf:pdf},
isbn = {0166-2236 (Print)\r0166-2236 (Linking)},
issn = {01662236},
journal = {Trends in Neurosciences},
number = {1},
pages = {9--18},
pmid = {19012975},
title = {{Low-frequency neuronal oscillations as instruments of sensory selection}},
volume = {32},
year = {2009}
}
@article{Davies2013,
author = {Davies, Matthew and Madison, Guy and Silva, Pedro and Gouyon, Fabien},
file = {:Users/gmac/mendeley/Davies et al/Davies et al. - 2013 - The Effect of Microtiming Deviations on the Perception of Groove in Short Rhythms.pdf:pdf},
journal = {Music Perception: An Interdisciplinary Journal},
month = {jun},
number = {5},
pages = {497--510},
publisher = {University of California Press},
title = {{The Effect of Microtiming Deviations on the Perception of Groove in Short Rhythms}},
url = {http://www.jstor.org/stable/info/10.1525/mp.2013.30.5.497 papers3://publication/doi/10.1525/mp.2013.30.5.497},
volume = {30},
year = {2013}
}
@article{Marmel2013,
abstract = {The neural mechanisms of pitch coding have been debated for more than a century. The two main mechanisms are coding based on the profiles of neural firing rates across auditory nerve fibers with different characteristic frequencies (place-rate coding), and coding based on the phase-locked temporal pattern of neural firing (temporal coding). Phase locking precision can be partly assessed by recording the frequency-following response (FFR), a scalp-recorded electrophysiological response that reflects synchronous activity in subcortical neurons. Although features of the FFR have been widely used as indices of pitch coding acuity, only a handful of studies have directly investigated the relation between the FFR and behavioral pitch judgments. Furthermore, the contribution of degraded neural synchrony (as indexed by the FFR) to the pitch perception impairments of older listeners and those with hearing loss is not well known. Here, the relation between the FFR and pure-tone frequency discrimination was investigated in listeners with a wide range of ages and absolute thresholds, to assess the respective contributions of subcortical neural synchrony and other age-related and hearing loss-related mechanisms to frequency discrimination performance. FFR measures of neural synchrony and absolute thresholds independently contributed to frequency discrimination performance. Age alone, i.e., once the effect of subcortical neural synchrony measures or absolute thresholds had been partialed out, did not contribute to frequency discrimination. Overall, the results suggest that frequency discrimination of pure tones may depend both on phase locking precision and on separate mechanisms affected in hearing loss.},
author = {Marmel, F and Linley, D and Carlyon, R P and Gockel, H E and Hopkins, K and Plack, C J},
doi = {10.1007/s10162-013-0402-3},
file = {:Users/gmac/mendeley/Marmel et al/Marmel et al. - 2013 - Subcortical Neural Synchrony and Absolute Thresholds Predict Frequency Discrimination Independently.pdf:pdf},
issn = {1438-7573},
journal = {Journal of the Association for Research in Otolaryngology : JARO},
keywords = {age,ffr,neural phase locking,perception,pitch,sensorineural hearing loss},
pages = {757--766},
pmid = {23760984},
title = {{Subcortical Neural Synchrony and Absolute Thresholds Predict Frequency Discrimination Independently.}},
volume = {766},
year = {2013}
}
@article{Skoe2010,
annote = {Methods
- Cz = active, non-inverting
- ipsilateral earlobe = reference, inverting
- forehead or contralateral earlobe = ground},
author = {Skoe, Erika and Kraus, Nina},
file = {:Users/gmac/mendeley/Skoe, Kraus/Skoe, Kraus - 2010 - Auditory Brain Stem Response to Complex Sounds A Tutorial.pdf:pdf},
journal = {Ear & Hearing},
month = {jun},
number = {3},
pages = {302--324},
title = {{Auditory Brain Stem Response to Complex Sounds: A Tutorial}},
url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00003446-201006000-00002 papers3://publication/doi/10.1097/AUD.0b013e3181cdb272},
volume = {31},
year = {2010}
}
@article{Cousineau2012,
author = {Cousineau, Marion and McDermott, Josh H and Peretz, Isabelle},
file = {:Users/gmac/mendeley/Cousineau, McDermott, Peretz/Cousineau, McDermott, Peretz - 2012 - The basis of musical consonance as revealed by congenital amusia.pdf:pdf},
journal = {PNAS},
keywords = {dissonance},
month = {nov},
number = {48},
pages = {19858--19863},
title = {{The basis of musical consonance as revealed by congenital amusia}},
url = {message:%3C3919F4DAB033E848BF84B857DF8B86DA140158DA@mail1.arts.ryerson.ca%3E papers3://publication/doi/10.1073/pnas.1207989109/-/DCSupplemental},
volume = {109},
year = {2012}
}
@book{Ullsperger2010,
author = {Ullsperger, M and Debener, S},
isbn = {9780190451776},
publisher = {Oxford University Press},
title = {{Simultaneous EEG and fMRI: Recording, Analysis, and Application}},
year = {2010}
}
@incollection{Izard1997,
address = {Cambridge},
author = {Izard, Carroll E},
booktitle = {The Psychology of Facial Expression},
editor = {Russell, James A and Fern{\'{a}}ndez-Dols, Jos{\'{e}} Miguel},
month = {jan},
number = {3},
pages = {57--77},
publisher = {Cambridge University Press},
title = {{Emotions and facial expressions: A perspective from Differential Emotions Theory BT  - The Psychology of Facial Expression}},
url = {papers3://publication/uuid/3BD4570E-B921-40BE-BD0C-B91DE10AA560},
year = {1997}
}
@article{Hove2014a,
annote = {- calls for more exhaustive testing of dynamic periodicites},
author = {Hove, Michael J and Schwartze, M},
file = {:Users/gmac/mendeley/Hove, Schwartze/Hove, Schwartze - 2014 - Deconstructing the Ability to Move to a Beat.pdf:pdf},
journal = {Journal of Neuroscience},
number = {7},
pages = {2403--2405},
title = {{Deconstructing the Ability to Move to a Beat}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4880-13.2014 papers3://publication/doi/10.1523/JNEUROSCI.4880-13.2014},
volume = {34},
year = {2014}
}
@article{Rose2014,
abstract = {The detailed study of EMGs is a course (or career) in itself. In this set of notes we will focus on understanding a few points about the analysis of the signals.},
author = {Rose, William},
file = {:Users/gmac/mendeley/Rose/Rose - 2014 - Raw signal amplification.pdf:pdf},
journal = {Mathematics and Signal Processing for Biomechanics},
title = {{Raw signal amplification}},
year = {2014}
}
@article{Schweizer2012,
abstract = {CORTEX, 48 (2012) 991-996. doi:10.1016/j.cortex.2011.04.009},
author = {Schweizer, Tom A and Ware, Jenna and Fischer, Corinne E and Craik, Fergus I M and Bialystok, Ellen},
file = {:Users/gmac/mendeley/Schweizer et al/Schweizer et al. - 2012 - Bilingualism as a contributor to cognitive reserve Evidence from brain atrophy in Alzheimer's disease.pdf:pdf},
journal = {CORTEX},
month = {sep},
number = {8},
pages = {991--996},
publisher = {Elsevier Ltd},
title = {{Bilingualism as a contributor to cognitive reserve: Evidence from brain atrophy in Alzheimer's disease}},
url = {http://dx.doi.org/10.1016/j.cortex.2011.04.009 papers3://publication/doi/10.1016/j.cortex.2011.04.009},
volume = {48},
year = {2012}
}
@incollection{Marler1997,
address = {Cambridge},
author = {Marler, Peter and Evans, Christopher},
booktitle = {The Psychology of Facial Expression},
editor = {Russell, James A and Fern{\'{a}}ndez-Dols, Jos{\'{e}} Miguel},
month = {jan},
number = {6},
pages = {133--157},
publisher = {Cambridge University Press},
title = {{Animal sounds and human faces: Do they have anything in common? BT  - The Psychology of Facial Expression}},
url = {papers3://publication/uuid/128268EB-96E2-4D06-A764-A3FE454A77C5},
year = {1997}
}
@article{Repp2008,
author = {Repp, Bruno H and Iversen, John R and Patel, Aniruddh D},
file = {:Users/gmac/mendeley/Repp, Iversen, Patel/Repp, Iversen, Patel - 2008 - Tracking an Imposed Beat within a Metrical Grid.pdf:pdf},
journal = {Music Perception},
month = {sep},
number = {1},
pages = {1--18},
title = {{Tracking an Imposed Beat within a Metrical Grid}},
url = {http://www.jstor.org/stable/40286165 papers3://publication/doi/10.1525/mp.2008.26.1.1},
volume = {26},
year = {2008}
}
@article{Jones2002,
annote = {- "in dynamic arrays, whether visual or auditory elements appear and disappear over time, meaning that to ensure synchrony attending must coincide with elements as they happen"
- reactive attending: phase alignments to tone onsets
- anticipatory attending: engagement of internal oscillatory periods with time intervals (IOIs) of a sequence
- temporal expectancies (anticipatory attending) is not strictly top-down & goal-directed process; they can be stimulus-driven
- "attending is strongly influenced by the presence and time structure of interpolated pitches regardless of the nature of instructions"
-"the dynamic attending model predicts that the narrow attentional focus that characterizes responses to regular rhythms will widen if one is presented with irregular rhythms"

-"temporal capture by unexpected elements...was more likely...because of a wider attentional focus"
-"relative attending to a singular abrupt onset is more likely following irregular rhythms than following regular rhythms"

-"the possibility that different aspects of dynamic arrays may give rise to different kinds of expectancies is consistent with ERP research"
- "it is possible that instead of widening the attentional focus, irregular timing encourages listeners to simply "wait" for late comparison tones"

- "sequence rhythm fits neatly into neither [endogenous or exogenous] cue category"
- "we propose that stimulus timing has an immediate and primitive impact on attending and expectancies"
- "when encountering a dynamic array bearing rhythmic information, people respond in the moment with expectancies that are driven, perhaps involuntarily, by the stimulus timing itself"},
author = {Jones, Mari Riess and Moynihan, Heather and Mackenzie, Noah and Puente, Jennifer},
file = {:Users/gmac/mendeley/Jones et al/Jones et al. - 2002 - Temporal Aspects of Stimulus-Driven Attending in Dynamic Arrays.pdf:pdf},
journal = {Psychological Science},
month = {jul},
pages = {313--319},
title = {{Temporal Aspects of Stimulus-Driven Attending in Dynamic Arrays}},
volume = {13},
year = {2002}
}
@article{Sellitto2010,
author = {Sellitto, M and Ciaramelli, E and di Pellegrino, G},
file = {:Users/gmac/mendeley/Sellitto, Ciaramelli, di Pellegrino/Sellitto, Ciaramelli, di Pellegrino - 2010 - Myopic Discounting of Future Rewards after Medial Orbitofrontal Damage in Humans.pdf:pdf},
journal = {Journal of Neuroscience},
month = {dec},
number = {49},
pages = {16429--16436},
title = {{Myopic Discounting of Future Rewards after Medial Orbitofrontal Damage in Humans}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2516-10.2010 papers3://publication/doi/10.1523/JNEUROSCI.2516-10.2010},
volume = {30},
year = {2010}
}
@article{Crowder1985,
abstract = {Describes 4 experiments examining perception of the major/minor distinction in continua of sine-wave triads, varying in 9 equal steps from pure minor to pure major chords. Facility in labeling these items as major or minor was highly variable, bimodal in distribution among Ss, and only moderately related to musical experience. Same-different discrimination of these chords posed no particular problems for the Ss. Nearly all Ss heard 1st-inversion triads as sounding more major than root-position triads. Neighboring triads along a continuum were subject to contrastive context effects. This contrast seemed to have a sensory rather than cognitive basis. Triads otherwise capable of showing contrast were not effective when separated by an octave, an unexpected failure of octave generalization. (PsycINFO Database Record (c) 2004 APA, all rights reserved)},
author = {Crowder, Robert G},
file = {:Users/gmac/mendeley/Crowder/Crowder - 1985 - Perception of the majorminor distinction II. Experimental investigations.pdf:pdf},
isbn = {0275-3987},
journal = {Psychomusicology},
keywords = {Human,Music,Pitch Discrimination,perception of major vs minor distinction in contin},
number = {1-2},
pages = {3--24},
title = {{Perception of the major/minor distinction: II. Experimental investigations}},
url = {http://www.fsu.edu},
volume = {5},
year = {1985}
}
@article{Ekman1992,
abstract = {Ortony and Turner's (1990) arguments against those who adopt the view that there are basic emotions are challenged. The evidence on universals in expression and in physiology strongly suggests that there is a biological basis to the emotions that have been studied. Ortony and Turner's reviews of this literature are faulted, and their alternative theoretical explanations do not fit the evidence. The utility of the basic emotions approach is also shown in terms of the research it has generated.},
address = {University of California, San Francisco 94143.},
author = {Ekman, Paul},
file = {:Users/gmac/mendeley/Ekman/Ekman - 1992 - Are there basic emotions.pdf:pdf},
journal = {Psychological Review},
month = {jul},
number = {3},
pages = {550--553},
title = {{Are there basic emotions?}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=1344638&retmode=ref&cmd=prlinks papers3://publication/uuid/AC16E956-E32B-4CCA-A613-25DC32ECEFEC},
volume = {99},
year = {1992}
}
@book{Miell,
address = {New York},
editor = {Miell, Dorothy and Macdonald, Raymond and Hargreaves, David J},
publisher = {Oxford University Press},
title = {{No Title}},
url = {papers3://publication/uuid/20AEAAEF-2BB6-452C-94DC-BA2DA41EA9F4}
}
@article{Hehman2017b,
abstract = {Perceivers form strong inferences of disposition from others' facial appearance, and these inferences guide a wide variety of important behaviors. The current research examines the possibility that similar-looking individuals are more likely to form groups with one another. We do so by testing a necessary downstream consequence of this process, examining whether the faces of individuals within groups more physically resemble one another than those in other groups. Across six studies, we demonstrate that individuals' group membership can be accurately classified both from ratings of members' faces, and from direct measurement of members' faces. Results provide insight into how affiliative groups initially form and maintain membership over time, as well as the perception of homogeneity of groups.},
author = {Hehman, Eric and Flake, Jessica K. and Freeman, Jonathan B.},
doi = {10.1177/0146167217722556},
file = {:Users/gmac/mendeley/Hehman, Flake, Freeman/Hehman, Flake, Freeman - 2017 - The Faces of Group Members Share Physical Resemblance.pdf:pdf},
isbn = {4302016000},
issn = {0146-1672},
journal = {Personality and Social Psychology Bulletin},
keywords = {face perception,group formation,impression formation,intragroup dynamics,person perception},
pages = {1--13},
title = {{The Faces of Group Members Share Physical Resemblance}},
year = {2017}
}
@article{Ward2003,
author = {Ward, Lawrence M},
file = {:Users/gmac/mendeley/Ward/Ward - 2003 - Synchronous neural oscillations and cognitive processes.pdf:pdf},
journal = {Trends in Cognitive Sciences},
month = {dec},
number = {12},
pages = {553--559},
publisher = {Elsevier Ltd},
title = {{Synchronous neural oscillations and cognitive processes}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661303002894 papers3://publication/doi/10.1016/j.tics.2003.10.012},
volume = {7},
year = {2003}
}
@article{Fletcher1924,
author = {Fletcher, Harvey},
file = {:Users/gmac/mendeley/Fletcher/Fletcher - 1924 - The Physical Criterion for Determining the Pitch of a Musical Tone.pdf:pdf},
journal = {Physical Review},
month = {jan},
number = {3},
pages = {427--437},
title = {{The Physical Criterion for Determining the Pitch of a Musical Tone}},
url = {papers3://publication/uuid/BC73E020-1CA1-4882-85B1-BB6BEC585374},
volume = {23},
year = {1924}
}
@incollection{Makeig1996,
address = {Cambridge, MA},
author = {Makeig, Scott and Bell, Anthony J and Jung, Tzyy-Ping and Sejnowski, Terrence J},
booktitle = {Advances in Neural Information Processing Systems 8},
editor = {Touretzky, D and Mozer, M and Hasselmo, M},
file = {:Users/gmac/mendeley/Makeig et al/Makeig et al. - 1996 - Independent Component Analysis of Electroencephalographic Data.pdf:pdf},
month = {jan},
pages = {145--151},
publisher = {MIT Press},
title = {{Independent Component Analysis of Electroencephalographic Data}},
url = {papers3://publication/uuid/FA6629C8-19AD-46CA-A8FF-B1872A3223F2},
year = {1996}
}
@article{Brignani2008,
author = {Brignani, Debora and Manganotti, Paolo and Rossini, Paolo M and Miniussi, Carlo},
file = {:Users/gmac/mendeley/Brignani et al/Brignani et al. - 2008 - Modulation of cortical oscillatory activity during transcranial magnetic stimulation.pdf:pdf},
journal = {Human Brain Mapping},
month = {jan},
number = {5},
pages = {603--612},
title = {{Modulation of cortical oscillatory activity during transcranial magnetic stimulation}},
url = {http://doi.wiley.com/10.1002/hbm.20423 papers3://publication/doi/10.1002/hbm.20423},
volume = {29},
year = {2008}
}
@article{Ekman1993,
abstract = {Cross-cultural research on facial expression and the developments of methods to measure facial expression are briefly summarized. What has been learned about emotion from this work on the face is then elucidated. Four questions about facial expression and emotion are discussed: What information does an expression typically convey? Can there be emotion without facial expression? Can there be a facial expression of emotion without emotion? How do individuals differ in their facial expressions of emotion?},
address = {Human Interaction Laboratory, University of California, San Francisco 94143.},
author = {Ekman, Paul},
file = {:Users/gmac/mendeley/Ekman/Ekman - 1993 - Facial expression and emotion.pdf:pdf},
journal = {American Psychologist},
month = {apr},
number = {4},
pages = {384--392},
publisher = {American Psychological Association},
title = {{Facial expression and emotion.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=8512154&retmode=ref&cmd=prlinks papers3://publication/uuid/5CB217FD-2CDF-467C-815C-3C50ED5A5CE9},
volume = {48},
year = {1993}
}
@article{North1995,
abstract = {The optimal complexity and preference-feedback hypotheses make specific predictions about the effects of stimulus familiarity and subjective complexity on liking for music excerpts. This study investigates the relationships between each of these three variables within the same experimental design. Seventy- five undergraduate subjects rated 60 excerpts of contemporary popular music for liking, subjective complexity, or familiarity. The results strongly supported the predictions of the two models, indicating a positive relationship between liking and familiarity, and an inverted-U relationship between liking and sub- jective complexity. The observed relationship between familiarity and subjec- tive complexity was more difficult to predict and explain, although there was some evidence that this relationship might best be described as an inverted-U function. The different relationships of these two variables with liking are ex- plained in terms of subjective complexity being related to objective properties of the stimuli, and familiarity being determined by cultural exposure and sub- jects own volition.},
author = {North, Adrian C and Hargreaves, David J},
doi = {10.1037/h0094090},
file = {:Users/gmac/mendeley/North, Hargreaves/North, Hargreaves - 1995 - Subjective complexity, familiarity and liking for popular music.pdf:pdf},
isbn = {0275-3987},
issn = {0275-3987},
journal = {Psychomusicology},
number = {1966},
pages = {77--93},
title = {{Subjective complexity, familiarity and liking for popular music}},
volume = {14},
year = {1995}
}
@article{Smith1985,
abstract = {There has long been interest in describing emotional experience in terms of underlying dimensions, but traditionally only two dimensions, pleasantness and arousal, have been reliably found. The reasons for these findings are reviewed, and integrating this review with two recent theories of emotions (Roseman, 1984; Scherer, 1982), we propose eight cognitive appraisal dimensions to differentiate emotional experience. In an investigation of this model, subjects recalled past experiences associated with each of 15 emotions, and rated them along the proposed dimensions. Six orthogonal dimensions, pleasantness, anticipated effort, certainty, attentional activity, self-other responsibility/control, and situational control, were recovered, and the emotions varied systematically along each of these dimensions, indicating a strong relation between the appraisal of one's circumstances and one's emotional state. The patterns of appraisal for the different emotions, and the role of each of the dimensions in differentiating emotional experience are discussed.},
author = {Smith, C a and Ellsworth, P C},
doi = {10.1037/0022-3514.48.4.813},
file = {:Users/gmac/mendeley/Smith, Ellsworth/Smith, Ellsworth - 1985 - Patterns of cognitive appraisal in emotion.pdf:pdf},
isbn = {0022-3514 (Print)\n0022-3514 (Linking)},
journal = {Journal of Personality and Social Psychology},
number = {July},
pages = {813--838},
pmid = {3886875},
title = {{Patterns of cognitive appraisal in emotion.}},
volume = {48},
year = {1985}
}
@article{Patston2011,
author = {Patston, Lucy L M and Tippett, Lynette J},
file = {:Users/gmac/mendeley/Patston, Tippett/Patston, Tippett - 2011 - The Effect of Background Music on Cognitive Performance in Musicians and Nonmusicians.pdf:pdf},
journal = {Music Perception},
month = {jan},
number = {2},
pages = {173--183},
title = {{The Effect of Background Music on Cognitive Performance in Musicians and Nonmusicians}},
url = {papers3://publication/doi/10.1525/mp.2011.29.2.173},
volume = {29},
year = {2011}
}
@article{Larsson2013,
author = {Larsson, Matz},
file = {:Users/gmac/mendeley/Larsson/Larsson - 2013 - Self-generated sounds of locomotion and ventilation and the evolution of human rhythmic abilities.pdf:pdf},
journal = {Animal Cognition},
month = {aug},
title = {{Self-generated sounds of locomotion and ventilation and the evolution of human rhythmic abilities}},
url = {http://link.springer.com/10.1007/s10071-013-0678-z papers3://publication/doi/10.1007/s10071-013-0678-z},
year = {2013}
}
@article{Perruchet2013,
author = {Perruchet, Pierre and Poulin-Charronnat, B{\'{e}}n{\'{e}}dicte},
file = {:Users/gmac/mendeley/Perruchet, Poulin-Charronnat/Perruchet, Poulin-Charronnat - 2013 - Challenging prior evidence for a shared syntactic processor for language and music.pdf:pdf},
journal = {Psychonomic Bulletin & Review},
month = {jan},
pages = {310--317},
title = {{Challenging prior evidence for a shared syntactic processor for language and music}},
url = {papers3://publication/uuid/9641EC47-C540-4134-AC1C-60857DF7ACCC},
volume = {20},
year = {2013}
}
@article{Sommers2005,
abstract = {OBJECTIVE:The purpose of the present study was to examine the effects of age on the ability to benefit from combining auditory and visual speech information, relative to listening or speechreading alone. In addition, the study was designed to compare visual enhancement (VE) and auditory enhancement (AE) for consonants, words, and sentences in older and younger adults.

DESIGN:Forty-four older adults and 38 younger adults with clinically normal thresholds for frequencies of 4 kHz and below were asked to identify vowel-consonant-vowels (VCVs), words in a carrier phrase, and semantically meaningful sentences in auditory-only (A), visual-only (V), and auditory-visual (AV) conditions. All stimuli were presented in a background of 20-talker babble, and signal-to-babble ratios were set individually for each participant and each stimulus type to produce approximately 50% correct in the A condition.

RESULTS:For all three types of stimuli, older and younger adults obtained similar scores for the A condition, indicating that the procedure for individually adjusting signal-to-babble ratios was successful at equating A scores for the two age groups. Older adults, however, had significantly poorer performance than younger adults in the AV and V modalities. Analyses of both AE and VE indicated no age differences in the ability to benefit from combining auditory and visual speech signals after controlling for age differences in the V condition. Correlations between scores for the three types of stimuli (consonants, words, and sentences) indicated moderate correlations in the V condition but small correlations for AV, AE, and VE.

CONCLUSIONS:Overall, the findings suggest that the poorer performance of older adults in the AV condition was a result of reduced speechreading abilities rather than a consequence of impaired integration capacities. The pattern of correlations across the three stimulus types indicates some overlap in the mechanisms mediating AV perception of words and sentences and that these mechanisms are largely independent from those used for AV perception of consonants.},
address = {Department of Psychology, Washington University, St. Louis, Missouri 63130, USA.},
author = {Sommers, Mitchell S and Tye-Murray, Nancy and Spehar, Brent},
file = {:Users/gmac/mendeley/Sommers, Tye-Murray, Spehar/Sommers, Tye-Murray, Spehar - 2005 - Auditory-visual speech perception and auditory-visual enhancement in normal-hearing younger and old.pdf:pdf},
journal = {Ear & Hearing},
month = {jun},
number = {3},
pages = {263--275},
title = {{Auditory-visual speech perception and auditory-visual enhancement in normal-hearing younger and older adults.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=15937408&retmode=ref&cmd=prlinks papers3://publication/uuid/98CCC291-B71A-491D-BDAD-CBEBFA7DB462},
volume = {26},
year = {2005}
}
@article{Ilie2006a,
abstract = {Using a three-dimensional model of affect, we compared the affective consequences of manipulating intensity, rate, and pitch height in music and speech. Participants rated 64 music and 64 speech excerpts on valence (pleasant-unpleasant), energy arousal (awake-tired), and tension arousal (tense-relaxed). For music and speech, loud excerpts were judged as more pleasant, energetic, and tense than soft excerpts. Manipulations of rate had overlapping effects on music and speech. Fast music and speech were judged as having greater energy than slow music and speech. However, whereas fast speech was judged as less pleasant than slow speech, fast music was judged as having greater tension than slow music. Pitch height had opposite consequences for music and speech, with high-pitched speech but lowpitched music associated with higher ratings of valence (more pleasant). Interactive effects on judgments were also observed. We discuss similarities and differences between vocal and musical communication of affect, and the need to distinguish between two types of arousal: energy and tension.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Ilie, Gabriella and Thompson, William Forde},
doi = {10.1525/mp.2006.23.4.319},
eprint = {arXiv:1011.1669v3},
file = {:Users/gmac/mendeley/Ilie, Thompson/Ilie, Thompson - 2006 - A Comparison of Acoustic Cues in Music and Speech for Three Dimensions of Affect.pdf:pdf},
isbn = {9788578110796},
issn = {0730-7829},
journal = {Music Perception},
number = {4},
pages = {319--330},
pmid = {25246403},
title = {{A Comparison of Acoustic Cues in Music and Speech for Three Dimensions of Affect}},
volume = {23},
year = {2006}
}
@article{Lakatos2005,
abstract = {EEG oscillations are hypothesized to reflect cyclical variations in the neuronal excitability, with particular frequency bands reflecting differing spatial scales of brain operation. However, despite decades of clinical and scientific investigation, there is no unifying theory of EEG organization, and the role of ongoing activity in sensory processing remains controversial. This study analyzed laminar profiles of synaptic activity [current source density CSD] and multiunit activity (MUA), both spontaneous and stimulus-driven, in primary auditory cortex of awake macaque monkeys. Our results reveal that the EEG is hierarchically organized; delta (1-4 Hz) phase modulates theta (4-10 Hz) amplitude, and theta phase modulates gamma (30-50 Hz) amplitude. This oscillatory hierarchy controls baseline excitability and thus stimulus-related responses in a neuronal ensemble. We propose that the hierarchical organization of ambient oscillatory activity allows auditory cortex to structure its temporal activity pattern so as to optimize the processing of rhythmic inputs.},
address = {Cognitive Neuroscience and Schizophrenia Program, Nathan Kline Inst., Orangeburg, New York 10962, USA.},
author = {Lakatos, Peter and Shah, Ankoor S and Knuth, Kevin H and Ulbert, Istvan and Karmos, George and Schroeder, Charles E},
file = {:Users/gmac/mendeley/Lakatos et al/Lakatos et al. - 2005 - An oscillatory hierarchy controlling neuronal excitability and stimulus processing in the auditory cortex.pdf:pdf},
journal = {Journal of Neurophysiology},
month = {sep},
number = {3},
pages = {1904--1911},
title = {{An oscillatory hierarchy controlling neuronal excitability and stimulus processing in the auditory cortex.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=15901760&retmode=ref&cmd=prlinks papers3://publication/doi/10.1152/jn.00263.2005},
volume = {94},
year = {2005}
}
@book{Brunswik1956,
address = {Berkeley},
author = {Brunswik, Egon},
month = {jan},
publisher = {University of California Press},
title = {{No Title}},
url = {papers3://publication/uuid/095B1374-10DC-4CF8-972B-BE4331E5A9E8},
year = {1956}
}
@article{McIntosh1997,
annote = {- studied PD on and off meds to investigate contribution of BG
- RAS was MIDI renaissance music
- after warm up, walked on their own, with RAS of preferred cadence, with RAS 10% faster, on their own
- on meds showed close phase coupling to RAS, off group most patients showed phase coupling
- improvements in velocity, cadence (steps/min); stride length for on and off groups but not controls},
author = {McIntosh, Gerald C and Brown, Susan H and Rice, Ruth R and Thaut, Michael H},
file = {:Users/gmac/mendeley/McIntosh et al/McIntosh et al. - 1997 - Rhythmic auditory-motor facilitation fo gait patterns in patients with Parkinson's disease.pdf:pdf},
journal = {Journal of Neurology, Neurosurgery, and Psychiatry},
month = {jan},
pages = {22--26},
title = {{Rhythmic auditory-motor facilitation fo gait patterns in patients with Parkinson's disease}},
url = {http://jnnp.bmj.com/content/62/1/22.full.pdf papers3://publication/uuid/53C72C01-291C-4199-99C6-68F3316BFFAE},
volume = {62},
year = {1997}
}
@article{Mognon2011,
author = {Mognon, Andrea and Jovicich, Jorge and Bruzzone, Lorenzo and Buiatti, Marco},
file = {:Users/gmac/mendeley/Mognon et al/Mognon et al. - 2011 - ADJUST An automatic EEG artifact detector based on the joint use of spatial and temporal features.pdf:pdf},
journal = {Psychophysiology},
month = {jan},
number = {2},
pages = {229--240},
title = {{ADJUST: An automatic EEG artifact detector based on the joint use of spatial and temporal features}},
volume = {48},
year = {2011}
}
@article{Coull2008,
annote = {The crucial distinction between explicit and implicit timing is whether or not the task instructions require subjects to provide an overt estimate of duration.


For tasks in which implicit timing is indexed by the temporal regularity of a motor output timing is said to emerge as a by-product of the dynamics of motor control (‘emergent timing') [10,11]. However, for tasks in which implicit timing is indexed by the temporal predictability of perceptual input timing is used to build an expectation of when the next stimulus will appear.},
author = {Coull, J T and Nobre, A C},
file = {:Users/gmac/mendeley/Coull, Nobre/Coull, Nobre - 2008 - Dissociating explicit timing from temporal expectation with fMRI.pdf:pdf},
journal = {Current Opinion in Neurobiology},
month = {apr},
number = {2},
pages = {137--144},
publisher = {Elsevier Ltd},
title = {{Dissociating explicit timing from temporal expectation with fMRI}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S095943880800069X papers3://publication/doi/10.1016/j.conb.2008.07.011},
volume = {18},
year = {2008}
}
@article{Hsu1991,
author = {Hsu, Kenneth and Hsu, Andrew},
file = {:Users/gmac/mendeley/Hsu, Hsu/Hsu, Hsu - 1991 - Self-similarity of the 1f noise called music.pdf:pdf},
journal = {Proceedings of the National Acadamy of Sciences},
keywords = {1/f},
month = {jan},
pages = {3507--3509},
title = {{Self-similarity of the "1/f noise" called music}},
url = {papers3://publication/uuid/DD110625-22BB-4A0E-8A3D-6B3BC085A271},
volume = {88},
year = {1991}
}
@article{Thut2011,
abstract = {The notion of driving brain oscillations by directly stimulating neuronal elements with rhythmic stimulation protocols has become increasingly popular in research on brain rhythms.},
author = {Thut, Gregor},
file = {:Users/gmac/mendeley/Thut/Thut - 2011 - Entrainment of perceptually relevant brain oscillations by non‑invasive rhythmic stimulation of the human brain.pdf:pdf},
month = {jul},
pages = {1--10},
title = {{Entrainment of perceptually relevant brain oscillations by non‑invasive rhythmic stimulation of the human brain}},
url = {papers3://publication/doi/10.3389/fpsyg.2011.00170/abstract},
year = {2011}
}
@article{Akerlind2005,
abstract = {Concerns with postdoctoral research training and employment outcomes are growing at an international level. Recent studies of postdoctoral and other contract researchers in various countries emphasize common issues associated with these appointments, including the absence of any systematic definition of postdoctoral research positions, lack of policy and data on postdoctoral researchers, and increasing dissatisfaction among postdoctoral researchers with the nature of their position and with their future employment prospects. These issues are explored further in the study reported here, through an interview-based investigation of the views of both postdoctoral researchers and postdoctoral supervisors with regard to the nature of postdoctoral research positions and the career development support provided within those positions. Key findings include substantial variation in the functions of postdoctoral researchers, and in the perceived purposes of such positions. Despite a widespread perception among both postdocs and their supervisors of limited employment opportunities in academia or research positions, there was a consistent focus among both parties on the postdoctoral period as providing preparation for such positions.},
author = {{\AA}kerlind, Gerlese S.},
doi = {10.1080/0729436052000318550},
file = {:Users/gmac/mendeley/{\AA}kerlind/{\AA}kerlind - 2005 - Postdoctoral researchers roles, functions and career prospects.pdf:pdf},
isbn = {0729436052000},
journal = {Higher Education Research & Development},
pages = {21--40},
title = {{Postdoctoral researchers: roles, functions and career prospects}},
volume = {24},
year = {2005}
}
@article{Baldwin1895,
author = {Baldwin, J Mark},
file = {:Users/gmac/mendeley/Baldwin/Baldwin - 1895 - Consciousness and Evolution.pdf:pdf},
journal = {Science},
month = {aug},
pages = {219--223},
title = {{Consciousness and Evolution}},
url = {http://www.jstor.org.ezproxy.lib.ryerson.ca/stable/1622600 papers3://publication/uuid/34D4DBEB-1882-46D7-833A-9F9AFAFF7FD0},
volume = {2},
year = {1895}
}
@article{Pastor2006,
author = {Pastor, Maria A and Thut, Gregor and Pascual-Leone, Alvaro},
file = {:Users/gmac/mendeley/Pastor, Thut, Pascual-Leone/Pastor, Thut, Pascual-Leone - 2006 - Modulation of steady-state auditory evoked potentials by cerebellar rTMS.pdf:pdf},
journal = {Experimental Brain Research},
month = {jul},
number = {4},
pages = {702--709},
title = {{Modulation of steady-state auditory evoked potentials by cerebellar rTMS}},
url = {http://link.springer.com/10.1007/s00221-006-0588-2 papers3://publication/doi/10.1007/s00221-006-0588-2},
volume = {175},
year = {2006}
}
@article{Sully1891,
author = {Sully, James},
file = {:Users/gmac/mendeley/Sully/Sully - 1891 - Book Review C. Stumpf, Tonpsychologie, II.pdf:pdf},
journal = {Mind},
month = {jan},
pages = {274--280},
title = {{Book Review: C. Stumpf, Tonpsychologie, II.}},
volume = {16},
year = {1891}
}
@article{Singh2017,
author = {Singh, Gurjit and Liskovoi, Lisa and Launer, Stefan and Russo, Frank A},
journal = {(under review)},
title = {{The Emotional Communication in Hearing Questionnaire (EMO-CHeQ): Development and Validation}},
year = {2017}
}
@article{Pitts2005,
abstract = {The views of audience members on their listening experiences are rarely heard in the research literature, although much speculation occurs on their roles and perspectives. This article reports on an investigation of audience experiences at a chamber music festival, and examines the ways in which social and musical enjoyment interact to generate commitment and a sense of involvement in the event. Audience members' anxieties for the future of classical music listening are discussed, and recommendations made for research and practice that could recognize more effectively the central role of the listener in contemporary musical life.},
author = {Pitts, Stephanie E},
file = {:Users/gmac/mendeley/Pitts/Pitts - 2005 - What Makes an Audience Investigating the Roles and Experiences of Listeners at a Chamber Music Festival.pdf:pdf},
journal = {Music & Letters},
month = {may},
number = {2},
pages = {257--269},
publisher = {Oxford University Press},
title = {{What Makes an Audience? Investigating the Roles and Experiences of Listeners at a Chamber Music Festival}},
url = {papers3://publication/doi/10.2307/3526537?ref=no-x-route:1caed8971de06c6a9fa934689a44afd0},
volume = {86},
year = {2005}
}
@article{VanNoorden1999,
author = {van Noorden, Leon and Moelants, Dirk},
file = {:Users/gmac/mendeley/van Noorden, Moelants/van Noorden, Moelants - 1999 - Resonance in the Perception of Musical Pulse.pdf:pdf},
journal = {Journal of New Music Research},
month = {may},
number = {1},
pages = {43--66},
title = {{Resonance in the Perception of Musical Pulse}},
url = {papers3://publication/uuid/FC89B730-F270-479F-9A0D-7E5B932DE401},
volume = {28},
year = {1999}
}
@article{Balkwill1999,
abstract = {Studies of the link between music and emotion have primarily focused on listeners' sensitivity to emotion in the music of their own culture. This sensitivity may reflect listeners' enculturation to the conventions of their culture's tonal system. However, it may also reflect responses to psychophysical dimensions of sound that are independent of musical ex- perience. A model of listeners' perception of emotion in music is pro- posed in which emotion in music is communicated through a combina- tion of universal and cultural cues. Listeners may rely on either of these cues, or both, to arrive at an understanding of musically expressed emo- tion. The current study addressed the hypotheses derived from this model using a cross-cultural approach. The following questions were investi- gated: Can people identify the intended emotion in music from an unfa- miliar tonal system? If they can, is their sensitivity to intended emotions associated with perceived changes in psychophysical dimensions of mu- sic? Thirty Western listeners rated the degree of joy, sadness, anger, and peace in 12 Hindustani raga excerpts (field recordings obtained in North India). In accordance with the raga-rasa system, each excerpt was in- tended to convey one of the four moods or "rasas" that corresponded to the four emotions rated by listeners. Listeners also provided ratings of four psychophysical variables: tempo, rhythmic complexity, melodic com- plexity, and pitch range. Listeners were sensitive to the intended emotion in ragas when that emotion was joy, sadness, or anger. Judgments of emotion were significantly related to judgments of psychophysical di- mensions, and, in some cases, to instrument timbre. The findings suggest that listeners are sensitive to musically expressed emotion in an unfamiliar tonal system, and that this sensitivity is facilitated by psychophysical cues.},
author = {Balkwill, Laura-lee and Thompson, William Forde},
doi = {10.2307/40285811},
file = {:Users/gmac/mendeley/Balkwill, Thompson/Balkwill, Thompson - 1999 - A Cross-Cultural Investigation of the Perception of and Cultural Cues Emotion in Music Psychophysical and Cu.pdf:pdf},
isbn = {0730-7829},
issn = {0730-7829},
journal = {Music Perception},
number = {1},
pages = {43--64},
pmid = {5030},
title = {{A Cross-Cultural Investigation of the Perception of and Cultural Cues Emotion in Music: Psychophysical and Cultural Cues}},
volume = {17},
year = {1999}
}
@article{Izzetoglu2004,
author = {Izzetoglu, Kurtulus and Bunce, Scott and Onaral, Banu and Pourrezaei, Kambiz and Chance, Britton},
file = {:Users/gmac/mendeley/Izzetoglu et al/Izzetoglu et al. - 2004 - Functional Optical Brain Imaging Usig Near-Infrared During Cognitive Tasks.pdf:pdf},
journal = {International Journal of Human-Computer Interaction},
month = {jul},
pages = {211--227},
title = {{Functional Optical Brain Imaging Usig Near-Infrared During Cognitive Tasks}},
url = {papers3://publication/uuid/5335F648-7E45-4F12-9D08-EF90C6D6C259},
volume = {17},
year = {2004}
}
@article{Thut2009,
author = {Thut, Gregor and Miniussi, Carlo},
file = {:Users/gmac/mendeley/Thut, Miniussi/Thut, Miniussi - 2009 - New insights into rhythmic brain activity from TMS–EEG studies.pdf:pdf},
journal = {Trends in Cognitive Sciences},
month = {apr},
number = {4},
pages = {182--189},
publisher = {Elsevier Ltd},
title = {{New insights into rhythmic brain activity from TMS–EEG studies}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661309000485 papers3://publication/doi/10.1016/j.tics.2009.01.004},
volume = {13},
year = {2009}
}
@article{Ladinig2013,
author = {Ladinig, Olivia and Huron, David},
file = {:Users/gmac/mendeley/Ladinig, Huron/Ladinig, Huron - 2013 - Minor Mode Cuing Do Composers Signal Minor Mode Sooner Than Major Mode.pdf:pdf},
journal = {Psychomusicology: Music, Mind, and Brain},
month = {jan},
number = {2},
pages = {117--122},
title = {{Minor Mode Cuing: Do Composers Signal Minor Mode Sooner Than Major Mode?}},
url = {papers3://publication/uuid/4A4568A5-D988-4704-BEF4-216DEAFA5DEF},
volume = {23},
year = {2013}
}
@article{Taborsky2007,
author = {Taborsky, Christopher},
file = {:Users/gmac/mendeley/Taborsky/Taborsky - 2007 - Musical Performance Anxiety A Review of Literature.pdf:pdf},
month = {jan},
pages = {1--11},
title = {{Musical Performance Anxiety: A Review of Literature}},
url = {papers3://publication/uuid/1254BD51-ECA7-4CFA-B47A-3EB6058A0850},
year = {2007}
}
@article{Tal2017a,
abstract = {Most humans have a near-automatic inclination to tap, clap, or move to the beat of music. The capacity to extract a periodic beat from a complex musical segment is remarkable, as it requires abstraction from the temporal structure of the stimulus. It has been suggested that nonlinear interactions in neuralnetworksresult in cortical oscillations at the beat frequency,andthatsuchentrained oscillations give rise to the percept of a beat or a pulse. Here we tested this neural resonance theory using MEG recordings as female and male individuals listened to 30 s sequences of complex syncopated drumbeats designed so that they contain no net energy at the pulse frequency when measured using linear analysis. We analyzed the spectrum of the neural activity while listening and compared it to the modulation spectrum of the stimuli.Wefound enhanced neural response in the auditory cortex at the pulse frequency.Wealso showed phase locking at the times of the missing pulse, even though the pulse was absent from the stimulus itself. Moreover, the strength of this pulse response correlated with individuals' speed in finding the pulse of these stimuli, as tested in a follow-up session. These findings demonstrate that neural activity at the pulse frequency in the auditory cortex is internally generated rather than stimulus-driven. The current results are both consistent with neural resonance theory and with models based on nonlinear response of the brain to rhythmic stimuli. The results thus help narrow the search for valid models of beat perception.},
author = {Tal, Idan and Large, Edward W. and Rabinovitch, Eshed and Wei, Yi and Schroeder, Charles E. and Poeppel, David and {Zion Golumbic}, Elana},
doi = {10.1523/JNEUROSCI.2500-16.2017},
file = {:Users/gmac/mendeley/Tal et al/Tal et al. - 2017 - Neural Entrainment to the Beat The “Missing-Pulse” Phenomenon.pdf:pdf},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
number = {26},
pages = {6331--6341},
pmid = {28559379},
title = {{Neural Entrainment to the Beat: The “Missing-Pulse” Phenomenon}},
url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.2500-16.2017},
volume = {37},
year = {2017}
}
@article{Barrett2010,
author = {Barrett, L F and Kensinger, E A},
file = {:Users/gmac/mendeley/Barrett, Kensinger/Barrett, Kensinger - 2010 - Context Is Routinely Encoded During Emotion Perception.pdf:pdf},
journal = {Psychological Science},
month = {apr},
number = {4},
pages = {595--599},
title = {{Context Is Routinely Encoded During Emotion Perception}},
url = {http://pss.sagepub.com/lookup/doi/10.1177/0956797610363547 papers3://publication/doi/10.1177/0956797610363547},
volume = {21},
year = {2010}
}
@article{Knudsen1983,
author = {Knudsen, Harold R. and Muzekari, Louis H.},
doi = {10.1007/BF00986266},
file = {:Users/gmac/mendeley/Knudsen, Muzekari/Knudsen, Muzekari - 1983 - The effects of verbal statements of context on facial expressions of emotion.pdf:pdf},
issn = {01915886},
journal = {Journal of Nonverbal Behavior},
number = {4},
pages = {202--212},
title = {{The effects of verbal statements of context on facial expressions of emotion}},
volume = {7},
year = {1983}
}
@article{Carrus2013,
abstract = {CORTEX, 49 (2013) 2186-2200. doi:10.1016/j.cortex.2012.08.024},
author = {Carrus, Elisa and Pearce, Marcus T and Bhattacharya, Joydeep},
file = {:Users/gmac/mendeley/Carrus, Pearce, Bhattacharya/Carrus, Pearce, Bhattacharya - 2013 - Melodic pitch expectation interacts with neural responses to syntactic but not semantic violations.pdf:pdf},
journal = {CORTEX},
month = {sep},
number = {8},
pages = {2186--2200},
publisher = {Elsevier Ltd},
title = {{Melodic pitch expectation interacts with neural responses to syntactic but not semantic violations}},
url = {http://dx.doi.org/10.1016/j.cortex.2012.08.024 papers3://publication/doi/10.1016/j.cortex.2012.08.024},
volume = {49},
year = {2013}
}
@article{Hoffmann2008,
author = {Hoffmann, Sven and Falkenstein, Michael},
editor = {Bussey, Tim},
file = {:Users/gmac/mendeley/Hoffmann, Falkenstein/Hoffmann, Falkenstein - 2008 - The Correction of Eye Blink Artefacts in the EEG A Comparison of Two Prominent Methods.pdf:pdf},
journal = {PLoS ONE},
month = {aug},
number = {8},
pages = {e3004--11},
title = {{The Correction of Eye Blink Artefacts in the EEG: A Comparison of Two Prominent Methods}},
url = {http://dx.plos.org/10.1371/journal.pone.0003004 papers3://publication/doi/10.1371/journal.pone.0003004},
volume = {3},
year = {2008}
}
@article{Fritz2009,
author = {Fritz, Thomas and Jentschke, Sebastian and Gosselin, Nathalie and Sammler, Daniela and Peretz, Isabelle and Turner, Robert and Friederici, Angela D and Koelsch, Stefan},
file = {:Users/gmac/mendeley/Fritz et al/Fritz et al. - 2009 - Universal Recognition of Three Basic Emotions in Music.pdf:pdf},
journal = {Current Biology},
month = {apr},
number = {7},
pages = {573--576},
publisher = {Elsevier Ltd},
title = {{Universal Recognition of Three Basic Emotions in Music}},
url = {http://dx.doi.org/10.1016/j.cub.2009.02.058 papers3://publication/doi/10.1016/j.cub.2009.02.058},
volume = {19},
year = {2009}
}
@article{Burghardt2009,
author = {Burghardt, Gordon M},
file = {:Users/gmac/mendeley/Burghardt/Burghardt - 2009 - Darwin's Legacy to Comparative Psychology and Ethology.pdf:pdf},
journal = {American Psychologist},
month = {mar},
number = {2},
pages = {102--110},
publisher = {American Psychological Association},
title = {{Darwin's Legacy to Comparative Psychology and Ethology}},
url = {http://dx.doi.org/10.1037/a0013385 papers3://publication/doi/10.1037/a0013385},
volume = {64},
year = {2009}
}
@article{Pineda2008,
author = {Pineda, Jaime A},
file = {:Users/gmac/mendeley/Pineda/Pineda - 2008 - Sensorimotor cortex as a critical component of an 'extended' mirror neuron system Does it solve the development, corresp.pdf:pdf},
journal = {Behavioral and Brain Functions},
keywords = {MNS,mu},
month = {jan},
number = {1},
pages = {47},
title = {{Sensorimotor cortex as a critical component of an 'extended' mirror neuron system: Does it solve the development, correspondence, and control problems in mirroring?}},
url = {http://www.behavioralandbrainfunctions.com/content/4/1/47 papers3://publication/doi/10.1186/1744-9081-4-47},
volume = {4},
year = {2008}
}
@article{Pecenka2011,
abstract = {Musical ensemble performance is a form of joint action that requires highly precise yet flexible interpersonal action coordination. To maintain synchrony during expressive passages that contain tempo variations, musicians presumably anticipate the sounds that will be produced by their co-performers. Our previous studies revealed that individuals differ in their ability to predict upcoming event timing when finger tapping in synchrony with tempo-changing pacing signals (i.e., the degree to which inter-tap intervals match vs. lag behind inter-onset intervals in the pacing signal varies between individuals). The current study examines the influence of these individual differences on synchronization performance in a dyadic tapping task. In addition, the stability of individual prediction tendencies across time is tested. Individuals with high or low prediction tendencies were invited to participate in two experimental sessions. In both sessions, participants were asked (1) to tap alone with a tempo-changing pacing signal and (2) to tap synchronously in dyads comprising individuals with similar or different prediction tendencies. Results indicated that individual differences in prediction tendencies were stable over several months and played a significant role in dyadic synchronization. Dyads composed of two high-predicting individuals tapped with higher accuracy and less variability than low-predicting dyads, while mixed dyads were intermediate. Prediction tendencies explained variance in dyadic synchronization performance over and above individual synchronization ability. These findings suggest that individual differences in temporal prediction ability may potentially mediate the interaction of cognitive, motor, and social processes underlying musical joint action.},
author = {Pecenka, Nadine and Keller, Peter E.},
doi = {10.1007/s00221-011-2616-0},
file = {:Users/gmac/mendeley/Pecenka, Keller/Pecenka, Keller - 2011 - The role of temporal prediction abilities in interpersonal sensorimotor synchronization.pdf:pdf},
isbn = {1432-1106 (Electronic) 0014-4819 (Linking)},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Dyadic finger tapping,Joint action,Sensorimotor synchronization,Temporal prediction},
number = {3-4},
pages = {505--515},
pmid = {21424257},
title = {{The role of temporal prediction abilities in interpersonal sensorimotor synchronization}},
volume = {211},
year = {2011}
}
@article{Plazak2010,
author = {Plazak, Joseph and Huron, David and Williams, Benjamin},
file = {:Users/gmac/mendeley/Plazak, Huron, Williams/Plazak, Huron, Williams - 2010 - EMR000084a_Plazak_Huron_Williams.pdf:pdf},
journal = {Empirical Musicology Review},
month = {apr},
number = {1},
pages = {10--17},
title = {{EMR000084a_Plazak_Huron_Williams}},
url = {papers3://publication/uuid/E349C314-FC71-44B4-A25E-C117BC73E7BD},
volume = {5},
year = {2010}
}
@article{Madison2006,
author = {Madison, Guy},
file = {:Users/gmac/mendeley/Madison/Madison - 2006 - Experiencing Groove Induced by Music Consistency and Phenomenology.pdf:pdf},
journal = {Music Perception},
month = {dec},
number = {2},
pages = {201--208},
title = {{Experiencing Groove Induced by Music: Consistency and Phenomenology}},
url = {papers3://publication/uuid/86885920-8847-4E01-B9F2-4B140857BE0A},
volume = {24},
year = {2006}
}
@article{Grube2010,
abstract = {CEREBELLAR FUNCTIONS IN TWO TYPES OF PERCEPTUAL TIMING WERE ASSESSED: the absolute (duration-based) timing of single intervals and the relative (beat-based) timing of rhythmic sequences. Continuous transcranial magnetic theta-burst stimulation (cTBS) was applied over the medial cerebellum and performance was measured adaptively before and after stimulation. A large and significant effect was found in the TBS (n = 12) compared to the SHAM (n = 12) group for single-interval timing but not for the detection of a regular beat or a deviation from it. The data support the existence of distinct perceptual timing mechanisms and an obligatory role of the cerebellum in absolute interval timing with a functional dissociation from relative timing of interval within rhythmic sequences based on a regular beat.},
address = {Newcastle Auditory Group, Institute of Neuroscience, Medical School, Newcastle University, Framlington Place Newcastle upon Tyne, UK.},
author = {Grube, Manon and Lee, Kwang-Hyuk and Griffiths, Timothy D and Barker, Anthony T and Woodruff, Peter W},
file = {:Users/gmac/mendeley/Grube et al/Grube et al. - 2010 - Transcranial magnetic theta-burst stimulation of the human cerebellum distinguishes absolute, duration-based from.pdf:pdf},
journal = {Frontiers in Psychology},
month = {jan},
pages = {171},
title = {{Transcranial magnetic theta-burst stimulation of the human cerebellum distinguishes absolute, duration-based from relative, beat-based perception of subsecond time intervals.}},
url = {http://journal.frontiersin.org/Journal/10.3389/fpsyg.2010.00171/full papers3://publication/doi/10.3389/fpsyg.2010.00171},
volume = {1},
year = {2010}
}
@article{Wong2007,
author = {Wong, Patrick C M and Skoe, Erika and Russo, Nicole M and Dees, Tasha and Kraus, Nina},
file = {:Users/gmac/mendeley/Wong et al/Wong et al. - 2007 - Musical experience shapes human brainstem encoding of linguistic pitch patterns.pdf:pdf},
journal = {Nature Neuroscience},
month = {mar},
title = {{Musical experience shapes human brainstem encoding of linguistic pitch patterns}},
url = {http://www.nature.com/doifinder/10.1038/nn1872 papers3://publication/doi/10.1038/nn1872},
year = {2007}
}
@article{Burger2017,
abstract = {Previous studies have found relationships between music-induced movement and musical character-istics on more general levels, such as tempo or pulse clarity. This study focused on synchronization abilities to music of finely-varying tempi and varying degrees of low-frequency spectral change/flux. Excerpts from six classic Motown/R&B songs at three different tempos (105, 115, and 130 BPM) were used as stimuli in this experiment. Each was then time-stretched by a factor of 5% with regard to the original tempo, yielding a total of 12 stimuli that were presented to 30 participants. Participants were asked to move along with the stimuli while being recorded with an optical motion capture system. Synchronization analysis was performed relative to the beat and the bar level of the music and four body parts. Results suggest that participants synchronized different body parts to specific metrical levels; in particular, vertical movements of hip and feet were synchronized to the beat level when the music con-tained large amounts of low-frequency spectral flux and had a slower tempo, while synchronization of head and hands was more tightly coupled to the weak flux stimuli at the bar level. Synchronization was generally more tightly coupled to the slower versions of the same stimuli, while synchronization showed an inverted u-shape effect at the bar level as tempo increased. These results indicate com-plex relationships between musical characteristics, in particular regarding metrical and temporal structure, and our ability to synchronize and entrain to such musical stimuli.},
author = {Burger, Birgitta and London, Justin and Thompson, Marc R and Toiviainen, Petri},
doi = {10.1007/s00426-017-0894-2},
file = {:Users/gmac/mendeley/Burger et al/Burger et al. - 2017 - Synchronization to metrical levels in music depends on low-frequency spectral components and tempo.pdf:pdf},
issn = {0340-0727},
journal = {Psychological Research},
month = {jul},
publisher = {Springer Berlin Heidelberg},
title = {{Synchronization to metrical levels in music depends on low-frequency spectral components and tempo}},
url = {http://link.springer.com/10.1007/s00426-017-0894-2},
year = {2017}
}
@article{Strait2011,
author = {Strait, Dana and Kraus, Nina},
file = {:Users/gmac/mendeley/Strait, Kraus/Strait, Kraus - 2011 - Playing Music for a Smarter Ear Cognitive, Perceptual and Neurobiological Evidence.pdf:pdf},
journal = {Music Perception: An Interdisciplinary Journal},
month = {dec},
number = {2},
pages = {133--146},
publisher = {University of California Press},
title = {{Playing Music for a Smarter Ear: Cognitive, Perceptual and Neurobiological Evidence}},
url = {http://www.jstor.org/stable/info/10.1525/mp.2011.29.2.133 papers3://publication/doi/10.1525/mp.2011.29.2.133},
volume = {29},
year = {2011}
}
@article{Lagarde2012,
abstract = {We examined to what extent the CNS can efficiently bind together the perception of non-coincident multimodal events with coordinated movements. To do so, we selected a bimanual coordination with left-right asymmetry, which was, achieving 3:2 polyrhythmic movements. We asked participants to synchronize left and right fingers' movements to events presented, respectively, to the left and to the right side. In two segregated conditions, sound was presented on one side at one frequency while touch was presented on the other side at the other frequency; thus, the left and right rhythms were paced via a distinct sensory modality. In the three control conditions, the stimuli on both sides were presented via the same sensory modality: sound, touch, or coincident sound and touch. Our aim was to contrast two opposing hypotheses: Sensory segregated pacing (1) stabilizes polyrhythmic coordination because it favors the distinction between the fast and the slow rhythm versus (2) destabilizes polyrhythmic coordination because it introduces a very strong asymmetry. We performed a parametric study in which the ability to maintain the polyrhythmic coordination was explored over a broad range of pacing rates. We found that switches from the polyrhythmic coordination to an isofrequency pattern took place only in the sensory segregated conditions, at the highest frequencies. Moreover, transitions were preceded by an increase in the variability of the synchronization of movement to stimuli. We therefore propose that the destabilization originating from the asymmetry between sensory modalities overrides the assumed segregation effect. We discuss the possible neuronal underpinnings of this failure of binding of movement to segregated sound and touch.},
author = {Lagarde, Julien and Zelic, Gregory and Mottet, Denis},
doi = {10.1007/s00221-012-3103-y},
file = {:Users/gmac/mendeley/Lagarde, Zelic, Mottet/Lagarde, Zelic, Mottet - 2012 - Segregated audio-tactile events destabilize the bimanual coordination of distinct rhythms.pdf:pdf},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Audio-tactile integration,Bimanual coordination,Binding,Multisensory integration,Polyrhythmic coordination,Segregation},
number = {3},
pages = {409--419},
pmid = {22569884},
title = {{Segregated audio-tactile events destabilize the bimanual coordination of distinct rhythms}},
volume = {219},
year = {2012}
}
@article{Burger2013,
abstract = {Music makes us move. Several factors can affect the characteristics of such movements, including individual factors or musical features. For this study, we investigated the effect of rhythm- and timbre-related musical features as well as tempo on movement characteristics. Sixty participants were presented with 30 musical stimuli representing different styles of popular music, and instructed to move along with the music. Optical motion capture was used to record participants' movements. Subsequently, eight movement features and four rhythm- and timbre-related musical features were computationally extracted from the data, while the tempo was assessed in a perceptual experiment. A subsequent correlational analysis revealed that, for instance, clear pulses seemed to be embodied with the whole body, i.e., by using various movement types of different body parts, whereas spectral flux and percussiveness were found to be more distinctly related to certain body parts, such as head and hand movement. A series of ANOVAs with the stimuli being divided into three groups of five stimuli each based on the tempo revealed no significant differences between the groups, suggesting that the tempo of our stimuli set failed to have an effect on the movement features. In general, the results can be linked to the framework of embodied music cognition, as they show that body movements are used to reflect, imitate, and predict musical characteristics.},
author = {Burger, Birgitta and Thompson, Marc R and Luck, Geoff and Saarikallio, Suvi and Toiviainen, Petri},
doi = {10.3389/fpsyg.2013.00183},
file = {:Users/gmac/mendeley/Burger et al/Burger et al. - 2013 - Influences of rhythm- and timbre-related musical features on characteristics of music-induced movement.pdf:pdf},
isbn = {1664-1078 (Electronic)},
issn = {1664-1078},
journal = {Frontiers in Psychology},
number = {April},
pages = {183},
pmid = {23641220},
title = {{Influences of rhythm- and timbre-related musical features on characteristics of music-induced movement}},
volume = {4},
year = {2013}
}
@book{Fancher2012,
address = {New York, London},
author = {Fancher, Raymond E and Rutherford, Alexandra},
month = {jan},
publisher = {W. W. Norton & Company, Inc.},
title = {{No Title}},
url = {papers3://publication/uuid/E3C999D1-75C9-4AB2-8A4C-958CE4F41099},
year = {2012}
}
@article{Baker2001,
author = {Baker, Felicity},
file = {:Users/gmac/mendeley/Baker/Baker - 2001 - The Effects of Live, Taped, and No Music on People Experiencing Posttraumatic Amnesia.pdf:pdf},
journal = {Journal of Music Therapy},
keywords = {audience,performance},
month = {oct},
number = {3},
pages = {170--192},
title = {{The Effects of Live, Taped, and No Music on People Experiencing Posttraumatic Amnesia}},
url = {papers3://publication/uuid/B0B71C26-00F6-4AC4-B149-01932205975C},
volume = {38},
year = {2001}
}
@article{Tervaniemi2004,
author = {Tervaniemi, Mari and Just, Viola and Koelsch, Stefan and Widmann, Andreas and Schr ger, Erich},
file = {:Users/gmac/mendeley/Tervaniemi et al/Tervaniemi et al. - 2004 - Pitch discrimination accuracy in musicians vs nonmusicians an event-related potential and behavioral study.pdf:pdf},
journal = {Experimental Brain Research},
month = {nov},
number = {1},
pages = {1--10},
title = {{Pitch discrimination accuracy in musicians vs nonmusicians: an event-related potential and behavioral study}},
url = {http://link.springer.com/10.1007/s00221-004-2044-5 papers3://publication/doi/10.1007/s00221-004-2044-5},
volume = {161},
year = {2004}
}
@article{Hornickel2011,
abstract = {Behavioural Brain Research, 216 (2010) 597-605. 10.1016/j.bbr.2010.08.051},
author = {Hornickel, Jane and Chandrasekaran, Bharath and Zecker, Steve and Kraus, Nina},
file = {:Users/gmac/mendeley/Hornickel et al/Hornickel et al. - 2011 - Auditory brainstem measures predict reading and speech-in-noise perception in school-aged children.pdf:pdf},
journal = {Behavioural Brain Research},
month = {jan},
number = {2},
pages = {597--605},
publisher = {Elsevier B.V.},
title = {{Auditory brainstem measures predict reading and speech-in-noise perception in school-aged children}},
url = {http://dx.doi.org/10.1016/j.bbr.2010.08.051 papers3://publication/doi/10.1016/j.bbr.2010.08.051},
volume = {216},
year = {2011}
}
@article{Chuen2016,
abstract = {A comprehensive characterization of autonomic and somatic responding within the auditory domain is currently lacking. We studied whether simple types of auditory change that occur frequently during music listening could elicit measurable changes in heart rate, skin conductance, respiration rate, and facial motor activity. Participants heard a rhythmically isochronous sequence consisting of a repeated standard tone, followed by a repeated target tone that changed in pitch, timbre, duration, intensity, or tempo, or that deviated momentarily from rhythmic isochrony. Changes in all parameters produced increases in heart rate. Skin conductance response magnitude was affected by changes in timbre, intensity, and tempo. Respiratory rate was sensitive to deviations from isochrony. Our findings suggest that music researchers interpreting physiological responses as emotional indices should consider acoustic factors that may influence physiology in the absence of induced emotions. [ABSTRACT FROM AUTHOR]},
author = {Chuen, Lorraine and Sears, David and Mcadams, Stephen},
doi = {10.1111/psyp.12633},
file = {:Users/gmac/mendeley/Chuen, Sears, Mcadams/Chuen, Sears, Mcadams - 2016 - Psychophysiological responses to auditory change.pdf:pdf},
issn = {14698986},
journal = {Psychophysiology},
keywords = {Auditory change,Facial EMG,Heart rate,Respiration rate,Skin conductance},
number = {6},
pages = {891--904},
pmid = {26927928},
title = {{Psychophysiological responses to auditory change}},
volume = {53},
year = {2016}
}
@article{Schneider2002,
annote = {- primary auditory cortex is largely confined to the medial two-thirds of Heschl's gyrus (HG), namely the anteromedial portion (amHG)
- neurophysiological: N19m-P30m amplitude about twice as large in professional musicians than non-musicians
- morphological: larger grey matter volumes of amHG in musicians than non-musicians (and in all of HG to a lesser extent)
- strong correlation between neurophysiological and anatomical parameters
- high correlation between neurophysiological and musical aptitude as measured by the AMMA},
author = {Schneider, Peter and Scherg, Michael and Dosch, H G{\"{u}}nter and Specht, Hans J and Gutschalk, Alexander and Rupp, Andr{\'{e}}},
file = {:Users/gmac/mendeley/Schneider et al/Schneider et al. - 2002 - Morphology of Heschl's gyrus reflects enhanced activation in the auditory cortex of musicians.pdf:pdf},
journal = {Nature Neuroscience},
month = {jun},
pages = {688--694},
title = {{Morphology of Heschl's gyrus reflects enhanced activation in the auditory cortex of musicians}},
url = {http://www.nature.com/doifinder/10.1038/nn871 papers3://publication/doi/10.1038/nn871},
volume = {5},
year = {2002}
}
@article{Lartillot2008,
author = {Lartillot, Olivier and Toiviainen, Petri and Eerola, Tuomas},
file = {:Users/gmac/mendeley/Lartillot, Toiviainen, Eerola/Lartillot, Toiviainen, Eerola - 2008 - A matlab toolbox for music information retrieval.pdf:pdf},
issn = {3540782397},
journal = {Data analysis, machine learning and applications},
month = {jan},
pages = {261--268},
publisher = {Springer},
title = {{A matlab toolbox for music information retrieval}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-78246-9_31},
year = {2008}
}
@article{Williams2005a,
abstract = {It is not known how the brain and autonomic systems interact during perception of facial signals of danger.We recorded blood-oxygen-level-dependent (BOLD) activity using fMRI and simultaneous skin conductance measures of autonomic arousal in healthy subjects. Distinct response profiles were elicited for fear (enhanced arousal with amygdala activity), anger (rapid onset, slow recovery arousal responses with anterior cingulate) and disgust (delayed arousal responses with insula and basal ganglia activity). The findings suggest that fear, anger and disgust perception involves specific interactions in the neural arousal systems for emotion and motivation.},
author = {Williams, Leanne M. and Das, Pritha and Liddell, Belinda and Olivieri, Gloria and Peduto, Anthony and Brammer, MJ and Gordon, Evian},
doi = {10.1097/00001756-200501190-00012},
file = {:Users/gmac/mendeley/Williams et al/Williams et al. - 2005 - BOLD, sweat and fears fMRI and skin conductance distinguish facial fear signals.pdf:pdf},
isbn = {0959-4965 (Print)\r0959-4965 (Linking)},
issn = {0959-4965},
journal = {NeuroReport},
keywords = {amygdala,anger,autonomic arousal,disgust,emotion,face,fear,functional mri,skin conductance},
number = {1},
pages = {49--52},
pmid = {15618889},
title = {{BOLD, sweat and fears: fMRI and skin conductance distinguish facial fear signals}},
url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00001756-200501190-00012},
volume = {16},
year = {2005}
}
@article{Plomp1965,
author = {Plomp, R and Levelt, W J M},
file = {:Users/gmac/mendeley/Plomp, Levelt/Plomp, Levelt - 1965 - Tonal Consonance and Critical Bandwidth.pdf:pdf},
journal = {Multiple values selected},
keywords = {dissonance},
month = {apr},
number = {4},
pages = {548--560},
title = {{Tonal Consonance and Critical Bandwidth}},
url = {http://scitation.aip.org/getpdf/servlet/GetPDFServlet?filetype=pdf&id=JASMAN000038000004000548000001&idtype=cvips&doi=10.1121/1.1909741&prog=normal papers3://publication/uuid/7AF01D38-1134-42A9-833E-47AA48EC37EF},
volume = {38},
year = {1965}
}
@article{Krishnan2000,
annote = {- played 80ms 400-600Hz and 600-400Hz tone sweeps to normal-hearing participants at different amplitudes
- FFR closely following time-varying frequency
- FFR amplitude increases with stimulus amplitude
- FFR amplitude increases with decreasing frequency
- FFR amplitude greater for rising than falling tone sweep},
author = {Krishnan, Ananthanarayan and Parkinson, Jeff},
file = {:Users/gmac/mendeley/Krishnan, Parkinson/Krishnan, Parkinson - 2000 - Human Frequency-Following Response Representation of Tonal Sweeps.pdf:pdf},
journal = {Audiology & Neuro-Otology},
month = {jan},
pages = {312--321},
title = {{Human Frequency-Following Response: Representation of Tonal Sweeps}},
url = {http://search.proquest.com.ezproxy.lib.ryerson.ca/docview/220862066 papers3://publication/uuid/B24CAB18-481A-48CC-962A-3FC99D71E879},
volume = {5},
year = {2000}
}
@article{Kaslow1992,
author = {Kaslow, Nadine J and McCarthy, Susan M and Rogers, James H and Summerville, Mary B},
file = {:Users/gmac/mendeley/Kaslow et al/Kaslow et al. - 1992 - Psychology Postdoctoral Training A Developmental Perspective.pdf:pdf},
journal = {Professional Psychology: Research and Practice},
pages = {369--375},
title = {{Psychology Postdoctoral Training : A Developmental Perspective}},
volume = {23},
year = {1992}
}
@article{Nozaradan2017c,
abstract = {The combination of frequency-tagging with electroencephalography (EEG) has recently proved fruitful for understanding the perception of beat and meter in musical rhythm, a common behavior shared by humans of all cultures. EEG frequency-tagging allows the objective measurement of input–output transforms to investigate beat perception, its modulation by exogenous and endogenous factors, development, and neural basis. Recent doubt has been raised about the validity of comparing frequency-domain representations of auditory rhythmic stimuli and corresponding EEG responses, assuming that it implies a one-to-one mapping between the envelope of the rhythmic input and the neural output, and that it neglects the sensitivity of frequency-domain representations to acoustic features making up the rhythms. Here we argue that these elements actually reinforce the strengths of the approach. The obvious fact that acoustic features influence the frequency spectrum of the sound envelope precisely justifies taking into consideration the sounds used to generate a beat percept for interpreting neural responses to auditory rhythms. Most importantly, the many-to-one relationship between rhythmic input and perceived beat actually validates an approach that objectively measures the input–output transforms underlying the perceptual categorization of rhythmic inputs. Hence, provided that a number of potential pitfalls and fallacies are avoided, EEG frequency-tagging to study input–output relationships appears valuable for understanding rhythm perception.},
author = {Nozaradan, Sylvie and Keller, Peter E. and Rossion, Bruno and Mouraux, Andr{\'{e}}},
doi = {10.1007/s10548-017-0605-8},
file = {:Users/gmac/mendeley/Nozaradan et al/Nozaradan et al. - 2017 - EEG Frequency-Tagging and Input–Output Comparison in Rhythm Perception.pdf:pdf},
isbn = {0123456789},
issn = {0896-0267},
journal = {Brain Topography},
keywords = {Auditory system,EEG,Frequency-tagging,Neural transform,Perceptual categorization,Rhythm and beat perception},
pages = {1--8},
title = {{EEG Frequency-Tagging and Input–Output Comparison in Rhythm Perception}},
year = {2017}
}
@incollection{Stumpf1930,
address = {Worcester, MA},
author = {Stumpf, Carl},
booktitle = {History of Psychology in Autobiography},
editor = {Murchison, Carl},
file = {:Users/gmac/mendeley/Stumpf/Stumpf - 1930 - Autobiography of Carl Stumpf BT - History of Psychology in Autobiography.pdf:pdf},
month = {jan},
pages = {389--441},
publisher = {Clark University Press},
title = {{Autobiography of Carl Stumpf BT  - History of Psychology in Autobiography}},
url = {papers3://publication/uuid/836A8D19-3C5F-477B-9152-8142E3F29877},
volume = {1},
year = {1930}
}
@article{Large1994a,
abstract = {Many connectionist approaches to musical expectancy and music composition let the question of 'What next?' overshadow the equally important question of 'When next?'. One cannot escape the latter question, one of remporal structure, when considering the perception of musical meter. We view the perception of mem'cal structure as a dynamic process where the temporal organization of external musical events synchronizes, or entrains, a listener's internal processing mechanisms. This article introduces a novel connectionist unit, based upon a mathematical model of entrainment, capable of phase- and frequency-locking to periodic components of incoming rhythmic patterns. Networks of these units can self-orga- nize temporally structured responses to rhythmic patterns. The resulting network behavior embodies the perception of mem'cal structure. The article concludes with a discussion of the implications of our approach for theories of memcal structure and musical expectancy.},
author = {Large, Edward W and Kolen, John F.},
doi = {10.1080/09540099408915723},
file = {:Users/gmac/mendeley/Large, Kolen/Large, Kolen - 1994 - Resonance and the perception of musical meter(2).pdf:pdf},
isbn = {0954009940891},
issn = {0954-0091},
journal = {Connection Science},
number = {1},
pages = {177--208},
title = {{Resonance and the perception of musical meter}},
volume = {6},
year = {1994}
}
@article{Phillips-Silver2005,
author = {Phillips-Silver, Jessica and Trainor, Laurel J},
file = {:Users/gmac/mendeley/Phillips-Silver, Trainor/Phillips-Silver, Trainor - 2005 - Feeling the Beat Movement Influences Infant Rhythm Perception.pdf:pdf},
journal = {Science},
month = {jun},
number = {5727},
pages = {1430},
title = {{Feeling the Beat: Movement Influences Infant Rhythm Perception}},
url = {http://www.sciencemag.org/cgi/content/abstract/308/5727/1430 papers3://publication/doi/10.1126/science.1110922},
volume = {308},
year = {2005}
}
@article{Kaviani1999,
abstract = {It has been widely reported that the eyeblink component of the acoustic startle reflex can be modulated by emotionally-toned slide stimuli; pleasant slides reduce eyeblink amplitudes whereas unpleasant slides enhance them. The present study examines the modulation of the acoustic startle reflex by short (2-min) film-clips classified as pleasant, unpleasant or neutral, on the basis of subjective ratings. These film-clips were also evaluated with respect to their test-retest reliability in producing affective states as well as modulating startle reflexes. Overall, results showed significant reduction of startle during pleasant clips and augmentation during unpleasant clips. However, on first showing, one of the two unpleasant clips (a medical demonstration film depicting details of toe surgery) actually inhibited the startle reflex rather than augmented it. This is discussed in terms of the proposition that only stimuli which arouse fear can be guaranteed to augment startle; stimuli that are repulsive may produce perceptual and emotional 'blunting' that reduces startle amplitude.},
author = {Kaviani, H and Gray, J A and Checkley, S A and Kumari, V and Wilson, G D},
doi = {10.1016/S0167-8760(98)00063-4},
file = {:Users/gmac/mendeley/Kaviani et al/Kaviani et al. - 1999 - Modulation of the acoustic startle reflex by emotionally-toned film-clips.pdf:pdf},
journal = {International journal of psychophysiology : official journal of the International Organization of Psychophysiology},
keywords = {Acoustic Stimulation,Adult,Blinking,Blinking: physiology,Electromyography,Emotions,Emotions: physiology,Female,Humans,Male,Startle Reaction,Startle Reaction: physiology},
number = {1},
pages = {47--54},
pmid = {10192007},
title = {{Modulation of the acoustic startle reflex by emotionally-toned film-clips.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10192007},
volume = {32},
year = {1999}
}
@article{Mitchell2007,
author = {Mitchell, Rachel L C},
doi = {10.1080/02699930601133994},
file = {:Users/gmac/mendeley/Mitchell/Mitchell - 2007 - Age-related decline in the ability to decode emotional prosody Primary or secondary phenomenon.pdf:pdf},
journal = {Cognition & Emotion},
number = {7},
pages = {1435--1454},
title = {{Age-related decline in the ability to decode emotional prosody: Primary or secondary phenomenon?}},
volume = {21},
year = {2007}
}
@article{Song2011,
abstract = {The presence of irrelevant auditory information (other talkers, environmental noises) presents a major challenge to listening to speech. The fundamental frequency (F(0)) of the target speaker is thought to provide an important cue for the extraction of the speaker's voice from background noise, but little is known about the relationship between speech-in-noise (SIN) perceptual ability and neural encoding of the F(0). Motivated by recent findings that music and language experience enhance brainstem representation of sound, we examined the hypothesis that brainstem encoding of the F(0) is diminished to a greater degree by background noise in people with poorer perceptual abilities in noise. To this end, we measured speech-evoked auditory brainstem responses to /da/ in quiet and two multitalker babble conditions (two-talker and six-talker) in native English-speaking young adults who ranged in their ability to perceive and recall SIN. Listeners who were poorer performers on a standardized SIN measure demonstrated greater susceptibility to the degradative effects of noise on the neural encoding of the F(0). Particularly diminished was their phase-locked activity to the fundamental frequency in the portion of the syllable known to be most vulnerable to perceptual disruption (i.e., the formant transition period). Our findings suggest that the subcortical representation of the F(0) in noise contributes to the perception of speech in noisy conditions.},
author = {Song, Judy H and Skoe, Erika and Banai, Karen and Kraus, Nina},
doi = {10.1162/jocn.2010.21556},
file = {:Users/gmac/mendeley/Song et al/Song et al. - 2011 - Perception of speech in noise neural correlates.pdf:pdf},
issn = {1530-8898},
journal = {Journal of cognitive neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Auditory Pathways,Auditory Pathways: physiology,Brain Mapping,Brain Stem,Brain Stem: physiology,Electroencephalography,Evoked Potentials, Auditory, Brain Stem,Evoked Potentials, Auditory, Brain Stem: physiolog,Female,Humans,Male,Music,Noise,Reaction Time,Reaction Time: physiology,Speech Acoustics,Speech Perception,Speech Perception: physiology,Young Adult},
language = {en},
month = {sep},
number = {9},
pages = {2268--79},
pmid = {20681749},
publisher = {MIT Press238 Main St., Suite 500, Cambridge, MA 02142-1046USAjournals-info@mit.edu},
title = {{Perception of speech in noise: neural correlates.}},
volume = {23},
year = {2011}
}
@article{Iguchi2007,
author = {Iguchi, Yoshinobu and Hoshi, Yoko and Nemoto, Masahito and Taira, Masato and Hashimoto, Isao},
file = {:Users/gmac/mendeley/Iguchi et al/Iguchi et al. - 2007 - Co-activation of the secondary somatosensory and auditory cortices facilitates frequency discrimination of vibrot.pdf:pdf},
journal = {Neuroscience},
month = {aug},
number = {2},
pages = {461--472},
title = {{Co-activation of the secondary somatosensory and auditory cortices facilitates frequency discrimination of vibrotactile stimuli}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0306452207007749},
volume = {148},
year = {2007}
}
@article{Chapin2010,
author = {Chapin, Heather and Jantzen, Kelly and Kelso, J A Scott and Steinberg, Fred and Large, Edward W},
editor = {Rodriguez-Fornells, Antoni},
file = {:Users/gmac/mendeley/Chapin et al/Chapin et al. - 2010 - Dynamic Emotional and Neural Responses to Music Depend on Performance Expression and Listener Experience.pdf:pdf},
journal = {PLoS ONE},
month = {dec},
number = {12},
pages = {e13812},
title = {{Dynamic Emotional and Neural Responses to Music Depend on Performance Expression and Listener Experience}},
url = {http://dx.plos.org/10.1371/journal.pone.0013812.s003 papers3://publication/doi/10.1371/journal.pone.0013812.s003},
volume = {5},
year = {2010}
}
@article{Gregory1996,
author = {Gregory, Andrew H and Varney, Nicolas},
file = {:Users/gmac/mendeley/Gregory, Varney/Gregory, Varney - 1996 - Cross-cultural Comparisons in the Affective Responsive to Music.pdf:pdf},
journal = {Psychology of Music},
pages = {47--52},
title = {{Cross-cultural Comparisons in the Affective Responsive to Music}},
volume = {24},
year = {1996}
}
@article{Juslin2013,
abstract = {Numerous studies have investigated whether music can reliably convey emotions to listeners, and—if so—what musical parameters might carry this information.},
author = {Juslin, Patrik N},
file = {:Users/gmac/mendeley/Juslin/Juslin - 2013 - What does music express Basic emotions and beyond.pdf:pdf},
month = {sep},
pages = {1--14},
title = {{What does music express? Basic emotions and beyond}},
url = {http://journal.frontiersin.org/Journal/10.3389/fpsyg.2013.00596/full papers3://publication/doi/10.3389/fpsyg.2013.00596/abstract},
year = {2013}
}
@article{Iwanaga1996,
abstract = {The present study was designed to examine the effect of repetitive exposure to music on subjective and physiological responses. Subjects were 12 undergraduate and graduate behavioral sciences majors. The pieces used in this study were Stravinsky's ''Sacrifice Dance'' from The Rite of Spring as the excitative selection and the orchestral version of Satie's Gymnopedie No. 1 as the sedative selection. Both pieces were presented a total of four times at 5-minute intervals. Musical activity was perceived as consistently higher for the excitative selection than for the sedative one. Subjects reported consistently high levels of relaxation and low tension while listening to the sedative music while they reported contrasting feelings during the excitative piece. Subjects also reported that relaxation increased with repeated listenings. There was significant music by phase interactions for heart rate (HR) and respiration rate (RR); HR and RR did not change during the excitative music, while they gradually decreased during the sedative music. Results indicate that the sedative effect of music was more apparent in the second half of the pieces.},
author = {Iwanaga, M. and Ikeda, M. and Iwaki, T.},
doi = {10.1093/jmt/33.3.219},
file = {:Users/gmac/mendeley/Iwanaga, Ikeda, Iwaki/Iwanaga, Ikeda, Iwaki - 1996 - The effects of repetitive exposure to music on subjective and physiological responses.pdf:pdf},
issn = {0022-2917},
journal = {Journal of Music Therapy},
number = {3},
pages = {219--230},
title = {{The effects of repetitive exposure to music on subjective and physiological responses}},
url = {http://apps.isiknowledge.com.proxy.lib.ohio-state.edu/full_record.do?product=WOS&search_mode=CitationReport&qid=17&SID=2D4g3ah4lpmo9lifaHj&page=2&doc=13&cacheurlFromRightClick=no},
volume = {33},
year = {1996}
}
@article{Gerlach2014,
abstract = {We spend much of our daily lives imagining how we can reach future goals and what will happen when we attain them. Despite the prevalence of such goal-directed simulations, neuroimaging studies on planning have mainly focused on executive processes in the frontal lobe. This experiment examined the neural basis of process simulations, during which participants imagined themselves going through steps toward attaining a goal, and outcome simulations, during which participants imagined events they associated with achieving a goal. In the scanner, participants engaged in these simulation tasks and an odd/even control task. We hypothesized that process simulations would recruit default and frontoparietal control network regions, and that outcome simulations, which allow us to anticipate the affective consequences of achieving goals, would recruit default and reward-processing regions. Our analysis of brain activity that covaried with process and outcome simulations confirmed these hypotheses. A functional connectivity analysis with posterior cingulate, dorsolateral prefrontal cortex and anterior inferior parietal lobule seeds showed that their activity was correlated during process simulations and associated with a distributed network of default and frontoparietal control network regions. During outcome simulations, medial prefrontal cortex and amygdala seeds covaried together and formed a functional network with default and reward-processing regions.},
address = {Department of Psychology, Harvard University, 33 Kirkland Street, Cambridge, MA 02138, USA. gerlach@fas.harvard.edu.},
author = {Gerlach, Kathy D and Spreng, R Nathan and Madore, Kevin P and Schacter, Daniel L},
file = {:Users/gmac/mendeley/Gerlach et al/Gerlach et al. - 2014 - Future planning default network activity couples with frontoparietal control network and reward-processing regio.pdf:pdf},
journal = {Social cognitive and affective neuroscience},
month = {may},
title = {{Future planning: default network activity couples with frontoparietal control network and reward-processing regions during process and outcome simulations.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=24493844&retmode=ref&cmd=prlinks papers3://publication/doi/10.1093/scan/nsu001},
year = {2014}
}
@article{Vines2006,
abstract = {We investigate the dynamics of sensory integration for perceiving musical performance, a complex natural behavior. Thirty musically trained participants saw, heard, or both saw and heard, performances by two clarinetists. All participants used a sliding potentiometer to make continuous judgments of tension (a measure correlated with emotional response) and continuous judgments of phrasing (a measure correlated with perceived musical structure) as performances were presented. The data analysis sought to reveal relations between the sensory modalities (vision and audition) and to quantify the effect of seeing the performances on participants' overall subjective experience of the music. In addition to traditional statistics, functional data analysis techniques were employed to analyze time-varying aspects of the data. The auditory and visual channels were found to convey similar experiences of phrasing but different experiences of tension through much of the performances. We found that visual information served both to augment and to reduce the experience of tension at different points in the musical piece (as revealed by functional linear modeling and functional significance testing). In addition, the musicians' movements served to extend the sense of phrasing, to cue the beginning of new phrases, to indicate musical interpretation, and to anticipate changes in emotional content. Evidence for an interaction effect suggests that there may exist an emergent quality when musical performances are both seen and heard. The investigation augments knowledge of human communicative processes spanning language and music, and involving multiple modalities of emotion and information transfer. ?? 2005 Elsevier B.V. All rights reserved.},
author = {Vines, Bradley W. and Krumhansl, Carol L. and Wanderley, Marcelo M. and Levitin, Daniel J},
doi = {10.1016/j.cognition.2005.09.003},
file = {:Users/gmac/mendeley/Vines et al/Vines et al. - 2006 - Cross-modal interactions in the perception of musical performance.pdf:pdf},
isbn = {0010-0277 (Print)\r0010-0277 (Linking)},
issn = {00100277},
journal = {Cognition},
keywords = {Cross-modal interactions,Emotion,Gesture,Music cognition},
number = {1},
pages = {80--113},
pmid = {16289067},
title = {{Cross-modal interactions in the perception of musical performance}},
volume = {101},
year = {2006}
}
@article{Ruckmick1937,
author = {Ruckmick, Christian A},
file = {:Users/gmac/mendeley/Ruckmick/Ruckmick - 1937 - Carl Stumpf.pdf:pdf},
journal = {The Psychological Bulletin},
month = {apr},
pages = {187--190},
title = {{Carl Stumpf}},
url = {papers3://publication/uuid/A8D8C423-0F69-4D03-A098-0B9D7F9A1073},
volume = {34},
year = {1937}
}
@article{Stel2008,
author = {Stel, Mari{\"{e}}lle and van Knippenberg, Ad},
file = {:Users/gmac/mendeley/Stel, van Knippenberg/Stel, van Knippenberg - 2008 - The Role of Facial Mimicry in the Recognition of Affect.pdf:pdf},
journal = {Psychological Science},
number = {10},
pages = {984--985},
title = {{The Role of Facial Mimicry in the Recognition of Affect}},
volume = {19},
year = {2008}
}
@article{DeWitt1987,
author = {DeWitt, Lucinda A and Crowder, Robert G},
file = {:Users/gmac/mendeley/DeWitt, Crowder/DeWitt, Crowder - 1987 - Tonal fusion of consonant musical intervals The oomph in Stumpf.pdf:pdf},
journal = {Perception & Psychophysics},
month = {jan},
number = {1},
pages = {73--84},
title = {{Tonal fusion of consonant musical intervals: The oomph in Stumpf}},
url = {papers3://publication/uuid/030AA7FF-B3D7-44D6-9E06-2BDF2B2D128C},
volume = {41},
year = {1987}
}
@article{Burland2010,
author = {Burland, Karen and Pitts, Stephanie E},
file = {:Users/gmac/mendeley/Burland, Pitts/Burland, Pitts - 2010 - Understanding Jazz Audiences Listening and Learning at the Edinburgh Jazz and Blues Festival.pdf:pdf},
journal = {Journal of New Music Research},
month = {jun},
number = {2},
pages = {125--134},
title = {{Understanding Jazz Audiences: Listening and Learning at the Edinburgh Jazz and Blues Festival}},
url = {http://www.tandfonline.com/doi/abs/10.1080/09298215.2010.493613 papers3://publication/doi/10.1080/09298215.2010.493613},
volume = {39},
year = {2010}
}
@article{Blood1999,
abstract = {Neural correlates of the often-powerful emotional responses to music are poorly understood. Here we used positron emission tomography to examine cerebral blood flow (CBF) changes related to affective responses to music. Ten volunteers were scanned while listening to six versions of a novel musical passage varying systematically in degree of dissonance. Reciprocal CBF covariations were observed in several distinct paralimbic and neocortical regions as a function of dissonance and of perceived pleasantness/unpleasantness. The findings suggest that music may recruit neural mechanisms similar to those previously associated with pleasant/unpleasant emotional states, but different from those underlying other components of music perception, and other emotions such as fear.},
author = {Blood, A J and Zatorre, R J and Bermudez, P and Evans, A C},
doi = {10.1038/7299},
file = {:Users/gmac/mendeley/Blood et al/Blood et al. - 1999 - Emotional responses to pleasant and unpleasant music correlate with activity in paralimbic brain regions.pdf:pdf},
isbn = {1097-6256 (Print)\n1097-6256 (Linking)},
journal = {Nature neuroscience},
number = {4},
pages = {382--387},
pmid = {10204547},
title = {{Emotional responses to pleasant and unpleasant music correlate with activity in paralimbic brain regions.}},
volume = {2},
year = {1999}
}
@article{Walworth2010,
author = {Walworth, Darcy D},
file = {:Users/gmac/mendeley/Walworth/Walworth - 2010 - Effect of Live Music Therapy for Patients Undergoing Magnetic Resonance Imaging.pdf:pdf},
journal = {Journal of Music Therapy},
keywords = {audience,performance},
month = {jan},
number = {4},
pages = {335--350},
title = {{Effect of Live Music Therapy for Patients Undergoing Magnetic Resonance Imaging}},
url = {papers3://publication/uuid/97611B13-AF1C-4018-8C7D-B59E512FF08D},
volume = {47},
year = {2010}
}
@article{Thompson2008,
author = {Thompson, William Forde and Russo, Frank A and Quinto, Lena},
file = {:Users/gmac/mendeley/Thompson, Russo, Quinto/Thompson, Russo, Quinto - 2008 - Audio-visual integration of emotional cues in song.pdf:pdf},
journal = {Cognition & Emotion},
month = {dec},
number = {8},
pages = {1457--1470},
title = {{Audio-visual integration of emotional cues in song}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02699930701813974 papers3://publication/doi/10.1080/02699930701813974},
volume = {22},
year = {2008}
}
@article{Repp2003,
author = {Repp, Bruno H},
file = {:Users/gmac/mendeley/Repp/Repp - 2003 - Rate Limits in Sensorimotor Synchronization With Auditory and Visual Sequences The Synchronization Threshold and the Benef.pdf:pdf},
journal = {Journal of Motor Behavior},
month = {jan},
pages = {355--370},
title = {{Rate Limits in Sensorimotor Synchronization With Auditory and Visual Sequences: The Synchronization Threshold and the Benefits and Costs of Interval Subdivision}},
url = {papers3://publication/uuid/7D02C557-C106-43E5-9210-A5450481FCF2},
volume = {35},
year = {2003}
}
@article{Frijda1989,
abstract = {Ss in 2 studies were asked to report on 32 emotional states. Ss were asked to remember instances of experiencing these states and, for each experience, to fill out a questionnaire on appraisal dimensions and action readiness modes. Appraisal patterns as well as patterns of action readiness show distinct relations to various emotion categories, or names; the contributions of both kinds of components to emotion distinction are in part independent and additive. Multiple correlations, predicting action readiness scores from appraisal scores, demonstrated significant relations between particular modes of action readiness and particular appraisal patterns. The results of these studies are interpreted as providing support for the view that emotions can be regarded both as experiences of forms of ap- praisal and as states of action readiness. Emotions can profitably be analyzed in terms of sets of components, in which action readiness components take an important share.},
author = {Frijda, Nico H and Kuipers, Peter and ter Schure, Elisabeth},
doi = {10.1037/0022-3514.57.2.212},
file = {:Users/gmac/mendeley/Frijda, Kuipers, ter Schure/Frijda, Kuipers, ter Schure - 1989 - Relations among emotion, appraisal, and emotional action readiness.pdf:pdf},
isbn = {1939-1315},
issn = {0022-3514},
journal = {Journal of Personality and Social Psychology},
keywords = {action readiness,action tendencies,appraisal,emotions},
number = {2},
pages = {212--228},
pmid = {21220612},
title = {{Relations among emotion, appraisal, and emotional action readiness}},
volume = {57},
year = {1989}
}
@article{Muller2013,
author = {M{\"{u}}ller, Viktor and S{\"{a}}nger, Johanna and Lindenberger, Ulman},
editor = {Sporns, Olaf},
file = {:Users/gmac/mendeley/M{\"{u}}ller, S{\"{a}}nger, Lindenberger/M{\"{u}}ller, S{\"{a}}nger, Lindenberger - 2013 - Intra- and Inter-Brain Synchronization during Musical Improvisation on the Guitar.pdf:pdf},
journal = {PLoS ONE},
month = {sep},
number = {9},
pages = {e73852},
title = {{Intra- and Inter-Brain Synchronization during Musical Improvisation on the Guitar}},
url = {http://dx.plos.org/10.1371/journal.pone.0073852.s012 papers3://publication/doi/10.1371/journal.pone.0073852.s012},
volume = {8},
year = {2013}
}
@article{Baumgartner2006,
author = {Baumgartner, Thomas and Esslen, Michaela and J{\"{a}}ncke, Lutz},
file = {:Users/gmac/mendeley/Baumgartner, Esslen, J{\"{a}}ncke/Baumgartner, Esslen, J{\"{a}}ncke - 2006 - From emotion perception to emotion experience Emotions evoked by pictures and classical music.pdf:pdf},
journal = {International Journal of Psychophysiology},
month = {apr},
number = {1},
pages = {34--43},
title = {{From emotion perception to emotion experience: Emotions evoked by pictures and classical music}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167876005001327 papers3://publication/doi/10.1016/j.ijpsycho.2005.04.007},
volume = {60},
year = {2006}
}
@article{Gabrielsson1996,
abstract = {Abstract Nine professional musicians were instructed to perform short melodies using various instruments-the violin, electric guitar, flute, and singing voice-so as to communicate specific emotional characters to listeners . The performances were first validated by having ... 
},
author = {Gabrielsson, Alf and Juslin, Patrik N},
file = {:Users/gmac/mendeley/Gabrielsson, Juslin/Gabrielsson, Juslin - 1996 - Emotional Expression in Music Performance Between the Performer's Intention and the Listener's Experience.pdf:pdf},
journal = {Psychology of Music},
month = {apr},
number = {1},
pages = {68--91},
publisher = {SAGE Publications},
title = {{Emotional Expression in Music Performance: Between the Performer's Intention and the Listener's Experience}},
url = {http://pom.sagepub.com/cgi/doi/10.1177/0305735696241007 papers3://publication/doi/10.1177/0305735696241007},
volume = {24},
year = {1996}
}
@inproceedings{Livingstone2012,
author = {Livingstone, Steven R and Peck, Katlyn and Russo, Frank A},
booktitle = {Annual Meeting of the Canadian Society for Brain, Behaviour and Cognitive Science},
title = {{RAVDESS: The Ryerson Audio-Visual Database of Emotional Speech and Song}},
year = {2012}
}
@article{Witek2014,
author = {Witek, Maria A G and Clarke, Eric F and Wallentin, Mikkel and Kringelbach, Morten L and Vuust, Peter},
editor = {Canal-Bruland, Rouwen},
file = {:Users/gmac/mendeley/Witek et al/Witek et al. - 2014 - Syncopation, Body-Movement and Pleasure in Groove Music.pdf:pdf},
journal = {PLoS ONE},
month = {apr},
number = {4},
pages = {e94446},
publisher = {Public Library of Science},
title = {{Syncopation, Body-Movement and Pleasure in Groove Music}},
url = {http://dx.plos.org/10.1371/journal.pone.0094446 papers3://publication/doi/10.1371/journal.pone.0094446},
volume = {9},
year = {2014}
}
@article{Dimberg2000,
abstract = {Studies reveal that when people are exposed to emotional facial expressions, they spontaneously react with distinct facial electromyographic (EMG) reactions in emotion-relevant facial muscles. These reactions reflect, in part, a tendency to mimic the facial stimuli. We investigated whether corresponding facial reactions can be elicited when people are unconsciously exposed to happy and angry facial expressions. Through use of the backward-masking technique, the subjects were prevented from consciously perceiving 30-ms exposures of happy, neutral, and angry target faces, which immediately were followed and masked by neutral faces. Despite the fact that exposure to happy and angry faces was unconscious, the subjects reacted with distinct facial muscle reactions that corresponded to the happy and angry stimulus faces. Our results show that both positive and negative emotional reactions can be unconsciously evoked, and particularly that important aspects of emotional face-to-face communication can occur on an unconscious level.},
author = {Dimberg, U and Thunberg, M and Elmehed, K},
doi = {10.1111/1467-9280.00221},
file = {:Users/gmac/mendeley/Dimberg, Thunberg, Elmehed/Dimberg, Thunberg, Elmehed - 2000 - Unconscious facial reactions to emotional facial expressions.pdf:pdf},
isbn = {0956-7976},
issn = {0956-7976},
journal = {Psychological Science},
number = {1},
pages = {86--89},
pmid = {11228851},
title = {{Unconscious facial reactions to emotional facial expressions.}},
volume = {11},
year = {2000}
}
@article{Weaver1939,
author = {Weaver, H E},
file = {:Users/gmac/mendeley/Weaver/Weaver - 1939 - Syncopation A study of musical rhythms.pdf:pdf},
journal = {The Journal of General Psychology},
month = {jan},
pages = {409--429},
title = {{Syncopation: A study of musical rhythms}},
url = {http://search.proquest.com.myaccess.library.utoronto.ca/pao/docview/1291049329/fulltextPDF/1424305A6BCD98A08A/1?accountid=14771 papers3://publication/uuid/F3B31167-BC59-4EEE-ADDB-C3E00832EC2D},
volume = {20},
year = {1939}
}
@article{Yin2016,
abstract = {The mu rhythm is a field oscillation in the ∼10Hz range over the sensorimotor cortex. For decades, the suppression of mu (event-related desynchronization) has been used to index movement planning, execution, and imagery. Recent work reports that non-motor processes, such as spatial attention and movement observation, also desynchronize mu, raising the possibility that the mu rhythm is associated with the activity of multiple brain regions and systems. In this study, we tested this hypothesis by recording simultaneous resting-state EEG-fMRI from healthy subjects. Independent component analysis (ICA) was applied to extract the mu components. The amplitude (power) fluctuations of mu were estimated as a time series using a moving-window approach, which, after convolving with a canonical hemodynamic response function (HRF), was correlated with blood-oxygen-level-dependent (BOLD) signals from the entire brain. Two main results were found. First, mu power was negatively correlated with BOLD from areas of the sensorimotor network, the attention control network, the putative mirror neuron system, and the network thought to support theory of mind. Second, mu power was positively correlated with BOLD from areas of the salience network, including anterior cingulate cortex and anterior insula. These results are consistent with the hypothesis that sensorimotor mu rhythm is associated with multiple brain regions and systems. They also suggest that caution should be exercised when attempting to interpret mu modulation in terms of a single brain network.},
author = {Yin, Siyang and Liu, Yuelu and Ding, Mingzhou},
doi = {10.3389/fnhum.2016.00364},
file = {:Users/gmac/mendeley/Yin, Liu, Ding/Yin, Liu, Ding - 2016 - Amplitude of Sensorimotor Mu Rhythm Is Correlated with BOLD from Multiple Brain Regions A Simultaneous EEG-fMRI.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
keywords = {SOBI,attention control,mirror neurons,motor control,mu rhythm,resting-state,salience network,simultaneous EEG-fMRI},
number = {July},
pages = {1--12},
pmid = {27499736},
title = {{Amplitude of Sensorimotor Mu Rhythm Is Correlated with BOLD from Multiple Brain Regions: A Simultaneous EEG-fMRI Study}},
url = {http://journal.frontiersin.org/Article/10.3389/fnhum.2016.00364/abstract},
volume = {10},
year = {2016}
}
@article{Juslin2012,
abstract = {Page 1. Emotion Review Vol. 4, No. 3 (July 2012) 283 –284 {\textcopyright} The Author(s) 2012 ISSN 1754-0739 DOI: 10.1177 / 1754073912439773 er.sagepub.com Abstract Cross-cultural studies of music and emotion are needed to assess ... 
},
author = {Juslin, Patrik N},
file = {:Users/gmac/mendeley/Juslin/Juslin - 2012 - Are musical emotions invariant across cultures.pdf:pdf},
journal = {Emotion Review},
month = {jan},
title = {{Are musical emotions invariant across cultures?}},
url = {http://emr.sagepub.com/content/4/3/283.short papers3://publication/doi/10.1177/1754073912439773},
year = {2012}
}
@article{Zanto2006,
annote = {what does he mean by an “induced GBA tempo dependance”},
author = {Zanto, Theodore P and Snyder, Joel S and Large, Edward W},
file = {:Users/gmac/mendeley/Zanto, Snyder, Large/Zanto, Snyder, Large - 2006 - Neural correlates of rhythmic expectancy.pdf:pdf},
journal = {Advances in Cognitive Psychology},
keywords = {rhythm},
month = {jan},
number = {2-3},
pages = {221--231},
title = {{Neural correlates of rhythmic expectancy}},
url = {http://scholar.google.ca/scholar?cluster=15873564748058520086&hl=en&as_sdt=0,5},
volume = {2},
year = {2006}
}
@article{Merchant2017,
abstract = {The neural underpinnings of rhythmic behavior, including music and dance, have been studied using the synchronization-continuation task (SCT), where subjects initially tap in synchrony with an isochronous metronome and then keep tapping at a similar rate via an internal beat mechanism. Here, we provide behavioral and neural evidence that supports a resetting drift-diffusion model (DDM) during SCT. Behaviorally, we show the model replicates the linear relation between the mean and standard-deviation of the intervals produced by monkeys in SCT. We then show that neural populations in the medial premotor cortex (MPC) contain an accurate trial-by-trial representation of elapsed-time between taps. Interestingly, the autocorrelation structure of the elapsed-time representation is consistent with aDDM.Theseresults indicate that MPC has an orderly representation of time with features characteristic of concatenated DDMs and that this population signal can be used to orchestrate the rhythmic structure of the internally timed elements of SCT.},
author = {Merchant, Hugo and Averbeck, Bruno B.},
doi = {10.1523/JNEUROSCI.0367-17.2017},
file = {:Users/gmac/mendeley/Merchant, Averbeck/Merchant, Averbeck - 2017 - The computational and neural basis of rhythmic timing in medial premotor cortex(2).pdf:pdf;:Users/gmac/mendeley/Merchant, Averbeck/Merchant, Averbeck - 2017 - The computational and neural basis of rhythmic timing in medial premotor cortex.pdf:pdf},
isbn = {4422381040},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
keywords = {and,behavioral data,computational modeling,drift-diffusion model,ensemble recordings,ensemble recordings from medial,favor of a class,in macaque monkeys,monkey,mpc,of drift-diffusion models of,premotor cortex,rhythmic timing during a,significance statement,supplementary motor cortex,the present study used,timing,to establish evidence in},
number = {17},
pages = {0367--17},
pmid = {28336572},
title = {{The computational and neural basis of rhythmic timing in medial premotor cortex}},
url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.0367-17.2017},
volume = {37},
year = {2017}
}
@article{Kidd2007,
author = {Kidd, Gary R and Watson, Charles S and Gygi, Brian},
file = {:Users/gmac/mendeley/Kidd, Watson, Gygi/Kidd, Watson, Gygi - 2007 - Individual differences in auditory abilities.pdf:pdf},
journal = {Journal of Economic Psychology},
month = {jul},
number = {1},
pages = {418--435},
title = {{Individual differences in auditory abilities}},
url = {http://scitation.aip.org/content/asa/journal/jasa/122/1/10.1121/1.2743154 papers3://publication/doi/10.1121/1.2743154},
volume = {122},
year = {2007}
}
@article{Iacoboni2005,
author = {Iacoboni, Marco and Molnar-Szakacs, Istvan and Gallese, Vittorio and Buccino, Giovanni and Mazziotta, John C and Rizzolatti, Giacomo},
file = {:Users/gmac/mendeley/Iacoboni et al/Iacoboni et al. - 2005 - Grasping the Intentions of Others with One's Own Mirror Neuron System.pdf:pdf},
journal = {PLoS Biology},
month = {mar},
number = {3},
pages = {e79},
title = {{Grasping the Intentions of Others with One's Own Mirror Neuron System}},
url = {papers3://publication/doi/10.1371/journal.pbio.0030079},
volume = {3},
year = {2005}
}
@article{Chan2013,
abstract = {WE EXAMINED FACIAL RESPONSES TO AUDIO-VISUAL presentations of emotional singing. Although many studies have now found evidence for facial responses to emotional stimuli, most have involved static facial expressions and none have involved singing. Singing represents a dynamic ecologically valid emotional stim- ulus with unique demands on orofacial motion that are independent of emotion, related to pitch and linguistic production. Observers' facial muscles were recorded with electromyography while they saw and heard recordings of a vocalist's performance sung with differ- ent emotional intentions (happy, neutral, and sad). Audio-visual presentations successfully elicited facial mimicry in observers that were congruent with the per- former's intended emotions. Happy singing perfor- mances elicited increased activity in the zygomaticus major muscle region of observers, while sad perfor- mances evoked increased activity in the corrugator supercilii muscle region. These spontaneous facial mus- cle responses occurred within the first three seconds following onset of video presentation indicating that emotional nuances of singing performances can elicit dynamic facial responses from observers.},
author = {Chan, Lisa P and Livingstone, Steven R and Russo, Frank A},
doi = {10.1525/mp.2013.30.4.361},
file = {:Users/gmac/mendeley/Chan, Livingstone, Russo/Chan, Livingstone, Russo - 2013 - Facial Mimicry in Response to Song.pdf:pdf},
isbn = {07307829},
issn = {07307829},
journal = {Music Perception},
keywords = {emg,emotion,facial,facial mimicry,song},
number = {4},
pages = {361--367},
title = {{Facial Mimicry in Response to Song}},
volume = {30},
year = {2013}
}
@article{Green2009,
author = {Green, Christopher D},
file = {:Users/gmac/mendeley/Green/Green - 2009 - Darwinian Theory, Functionalism, and the First American Psychological Revolution.pdf:pdf},
journal = {American Psychologist},
month = {mar},
number = {2},
pages = {75--83},
publisher = {American Psychological Association},
title = {{Darwinian Theory, Functionalism, and the First American Psychological Revolution}},
url = {http://dx.doi.org/10.1037/a0013338 papers3://publication/doi/10.1037/a0013338},
volume = {64},
year = {2009}
}
@article{Nespoli2013,
author = {Nespoli, Gabe and Behar, Alberto and Russo, Frank A},
file = {:Users/gmac/mendeley/Nespoli, Behar, Russo/Nespoli, Behar, Russo - 2013 - Validation of the CSA Z107.56 Standard Method for the Measurement of Noise Exposure from Headsets.pdf:pdf},
journal = {Canadian Acoustics},
month = {sep},
pages = {31--36},
title = {{Validation of the CSA Z107.56 Standard Method for the Measurement of Noise Exposure from Headsets}},
url = {papers3://publication/uuid/A84B9932-6FE9-4FD2-8AB9-BC28A4E21622},
volume = {41},
year = {2013}
}
@article{Boulenger2008,
author = {Boulenger, V{\'{e}}ronique and Mechtouff, Laura and Thobois, St{\'{e}}phane and Broussolle, Emmanuel and Jeannerod, Marc and Nazir, Tatjana A},
file = {:Users/gmac/mendeley/Boulenger et al/Boulenger et al. - 2008 - Word processing in Parkinson's disease is impaired for action verbs but not for concrete nouns.pdf:pdf},
journal = {Neuropsychologia},
month = {jan},
pages = {743--756},
publisher = {Elsevier Ltd},
title = {{Word processing in Parkinson's disease is impaired for action verbs but not for concrete nouns}},
url = {papers3://publication/doi/10.1016/j.neuropsychologia.2007.10.007},
volume = {46},
year = {2008}
}
@article{Kung2013,
abstract = {Humans are able to find and tap to the beat of musical rhythms varying in complexity from children's songs to modern jazz. Musical beat has no one-to-one relationship with auditory features-it is an abstract perceptual representation that emerges from the interaction between sensory cues and higher-level cognitive organization. Previous investigations have examined the neural basis of beat processing but have not tested the core phenomenon of finding and tapping to the musical beat. To test this, we used fMRI and had musicians find and tap to the beat of rhythms that varied from metrically simple to metrically complex-thus from a strong to a weak beat. Unlike most previous studies, we measured beat tapping performance during scanning and controlled for possible effects of scanner noise on beat perception. Results showed that beat finding and tapping recruited largely overlapping brain regions, including the superior temporal gyrus (STG), premotor cortex, and ventrolateral PFC (VLPFC). Beat tapping activity in STG and VLPFC was correlated with both perception and performance, suggesting that they are important for retrieving, selecting, and maintaining the musical beat. In contrast BG activity was similar in all conditions and was not correlated with either perception or production, suggesting that it may be involved in detecting auditory temporal regularity or in associating auditory stimuli with a motor response. Importantly, functional connectivity analyses showed that these systems interact, indicating that more basic sensorimotor mechanisms instantiated in the BG work in tandem with higher-order cognitive mechanisms in PFC.},
author = {Kung, Shu-Jen and Chen, Joyce L and Zatorre, Robert J and Penhune, Virginia B},
doi = {10.1162/jocn_a_00325},
file = {:Users/gmac/mendeley/Kung et al/Kung et al. - 2013 - Interacting cortical and basal ganglia networks underlying finding and tapping to the musical beat.pdf:pdf},
isbn = {1530-8898 (Electronic)\r0898-929X (Linking)},
issn = {1530-8898},
journal = {Journal of cognitive neuroscience},
number = {3},
pmid = {23163420},
title = {{Interacting cortical and basal ganglia networks underlying finding and tapping to the musical beat.}},
volume = {25},
year = {2013}
}
@article{Vieillard2008,
author = {Vieillard, Sandrine and Peretz, Isabelle and Gosselin, Nathalie and Khalfa, St{\'{e}}phanie and Gagnon, Lise and Bouchard, Bernard},
doi = {10.1080/02699930701503567},
file = {:Users/gmac/mendeley/Vieillard et al/Vieillard et al. - 2008 - Happy, sad, scary and peaceful musical excerpts for research on emotions.pdf:pdf},
issn = {0269-9931},
journal = {Cognition & Emotion},
number = {4},
pages = {720--752},
title = {{Happy, sad, scary and peaceful musical excerpts for research on emotions}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02699930701503567},
volume = {22},
year = {2008}
}
@article{Hougaard2011,
author = {Hougaard, S{\o}ren and Ruf, Stefan},
file = {:Users/gmac/mendeley/Hougaard, Ruf/Hougaard, Ruf - 2011 - EuroTrak I A Consumer Survey About Hearing Aids in Germany, France, and the UK.pdf:pdf},
journal = {Hearing Review},
number = {2},
pages = {12--28},
title = {{EuroTrak I: A Consumer Survey About Hearing Aids in Germany, France, and the UK}},
volume = {18},
year = {2011}
}
@article{Jancke2000,
author = {J{\"{a}}ncke, L and Loose, R and Lutz, K and Specht, K and NJ, Shah},
file = {:Users/gmac/mendeley/J{\"{a}}ncke et al/J{\"{a}}ncke et al. - 2000 - Cortical activations during paced finger-tapping applying visual and auditory pacing stimuli.pdf:pdf},
journal = {Cognitive Brain Research},
keywords = {tapping},
month = {jan},
pages = {51--66},
title = {{Cortical activations during paced finger-tapping applying visual and auditory pacing stimuli}},
url = {papers3://publication/uuid/A8F789B2-121A-406C-881D-3586F5EAF07C},
volume = {10},
year = {2000}
}
@article{Khalfa2002,
abstract = {While the reasons underlying musical emotions are unclear, music is nevertheless a powerful elicitor of emotion, and as such, may induce autonomic nervous system responses. One typical measure of this neural pathway is the skin conductance response (SCR). This response generally depends upon stimulus arousal, one of the two motivational determinants of emotion. The objective of the present study was to verify whether emotional reactions to music elicit such event-related autonomic responses. To this aim, four musical emotions varying in arousal were employed: fear, happiness, sadness and peacefulness. SCRs were found to be greater with the two more stimulating emotions, fear and happiness, as compared to the two more relaxing emotions, sadness and peacefulness (P<0.05). In addition, subjects' ratings of the emotional clarity for each excerpt did not parallel the corresponding SCRs magnitudes. The results show that SCRs can be evoked and modulated by musical emotional arousal, but are not sensitive to emotional clarity. While several studies have been performed with visual scenes and environmental sounds, the present study brings similar evidence from the musical domain.},
author = {Khalfa, St{\'{e}}phanie and Isabelle, Peretz and Jean-Pierre, Blondin and Manon, Robert},
doi = {10.1016/S0304-3940(02)00462-7},
file = {:Users/gmac/mendeley/Khalfa et al/Khalfa et al. - 2002 - Event-related skin conductance responses to musical emotions in humans.pdf:pdf},
isbn = {1151434361},
issn = {03043940},
journal = {Neuroscience Letters},
keywords = {Arousal,Electrodermal activity,Emotion,Music,Sympathetic nervous system},
number = {2},
pages = {145--149},
pmid = {12133576},
title = {{Event-related skin conductance responses to musical emotions in humans}},
volume = {328},
year = {2002}
}
@article{Grahn2007,
abstract = {When we listen to rhythm, we often move spontaneously to the beat. This movement may result from processing of the beat by motor areas. Previous studies have shown that several motor areas respond when attending to rhythms. Here we investigate whether specific motor regions respond to beat in rhythm. We predicted that the basal ganglia and supplementary motor area (SMA) would respond in the presence of a regular beat. To establish what rhythm properties induce a beat, we asked subjects to reproduce different types of rhythmic sequences. Improved reproduction was observed for one rhythm type, which had integer ratio relationships between its intervals and regular perceptual accents. A subsequent functional magnetic resonance imaging study found that these rhythms also elicited higher activity in the basal ganglia and SMA. This finding was consistent across different levels of musical training, although musicians showed activation increases unrelated to rhythm type in the premotor cortex, cerebellum, and SMAs (pre-SMA and SMA). We conclude that, in addition to their role in movement production, the basal ganglia and SMAs may mediate beat perception.},
address = {MRC Cognition and Brain Sciences Unit, Cambridge, UK. Jessica.grahn@mrc-cbu.cam.ac.uk},
annote = {There is limited evidence that neural synchronization strength to auditory events at short timescales in the IC is linked to synchronization strength at longer timescales in the auditory cortex. Tierney and Kraus {*Tierney:2013ia} compared variability in tapping along with a metronome to IC synchronization strength to the speech sound /da/. They found that the variability in inter-tap-intervals was related to two measures of ABR variability: response consistency and inter-trial phase locking. To measure response consistency for each participant, half of the trials were randomly selected and averaged, and cross-correlated with the other half of responses. This was done 100 times, and the average of cross-correlations gave the final measure of response consistency. Inter-trial phase locking was calculated by averaging FFTs of all trials

tapping variability correlates with subcortical f0 synchrony. links between IC and cerebellum might mean that synchrony is improved in both with musicianship},
author = {Grahn, Jessica A and Brett, Matthew},
file = {:Users/gmac/mendeley/Grahn, Brett/Grahn, Brett - 2007 - Rhythm and beat perception in motor areas of the brain.pdf:pdf},
journal = {Journal of Cognitive Neuroscience},
month = {may},
number = {5},
pages = {893--906},
title = {{Rhythm and beat perception in motor areas of the brain}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/jocn.2007.19.5.893 papers3://publication/doi/10.1162/jocn.2007.19.5.893},
volume = {19},
year = {2007}
}
@article{Jenson2015,
author = {Jenson, David and Harkrider, Ashley W. and Thornton, David and Bowers, Andrew L. and Saltuklaroglu, Tim},
doi = {10.3389/fnhum.2015.00534},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
keywords = {auditory alpha,dorsal stream,eeg,frontiers in human neuroscience,frontiersin,org,sensorimotor integration,sensorimotor integration, auditory alpha, EEG, dor,speech-induced suppression,www},
number = {October},
pages = {1--17},
title = {{Auditory cortical deactivation during speech production and following speech perception: an EEG investigation of the temporal dynamics of the auditory alpha rhythm}},
url = {http://journal.frontiersin.org/article/10.3389/fnhum.2015.00534},
volume = {9},
year = {2015}
}
@article{Rosenbaum2007,
author = {Rosenbaum, R S and Stuss, D T and Levine, B and Tulving, E},
file = {:Users/gmac/mendeley/Rosenbaum et al/Rosenbaum et al. - 2007 - Theory of Mind Is Independent of Episodic Memory.pdf:pdf},
journal = {Science},
month = {nov},
number = {5854},
pages = {1257},
title = {{Theory of Mind Is Independent of Episodic Memory}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1148763 papers3://publication/doi/10.1126/science.1148763},
volume = {318},
year = {2007}
}
@article{Russell2003,
author = {Russell, James A},
file = {:Users/gmac/mendeley/Russell/Russell - 2003 - Core affect and the psychological construction of emotion.pdf:pdf},
journal = {Psychological Review},
month = {jan},
number = {1},
pages = {145--172},
title = {{Core affect and the psychological construction of emotion.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.110.1.145 papers3://publication/doi/10.1037/0033-295X.110.1.145},
volume = {110},
year = {2003}
}
@article{Fox2016,
abstract = {A fundamental issue in cognitive neuroscience is how the brain encodes others' actions and intentions. In recent years, a potential advance in our knowledge on this issue is the discovery of mirror neurons in the motor cortex of the nonhuman primate. These neurons fire to both execution and observation of specific types of actions. Researchers use this evidence to fuel investigations of a human mirror system, suggesting a common neural code for perceptual and motor processes. Among the methods used for inferring mirror system activity in humans are changes in a particular frequency band in the electroen-cephalogram (EEG) called the mu rhythm. Mu frequency appears to decrease in amplitude (reflecting cortical activity) during both action execution and action observation. The current meta-analysis re-viewed 85 studies (1,707 participants) of mu that infer human mirror system activity. Results demon-strated significant effect sizes for mu during execution (Cohen's d ϭ 0.46, N ϭ 701) as well as observation of action (Cohen's d ϭ 0.31, N ϭ 1,508), confirming a mirroring property in the EEG. A number of moderators were examined to determine the specificity of these effects. We frame these meta-analytic findings within the current discussion about the development and functions of a human mirror system, and conclude that changes in EEG mu activity provide a valid means for the study of human neural mirroring. Suggestions for improving the experimental and methodological approaches in using mu to study the human mirror system are offered.},
author = {Fox, Nathan A and Bakermans-Kranenburg, Marian J and Yoo, Kathryn H and Bowman, Lindsay C and Cannon, Erin N and Vanderwert, Ross E and Ferrari, Pier F and {Van Ijzendoorn}, Marinus H},
doi = {10.1037/bul0000031},
file = {:Users/gmac/mendeley/Fox et al/Fox et al. - 2016 - Assessing Human Mirror Activity With EEG Mu Rhythm A Meta-Analysis.pdf:pdf},
issn = {1939-1455(Electronic);0033-2909(Print)},
journal = {Psychological Bulletin},
keywords = {EEG,action execution,action observation,mirror neurons,mu rhythm},
number = {3},
pages = {291--313},
pmid = {26689088},
title = {{Assessing Human Mirror Activity With EEG Mu Rhythm: A Meta-Analysis}},
url = {http://dx.doi.org/10.1037/bul0000031.supp},
volume = {142},
year = {2016}
}
@article{Barrett2004,
abstract = {People differ in the extent to which they emphasize feelings of activation or deactivation in their verbal reports of experienced emotion, termed arousal focus (AF). Two multimethod studies indicate that AF is linked to heightened interoceptive sensitivity (as measured by performance on a heartbeat detection task). People who were more sensitive to their heartbeats emphasized feelings of activation and deactivation when reporting their experiences of emotion over time more than did those who were less sensitive. This relationship was not accounted for by several other variables, including simple language effects. Implications for the role of interoception in experienced emotion and the validity of self-reported emotion are discussed.},
author = {Barrett, Lisa Feldman and Quigley, Karen S and Bliss-Moreau, Eliza and Aronson, Keith R},
doi = {10.1037/0022-3514.87.5.684},
file = {:Users/gmac/mendeley/Barrett et al/Barrett et al. - 2004 - Interoceptive Sensitivity and Self-Reports of Emotional Experience.pdf:pdf},
isbn = {2158987413},
issn = {1939-1315},
journal = {Journal of Personality and Social Psychology},
number = {5},
pages = {684--697},
title = {{Interoceptive Sensitivity and Self-Reports of Emotional Experience.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0022-3514.87.5.684},
volume = {87},
year = {2004}
}
@article{Loui2015a,
abstract = {Singing requires effortless and efficient use of auditory and motor systems that center around the perception and production of the human voice. Although perception and production are usually tightly coupled functions, occasional mismatches between the two systems inform us of dissociable pathways in the brain systems that enable singing. Here I review the literature on perception and production in the auditory modality, and propose a dual-stream neuroanatomical model that subserves singing. I will discuss studies surrounding the neural functions of feedforward, feedback, and efference systems that control vocal monitoring, as well as the white matter pathways that connect frontal and temporal regions that are involved in perception and production. I will also consider disruptions of the perception-production network that are evident in tone-deaf individuals and poor pitch singers. Finally, by comparing expert singers against other musicians and nonmusicians, I will evaluate the possibility that singing training might offer rehabilitation from these disruptions through neuroplasticity of the perception-production network. Taken together, the best available evidence supports a model of dorsal and ventral pathways in auditory-motor integration that enables singing and is shared with language, music, speech, and human interactions in the auditory environment.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Loui, Psyche},
doi = {10.1525/mp.2015.32.3.232},
eprint = {15334406},
file = {:Users/gmac/mendeley/Loui/Loui - 2015 - A Dual-Stream Neuroanatomy of Singing.pdf:pdf},
isbn = {0520057295},
issn = {07307829},
journal = {Music Perception: An Interdisciplinary Journal},
keywords = {arcuate,neuroanatomy,pitch,singing,voice},
number = {3},
pages = {232--241},
pmid = {26120242},
title = {{A Dual-Stream Neuroanatomy of Singing}},
url = {http://mp.ucpress.edu/cgi/doi/10.1525/mp.2015.32.3.232},
volume = {32},
year = {2015}
}
@article{Tillmann2010,
author = {Tillmann, Barbara and Bigand, Emmanuel},
file = {:Users/gmac/mendeley/Tillmann, Bigand/Tillmann, Bigand - 2010 - Musical structure processing after repeated listening Schematic expectationsresist veridical expectations.pdf:pdf},
journal = {Musicae Scientiae},
month = {jan},
number = {Special Issue},
pages = {33--47},
publisher = {European Society for the Cognitive Sciences of Music},
title = {{Musical structure processing after repeated listening: Schematic expectationsresist veridical expectations}},
url = {papers3://publication/uuid/A2C2C50E-7C02-4716-B9D5-4CBD277CBC78},
year = {2010}
}
@article{Asakawa2014,
author = {Asakawa, Tetsuya and Muramatsu, Ayumi and Hayashi, Takuto and Urata, Tatsuya and Taya, Masato and Mizuno-Matsumoto, Yuko},
doi = {10.3389/fnhum.2014.01006},
file = {:Users/gmac/mendeley/Asakawa et al/Asakawa et al. - 2014 - Comparison of EEG propagation speeds under emotional stimuli on smartphone between the different anxiety states.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
keywords = {EEG, smartphone, emotional stimuli, anxiety states,anxiety states,eeg,emotional stimuli,propagation speed,smartphone},
number = {December},
pages = {1--8},
title = {{Comparison of EEG propagation speeds under emotional stimuli on smartphone between the different anxiety states}},
url = {http://journal.frontiersin.org/article/10.3389/fnhum.2014.01006/abstract},
volume = {8},
year = {2014}
}
@article{Song2015,
abstract = {Background: The accuracy of EEG source localization depends on a sufficient sampling of the surface potential field, an accurate conducting volume estimation (head model), and a suitable and well-understood inverse technique. The goal of the present study is to examine the effect of sampling density and coverage on the ability to accurately localize sources, using common linear inverse weight techniques, at different depths. Several inverse methods are examined, using the popular head conductivity. New method: Simulation studies were employed to examine the effect of spatial sampling of the potential field at the head surface, in terms of sensor density and coverage of the inferior and superior head regions. In addition, the effects of sensor density and coverage are investigated in the source localization of epileptiform EEG. Results: Greater sensor density improves source localization accuracy. Moreover, across all sampling density and inverse methods, adding samples on the inferior surface improves the accuracy of source estimates at all depths. Comparison with existing methods: More accurate source localization of EEG data can be achieved with high spatial sampling of the head surface electrodes. Conclusions: The most accurate source localization is obtained when the voltage surface is densely sampled over both the superior and inferior surfaces.},
author = {Song, Jasmine and Davey, Colin and Poulsen, Catherine and Luu, Phan and Turovets, Sergei and Anderson, Erik and Li, Kai and Tucker, Don},
doi = {10.1016/j.jneumeth.2015.08.015},
file = {:Users/gmac/mendeley/Song et al/Song et al. - 2015 - EEG source localization Sensor density and head surface coverage.pdf:pdf},
issn = {1872678X},
journal = {Journal of Neuroscience Methods},
keywords = {Dense array EEG,Epilepsy,FDM,Minimum norm,SLORETA,Source localization},
pages = {9--21},
pmid = {26300183},
publisher = {Elsevier B.V.},
title = {{EEG source localization: Sensor density and head surface coverage}},
url = {http://dx.doi.org/10.1016/j.jneumeth.2015.08.015},
volume = {256},
year = {2015}
}
@article{Antonietti2009,
author = {Antonietti, Alessandro and Cocomazzi, Daniela and Iannello, Paola},
file = {:Users/gmac/mendeley/Antonietti, Cocomazzi, Iannello/Antonietti, Cocomazzi, Iannello - 2009 - Looking at the Audience Improves Music Appreciation.pdf:pdf},
journal = {Journal of Nonverbal Behavior},
keywords = {audience,performance},
month = {jan},
number = {2},
pages = {89--106},
title = {{Looking at the Audience Improves Music Appreciation}},
url = {http://www.springerlink.com/index/10.1007/s10919-008-0062-x papers3://publication/doi/10.1007/s10919-008-0062-x},
volume = {33},
year = {2009}
}
@article{Stansfeld2003a,
author = {Stansfeld, S. A and Matheson, Mark P},
doi = {10.1093/bmb/ldg033},
file = {:Users/gmac/mendeley/Stansfeld, Matheson/Stansfeld, Matheson - 2003 - Noise pollution non-auditory effects on health.pdf:pdf},
issn = {1471-8391},
journal = {British Medical Bulletin},
keywords = {noise,noise exposure},
month = {dec},
number = {1},
pages = {243--257},
publisher = {Oxford University Press},
title = {{Noise pollution: non-auditory effects on health}},
url = {https://academic.oup.com/bmb/article-lookup/doi/10.1093/bmb/ldg033},
volume = {68},
year = {2003}
}
@article{Lin2014,
author = {Lin, Eric S and Chiu, Shih-yung},
doi = {10.1007/s11162-015-9388-5},
file = {:Users/gmac/mendeley/Lin, Chiu/Lin, Chiu - 2014 - Does Holding a Postdoctoral Position Bring Benefits for Advancing to Academia.pdf:pdf},
isbn = {1116201593},
journal = {Research in Higher Education},
keywords = {PhD,academia,job choice,postdoctoral position},
title = {{Does Holding a Postdoctoral Position Bring Benefits for Advancing to Academia?}},
year = {2014}
}
@article{Snyder2005,
annote = {- The firing patterns of neurons have been found to synchronize with periodic stimuli in a predictive way. Various neural measures have revealed entrainment of neurons to isochronous sequences. Using EEG, the modulation of gamma-band (20-60 Hz) activity as calculated over fronto-central electrodes has been found to synchronize with an isochronous sequence of loud and soft tones [@Snyder2005]. Interestingly, induced gamma-band peaks persisted during tone omissions, whereas evoked peaks arrived late, suggesting that the induced gamma-band oscillations are predictive.------
    	- In music and speech, event onsets are perceived as being periodic with inter-onset intervals (IOIs) in the 100–1000 ms range. This time scale corresponds to the range over which humans are most sensitive to changes in tempo for periodic and nearly periodic sequences [6] and the rates for which anticipation is observed in sensorimotor synchronization tasks [7] (p.117)- Long-latency ... responses diminish in amplitude at fast tempos and because responses from adjacent tone onsets begin to overlap at rhythmic rates with IOIs shorter than 1000 ms (p.118)- short-latency evoked (phase-locked) gamma-band (20–60 Hz) activity (GBA) quickly follows stimulus events at a range of tempos (p.118)- Such anticipatory activity is predicted by theories of meter perception that posit internal attentional processes that synchronize with external rhythmic patterns forming the basis of metric percepts (p.118)Analysis:- We first bandpass filtered each block of data with a 25-point finite impulse response filter (15–100 Hz passband) (p.118)- complex Morlet wavelet family. The wavelet family was defined such that wavelet bandwidth {\ldots} 20 to 60 Hz in 1 Hz steps (p.118)- Grand averaged TF representations were means across all eight subjects and the 15 fronto-central channels (Fz, F1/2/3/4, FCz, FC1/2/3/4, Cz, C1/2/3/4) (p.119)- converted TF representations from power, P, in AV2 to normalized power, Pnorm, using the conversion: Pnorm = ( P/ Pmin) / rP, where Pmin is the minimum power and rP is the range of power values for the TF representations of the corresponding recording blocks- We considered the peak to be the highest local peak in TF space within F195 ms of expected tone onset (p.119)- Evoked GBA requires first finding the mean event-related potential (ERP) across all trials and then taking the CWT of the ERP. In the current study, this was accomplished by averaging TF representations with both the amplitude and phase information present (p.120)- Anticipatory cortical activity {\ldots} may play a role in processing rapidly evolving temporal patterns such as music and speech, in which it is important to develop forward-looking representations for when events are likely to occur (p.124)- The induced activity varied more between subjects than evoked activity in the timing relative to tone onsets and the extent to which it exceeded the background activity. Such variability might be explained by individual differences in attention during the task, musical experience, and listening strategies, especially in the more rhythmically complex stimulus conditions (p.124)- In humans, when one click followed another by more than 12.5 ms (the approximate threshold for perceiving two distinct events), the second click reset the phase of evoked GBA suggesting a role in limiting temporal resolution (p.126)- For example, recent findings showed larger late responses to tone omissions in drummers and bass guitarists compared to non-musically-trained individuals (p.126)- Our results demonstrate that induced GBA precedes evoked GBA, implicating a functional relationship between the two: induced GBA increases might predict events, and the occurrence of the tone onset evokes a phase-locked gamma-band response. This would be consistent with previous reports that evoked responses represent the modulation of ongoing EEG activity rather than the transient activation of neuronal populations [19]. Thus, the anticipatory increases of induced GBA may result in a larger and/or more synchronized population of neurons contributing to EEG phase resetting. (p.126)},
author = {Snyder, Joel S and Large, Edward W},
file = {:Users/gmac/mendeley/Snyder, Large/Snyder, Large - 2005 - Gamma-band activity reflects the metric structure of rhythmic tone sequences.pdf:pdf},
journal = {Cognitive Brain Research},
keywords = {gamma,rhythm},
month = {jun},
pages = {117--126},
title = {{Gamma-band activity reflects the metric structure of rhythmic tone sequences}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0926641005000054 papers3://publication/doi/10.1016/j.cogbrainres.2004.12.014},
volume = {24},
year = {2005}
}
@article{Murata2005,
author = {Murata, Atsuo and Uetake, Atsushi and Takasawa, Yosuke},
file = {:Users/gmac/mendeley/Murata, Uetake, Takasawa/Murata, Uetake, Takasawa - 2005 - Evaluation of mental fatigue using feature parameter extracted from event-related potential.pdf:pdf},
journal = {International Journal of Industrial Ergonomics},
month = {aug},
number = {8},
pages = {761--770},
title = {{Evaluation of mental fatigue using feature parameter extracted from event-related potential}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169814105000478 papers3://publication/doi/10.1016/j.ergon.2004.12.003},
volume = {35},
year = {2005}
}
@article{Cant2003,
abstract = {The cochlear nuclear complex gives rise to widespread projections to nuclei throughout the brainstem. The projections arise from separate, well-defined populations of cells. None of the cell populations in the cochlear nucleus projects to all brainstem targets, and none of the targets receives inputs from all cell types. The projections of nine distinguishable cell types in the cochlear nucleus-seven in the ventral cochlear nucleus and two in the dorsal cochlear nucleus-are described in this review. Globular bushy cells and two types of spherical bushy cells project to nuclei in the superior olivary complex that play roles in sound localization based on binaural cues. Octopus cells convey precisely timed information to nuclei in the superior olivary complex and lateral lemniscus that, in turn, send inhibitory input to the inferior colliculus. Cochlear root neurons send widespread projections to areas of the reticular formation involved in startle reflexes and autonomic functions. Type I multipolar cells may encode complex features of natural stimuli and send excitatory projections directly to the inferior colliculus. Type II multipolar cells send inhibitory projections to the contralateral cochlear nuclei. Fusiform cells in the dorsal cochlear nucleus appear to be important for the localization of sounds based on spectral cues and send direct excitatory projections to the inferior colliculus. Giant cells in the dorsal cochlear nucleus also project directly to the inferior colliculus; some of them may convey inhibitory inputs to the contralateral cochlear nucleus as well.},
author = {Cant, Nell B and Benson, Christina G},
doi = {10.1016/S0361-9230(03)00050-9},
file = {:Users/gmac/mendeley/Cant, Benson/Cant, Benson - 2003 - Parallel auditory pathways projection patterns of the different neuronal populations in the dorsal and ventral coc.pdf:pdf},
isbn = {0361-9230},
issn = {03619230},
journal = {Brain Research Bulletin},
keywords = {brainstem auditory system,inferior colliculus,lateral lemniscus,neuroanatomy,superior olivary complex},
number = {5-6},
pages = {457--474},
pmid = {12787867},
title = {{Parallel auditory pathways: projection patterns of the different neuronal populations in the dorsal and ventral cochlear nuclei.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=12787867&retmode=ref&cmd=prlinks%5Cnpapers3://publication/uuid/7244B567-2736-4A24-B928-CB68947FCBA2},
volume = {60},
year = {2003}
}
@article{Hinton2011,
abstract = {What is machine learning? Machine learning is a type of statistics that places parti-cular emphasis on the use of advanced computational algorithms. As computers become more powerful, and modern experimental methods in areas such as imaging generate vast bodies of data, machine learning is becom-ing ever more important for extracting reliable and meaningful relationships and for making accurate pre-dictions. Key strands of modern machine learning grew out of attempts to understand how large numbers of interconnected, more or less neuron-like elements could learn to achieve behaviourally meaningful computations and to extract useful features from images or sound waves. By the 1990s, key approaches had converged on an elegant framework called 'graphical models', explained in Koller and Friedman, in which the nodes of a graph represent variables such as edges and corners in an image, or phonemes and words in speech. The probabil-istic relationships between nodes are represented by conditional probability tables or simple functions whose parameters are learned from the data. There are three main problems in fitting graphical models to data: inference, parameter learning and struc-ture learning. The inference problem is how to infer the probable values of unobserved variables when the values of a subset of the variables have been observed, and is a problem that perceptual systems need to solve if they are to infer the hidden causes of their sensory input. The parameter-learning problem is how to adjust the parameters governing the way in which one variable influences another, so that the graphical model is a bet-ter fit to some observed data. In the brain, this is pre-sumably done by changing synapse strengths. The structure-learning problem is how to decide which unobserved variables are needed and how they must be connected to model the correlations between observed variables. In the brain, evolution and early pruning of connections presumably have a large role to play in determining the structure. Could you provide a brief description of the methods of machine learning? Machine learning can be divided into three parts: 1) in supervised learning, the aim is to predict a class label or a real value from an input (classifying objects in images or predicting the future value of a stock are examples of this type of learning); 2) in unsupervised learning, the aim is to discover good features for representing the input data; and 3) in reinforcement learning, the aim is to discover what action should be performed next in order to maximize the eventual payoff.},
author = {Hinton, Geoffrey E},
doi = {10.1186/2042-1001-1-12},
file = {:Users/gmac/mendeley/Hinton/Hinton - 2011 - Machine learning for neuroscience.pdf:pdf},
isbn = {9780262013192},
issn = {2042-1001},
journal = {Neural Systems & Circuits},
number = {1},
pages = {12},
pmid = {22330889},
title = {{Machine learning for neuroscience}},
url = {http://www.neuralsystemsandcircuits.com/content/1/1/12},
volume = {1},
year = {2011}
}
@article{Kung2011,
author = {Kung, Shu-Jen and Tzeng, Ovid J L and Hung, Daisy L and Wu, Denise H},
file = {:Users/gmac/mendeley/Kung et al/Kung et al. - 2011 - Dynamic allocation of attention to metrical and grouping accents in rhythmic sequences.pdf:pdf},
journal = {Experimental Brain Research},
month = {mar},
number = {2},
pages = {269--282},
title = {{Dynamic allocation of attention to metrical and grouping accents in rhythmic sequences}},
url = {http://link.springer.com/10.1007/s00221-011-2630-2 papers3://publication/doi/10.1007/s00221-011-2630-2},
volume = {210},
year = {2011}
}
@article{Todd1985,
author = {Todd, Neil},
file = {:Users/gmac/mendeley/Todd/Todd - 1985 - A Model of Expressive Timing in Tonal Music.pdf:pdf},
journal = {Music Perception},
month = {oct},
number = {1},
pages = {33--58},
title = {{A Model of Expressive Timing in Tonal Music}},
url = {http://pao.chadwyck.com/PDF/1350489193276.pdf papers3://publication/uuid/4CFF8163-4BA7-4F80-9EB1-3B63178E94BC},
volume = {3},
year = {1985}
}
@article{Kawase2014,
author = {Kawase, Satoshi},
file = {:Users/gmac/mendeley/Kawase/Kawase - 2014 - Importance of Communication Cues in Music Performance according to Performers and Audience.pdf:pdf},
journal = {International Journal of Psychological Studies},
month = {may},
number = {2},
pages = {1--17},
title = {{Importance of Communication Cues in Music Performance according to Performers and Audience}},
url = {http://www.ccsenet.org/journal/index.php/ijps/article/view/35034 papers3://publication/doi/10.5539/ijps.v6n2p49},
volume = {6},
year = {2014}
}
@article{Parsons2011,
abstract = {Major League Baseball umpires express their racial/ethnic prefer ences when they evaluate pitchers. Strikes are called less often if the umpire and pitcher do not match race/ethnicity, but mainly where there is little scrutiny of umpires. Pitchers understand the incentives and throw pitches that allow umpires less subjective judgment (e.g., fastballs over home plate) when they anticipate bias. These direct and indirect effects bias performance measures of minorities down ward. The results suggest how discrimination alters discriminated groups' behavior generally. They imply that biases in measured pro ductivity must be accounted for in generating measures of wage dis crimination},
author = {Parsons, Christopher A. and Sulaeman, Johan and Yates, Michael C. and Hamermesh, Daniel S.},
doi = {10.1257/aer.101.4.1410},
file = {:Users/gmac/mendeley/Parsons et al/Parsons et al. - 2011 - Strike three Discrimination, incentives, and evaluation.pdf:pdf},
isbn = {00028282},
issn = {00028282},
journal = {American Economic Review},
number = {4},
pages = {1410--1435},
title = {{Strike three: Discrimination, incentives, and evaluation}},
volume = {101},
year = {2011}
}
@article{Buzsaki2004,
annote = {- oscillations seen during anesthesia and epilepsy, states associated with loss of consciousness (ref 2)
-- locking onto the beat associated with a loss in consciousness? Or at least removing the beat from consciousness?
- "although synchronous assemblies can be brought about by strong common inputs that occur irregularly, oscillation-based synchrony is the most energy-efficient physical mechanism for temporal coordination (refs 21, 22)"
-- speaks to why we extract the pulse},
author = {Buzsaki, Gyorgy and Draguhn, Andreas},
file = {:Users/gmac/mendeley/Buzsaki, Draguhn/Buzsaki, Draguhn - 2004 - Neuronal Oscillations in Cortical Networks.pdf:pdf},
journal = {Science},
month = {jun},
pages = {1926--1929},
title = {{Neuronal Oscillations in Cortical Networks}},
url = {http://www.jstor.org.ezproxy.lib.ryerson.ca/stable/3837193 papers3://publication/uuid/D7ED24B1-00D8-47D7-9D15-AAB27F6B41D5},
volume = {304},
year = {2004}
}
@article{Mayville2001,
author = {Mayville, Justine M and Fuchs, Armin and Ding, Mingzhou and Cheyne, Douglas and der Deecke, L and Kelso, J A Scott},
file = {:Users/gmac/mendeley/Mayville et al/Mayville et al. - 2001 - Event-related changes in neuromagnetic activity associated with syncopation and synchronization timing tasks.pdf:pdf},
journal = {Human Brain Mapping},
month = {jan},
number = {2},
pages = {65--80},
publisher = {John Wiley & Sons, Inc.},
title = {{Event-related changes in neuromagnetic activity associated with syncopation and synchronization timing tasks}},
url = {http://doi.wiley.com/10.1002/hbm.1042 papers3://publication/doi/10.1002/hbm.1042},
volume = {14},
year = {2001}
}
@article{Mclaughlin2010,
author = {Mclaughlin, P and Boals, A},
file = {:Users/gmac/mendeley/Mclaughlin, Boals/Mclaughlin, Boals - 2010 - Perceptual organization can affect performance on rhythmic tasks.pdf:pdf},
journal = {Psychology of Music},
month = {sep},
number = {4},
pages = {395--401},
title = {{Perceptual organization can affect performance on rhythmic tasks}},
url = {http://pom.sagepub.com/cgi/doi/10.1177/0305735609351916 papers3://publication/doi/10.1177/0305735609351916},
volume = {38},
year = {2010}
}
@article{Chandrasekaran2010,
author = {Chandrasekaran, Bharath and Kraus, Nina},
file = {:Users/gmac/mendeley/Chandrasekaran, Kraus/Chandrasekaran, Kraus - 2010 - The scalp-recorded brainstem response to speech Neural origins and plasticity.pdf:pdf},
journal = {Psychophysiology},
month = {mar},
number = {2},
pages = {236--246},
title = {{The scalp-recorded brainstem response to speech: Neural origins and plasticity}},
url = {http://doi.wiley.com/10.1111/j.1469-8986.2009.00928.x papers3://publication/doi/10.1111/j.1469-8986.2009.00928.x},
volume = {47},
year = {2010}
}
@article{Verrillo1992,
annote = {- "At lower frequencies, subjects report a sensation of periodicity, or "buzz" and the sensation is very localized at a specific place on the skin. The higher frequencies were described as more diffuse, more difficult to localize, and produced a "smooth" sensation." p.285},
author = {Verrillo, Ronald T},
file = {:Users/gmac/mendeley/Verrillo/Verrillo - 1992 - Vibration Sensation in Humans.pdf:pdf},
journal = {Music Perception},
keywords = {haptics},
month = {apr},
number = {3},
pages = {281--302},
title = {{Vibration Sensation in Humans}},
url = {papers3://publication/uuid/F316CF88-6BCE-4519-AED8-EAC41D275C3C},
volume = {9},
year = {1992}
}
@inproceedings{Iversen2008a,
address = {Sapporo, Japan},
author = {Iversen, John R and Patel, Aniruddh D},
booktitle = {Proceedings of the 10th International Conference on Music Perception and Cognition},
file = {:Users/gmac/mendeley/Iversen, Patel/Iversen, Patel - 2008 - The Beat Alignment Test (BAT) Surveying beat processing abilities in the general population.pdf:pdf},
month = {may},
pages = {465--468},
title = {{The Beat Alignment Test (BAT): Surveying beat processing abilities in the general population}},
url = {papers3://publication/uuid/41608688-A184-49E1-9CB5-A87823C997A9},
year = {2008}
}
@inproceedings{Stober2014a,
abstract = {Electroencephalography (EEG) recordings of rhythmperceptionmight contain enough information to distinguish different rhythmtypes/genres or even identify the rhythms themselves.We apply convolutional neural networks (CNNs) to analyze and classify EEGdata recordedwithin a rhythmperception study inKigali,Rwandawhich comprises 12 East African and 12Western rhythmic stimuli – each presented in a loop for 32 seconds to 13 participants. We investigate the impact of the data representation and the pre-processing steps for this classification tasks and compare different network structures. Using CNNs, we are able to recognize individual rhythms from the EEG with amean classification accuracy of 24.4%(chance level 4.17%) over all subjects by looking at less than three seconds froma single channel. Aggregating predictions for multiple channels, amean accuracy of up to 50%can be achieved for individual subjects. 1},
author = {Stober, Sebastian and Cameron, Daniel J and Grahn, Jessica A},
booktitle = {Advances in Neural Information Processing Systems 27},
file = {:Users/gmac/mendeley/Stober, Cameron, Grahn/Stober, Cameron, Grahn - 2014 - Using Convolutional Neural Networks to Recognize Rhythm Stimuli from Electroencephalography Recordings.pdf:pdf},
pages = {1449--1457},
title = {{Using Convolutional Neural Networks to Recognize Rhythm Stimuli from Electroencephalography Recordings}},
url = {http://papers.nips.cc/paper/5272-using-convolutional-neural-networks-to-recognize-rhythm-stimuli-from-electroencephalography-recordings.pdf},
year = {2014}
}
@article{Livingstone2016,
abstract = {Background: Humans spontaneously mimic the facial expressions of others, facilitating social interaction. This mimicking behavior may be impaired in individuals with Parkinson's disease, for whom the loss of facial movements is a clinical feature. Objective: To assess the presence of facial mimicry in patients with Parkinson's disease. Method: Twenty-seven non-depressed patients with idiopathic Parkinson's disease and 28 age-matched controls had their facial muscles recorded with electromyography while they observed presentations of calm, happy, sad, angry, and fearful emotions. Results: Patients exhibited reduced amplitude and delayed onset in the zygomaticus major muscle region (smiling response) following happy presentations (patients M = 0.02, 95% confidence interval [CI] −0.15 to 0.18, controls M = 0.26, CI 0.14 to 0.37, ANOVA, effect size [ES] = 0.18, p < 0.001). Although patients exhibited activation of the corrugator supercilii and medial frontalis (frowning response) following sad and fearful presentations, the frontalis response to sad presentations was attenuated relative to controls (patients M = 0.05, CI −0.08 to 0.18, controls M = 0.21, CI 0.09 to 0.34, ANOVA, ES = 0.07, p = 0.017). The amplitude of patients' zygomaticus activity in response to positive emotions was found to be negatively correlated with response times for ratings of emotional identification, suggesting a motor-behavioral link (r = –0.45, p = 0.02, two-tailed). Conclusions: Patients showed decreased mimicry overall, mimicking other peoples' frowns to some extent, but presenting with profoundly weakened and delayed smiles. These findings open a new avenue of inquiry into the “masked face” syndrome of PD.},
author = {Livingstone, Steven R and Vezer, Esztella and McGarry, Lucy M. and Lang, Anthony E. and Russo, Frank A.},
doi = {10.3389/fpsyg.2016.00780},
file = {:Users/gmac/mendeley/Livingstone et al/Livingstone et al. - 2016 - Deficits in the mimicry of facial expressions in Parkinson's disease.pdf:pdf},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Emotion,Facial bradykinesia,Facial expression,Facial masking,Facial mimicry,Hypomimia,Parkinson's disease,Rhythm},
number = {June},
pages = {1--12},
pmid = {27375505},
title = {{Deficits in the mimicry of facial expressions in Parkinson's disease}},
volume = {7},
year = {2016}
}
@article{Russo2012,
author = {Russo, Frank A and Ammirante, Paolo and Fels, Deborah I},
file = {:Users/gmac/mendeley/Russo, Ammirante, Fels/Russo, Ammirante, Fels - 2012 - Vibrotactile discrimination of musical timbre.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
keywords = {haptics},
month = {jan},
number = {4},
pages = {822--826},
publisher = {American Psychological Association},
title = {{Vibrotactile discrimination of musical timbre.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0029046 papers3://publication/doi/10.1037/a0029046},
volume = {38},
year = {2012}
}
@article{Goebl2009,
author = {Goebl, Werner and Palmer, Caroline},
file = {:Users/gmac/mendeley/Goebl, Palmer/Goebl, Palmer - 2009 - Synchronization of Timing and Motion Among Performing Musicians.pdf:pdf},
journal = {Music Perception},
month = {jun},
number = {5},
pages = {427--438},
title = {{Synchronization of Timing and Motion Among Performing Musicians}},
url = {http://www.jstor.org/stable/40286131 papers3://publication/doi/10.1525/mp.2009.26.5.427},
volume = {26},
year = {2009}
}
@article{Hove2007,
abstract = {Musical ensemble performance requires the synchronization of multiple performers, resulting in sequences of chords containing multiple tones with multiple onsets. Experiments 1 and 2 investigate whether sensorimotor synchronization with chord sequences containing tone-onset asynchronies is affected by (1) the magnitude of these asynchronies (25, 30, or 50 msec) and (2) the pitch of the leading tone (high vs. low). Participants tapped a finger in synchrony with different types of chord sequences created by crossing these variables, as well as with sequences of chords containing simultaneous onsets. Results indicate that taps were drawn toward the second onset, when present, especially when it was lower in pitch than the first. Additionally, chords with nonsimultaneous onsets increased tapping variability for nonmusicians, but decreased variability for musicians. Experiment 3 measured the perceptual centers of the chords from Experiment 2, and yielded results suggesting that subjective onsets determine the temporal placement of taps during synchronization.},
author = {Hove, Michael J and Keller, Peter E and Krumhansl, Carol L},
doi = {10.3758/BF03193772},
file = {:Users/gmac/mendeley/Hove, Keller, Krumhansl/Hove, Keller, Krumhansl - 2007 - Sensorimotor synchronization with chords containing tone-onset asynchronies(2).pdf:pdf},
isbn = {0031-5117 (Print)\r0031-5117 (Linking)},
issn = {0031-5117},
journal = {Perception & psychophysics},
number = {5},
pages = {699--708},
pmid = {17929693},
title = {{Sensorimotor synchronization with chords containing tone-onset asynchronies.}},
volume = {69},
year = {2007}
}
@article{Giraud2012,
annote = {- spectral impoverishment of speech can be tolerated to a remarkable degree, whereas temporal manipulations cause marked failures of perception
- low gamma, theta and delta activity might indicate phonemic, syllabic and phrasal processing, respectively
- intrinsic oscillations in auditory cortex interact with the neuronal activity generated by an incoming speech signal
- theta and gamma oscillations act by discretizing (sampling) the input spike trains to generate elementary units of the appropriate temporal granularity
- the neuronal response profile [of auditory cortex] is remarkably similar to the spectro-temporal structure of the speech envelope in the same 1-140 Hz frequency range
- when envelope tracking fails, speech intelligibility is compromised
- by preferentially trackin modulation within the delta-theta and gamma bands, auditory cortex 'discards' modulations situated in the beta (15-20 Hz) range
- the fractionation of modulation tracking over two discontinuous scales permits oscillatory nesting, the process by which the phrase of slow cortical oscillations controls higher rate oscillations; namely, their power or phase ... concurrent syllabic and phonemic analyses can remain heirarchically bound
- Zatorre's spectral-temporal asymmetry model. the main assumption is that gamma sampling dominates in left auditory cortex underpinning neural computations on a 12.5-25 ms timescale, whereas theta sampling is assumed to dominate in right auditory cortex
- cortical oscillations provide ways to temporally organize the incoming speech signal},
author = {Giraud, Anne-Lise and Poeppel, David},
file = {:Users/gmac/mendeley/Giraud, Poeppel/Giraud, Poeppel - 2012 - Cortical oscillations and speech processing emerging computational principles and operations.pdf:pdf},
journal = {Nature Neuroscience},
month = {mar},
number = {4},
pages = {511--517},
title = {{Cortical oscillations and speech processing: emerging computational principles and operations}},
url = {http://www.nature.com/doifinder/10.1038/nn.3063 papers3://publication/doi/10.1038/nn.3063},
volume = {15},
year = {2012}
}
@article{LeBlanc1997,
abstract = {We tested 27 male and female high school band members performing solos under three levels of audience presence. Participants performed alone in a practice room, in a practice room with one researcher present, and in the rehearsal room with all researchers, a peer group, and a tape recording being made. Dependent measures were an analog scale self-report of perceived anxiety, heart rate recorded during performance, judges' rating of the final performance, and an exit interview. Self-reported anxiety rose with each succeeding performance condition, and each reported increase was significant. Heart rate was steady across the first two performance conditions, but rose significantly at the third. Female participants presented better performances, reported significantly higher anxiety levels than did males in the third performance condition, and attained significantly higher heart rates than did males in the first and third conditions. Gender emerged as a significant predictor of heart rate during performance, with female performers attaining higher heart rates.},
author = {LeBlanc, Albert and Jin, Young Chang and Obert, Mary and Siivola, Carolyn},
file = {:Users/gmac/mendeley/LeBlanc et al/LeBlanc et al. - 1997 - Effect of Audience on Music Performance Anxiety.pdf:pdf},
journal = {Journal of Research in Music Education},
month = {oct},
number = {3},
pages = {480--496},
publisher = {MENC: The National Association for Music Education},
title = {{Effect of Audience on Music Performance Anxiety}},
url = {http://jrm.sagepub.com/content/45/3/480.abstract papers3://publication/doi/10.2307/3345541?ref=no-x-route:c5d782d6071182cb0f7a83b302dc3832},
volume = {45},
year = {1997}
}
@article{Onton2006,
author = {Onton, Julie and Westerfield, Marissa and Townsend, Jeanne and Makeig, Scott},
file = {:Users/gmac/mendeley/Onton et al/Onton et al. - 2006 - Imaging human EEG dynamics using independent component analysis.pdf:pdf},
journal = {Neuroscience & Biobehavioral Reviews},
month = {jan},
number = {6},
pages = {808--822},
title = {{Imaging human EEG dynamics using independent component analysis}},
volume = {30},
year = {2006}
}
@article{Todd2015,
abstract = {Some 20 years ago Todd and colleagues proposed that rhythm perception is mediated by the conjunction of a sensory representation of the auditory input and a motor representation of the body (Todd, 1994a, 1995), and that a sense of motion from sound is mediated by the vestibular system (Todd, 1992a, 1993b). These ideas were developed into a sensory-motor theory of rhythm and beat induction (Todd et al., 1999). A neurological substrate was proposed which might form the biological basis of the theory (Todd et al., 2002). The theory was implemented as a computational model and a number of experiments conducted to test it. In the following time there have been several key developments. One is the demonstration that the vestibular system is primal to rhythm perception, and in related work several experiments have provided further evidence that rhythm perception is body dependent. Another is independent advances in imaging, which have revealed the brain areas associated with both vestibular processing and rhythm perception. A third is the finding that vestibular receptors contribute to auditory evoked potentials (Todd et al., 2014a,b). These behavioral and neurobiological developments demand a theoretical overview which could provide a new synthesis over the domain of rhythm perception. In this paper we suggest four propositions as the basis for such a synthesis. (1) Rhythm perception is a form of vestibular perception; (2) Rhythm perception evokes both external and internal guidance of somatotopic representations; (3) A link from the limbic system to the internal guidance pathway mediates the "dance habit"; (4) The vestibular reward mechanism is innate. The new synthesis provides an explanation for a number of phenomena not often considered by rhythm researchers. We discuss these along with possible computational implementations and alternative models and propose a number of new directions for future research.},
author = {Todd, Neil P. M. and Lee, Christopher S.},
doi = {10.3389/fnhum.2015.00444},
file = {:Users/gmac/mendeley/Todd, Lee/Todd, Lee - 2015 - The sensory-motor theory of rhythm and beat induction 20 years on a new synthesis and future perspectives.pdf:pdf},
isbn = {doi:10.3389/fnhum.2015.00444},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
keywords = {auditory cortex,beat induction,movement,music and,rhythm perception,sensory-motor integration,vestibular syst,vestibular system},
number = {August},
pages = {444},
pmid = {26379522},
title = {{The sensory-motor theory of rhythm and beat induction 20 years on: a new synthesis and future perspectives}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4549635&tool=pmcentrez&rendertype=abstract},
volume = {9},
year = {2015}
}
@article{Nozaradan2017b,
abstract = {Musical entrainment is shared by all human cultures and the perception of a periodic beat is a cornerstone of this entrainment behavior. Here, we investigated whether beat perception might have its roots in the earliest stages of auditory cortical processing. Local field potentials were recorded from 8 patients implanted with depth-electrodes in Heschl's gyrus and the planum temporale (55 recording sites in total), usually considered as human primary and secondary auditory cortices. Using a frequency-tagging approach, we show that both low-frequency (<30 Hz) and high-frequency (>30 Hz) neural activities in these structures faithfully track auditory rhythms through frequency-locking to the rhythm envelope. A selective gain in amplitude of the response frequency-locked to the beat frequency was observed for the low-frequency activities but not for the high-frequency activities, and was sharper in the planum temporale, especially for the more challenging syncopated rhythm. Hence, this gain process is not systematic in all activities produced in these areas and depends on the complexity of the rhythmic input. Moreover, this gain was disrupted when the rhythm was presented at fast speed, revealing low-pass response properties which could account for the propensity to perceive a beat only within the musical tempo range. Together, these observations show that, even though part of these neural transforms of rhythms could already take place in subcortical auditory processes, the earliest auditory cortical processes shape the neural representation of rhythmic inputs in favor of the emergence of a periodic beat.},
author = {Nozaradan, Sylvie and Mouraux, Andr{\'{e}} and Jonas, Jacques and Colnat-Coulbois, Sophie and Rossion, Bruno and Maillard, Louis},
doi = {10.1007/s00429-016-1348-0},
file = {:Users/gmac/mendeley/Nozaradan et al/Nozaradan et al. - 2017 - Intracerebral evidence of rhythm transform in the human auditory cortex.pdf:pdf},
issn = {1863-2653},
journal = {Brain Structure and Function},
keywords = {Frequency-tagging,Human auditory perception,Human depth-electrode recording,Intracerebral EEG,Music cognition,Musical rhythm and beat processing},
number = {5},
pages = {2389--2404},
pmid = {27990557},
title = {{Intracerebral evidence of rhythm transform in the human auditory cortex}},
volume = {222},
year = {2017}
}
@article{Preston2002,
author = {Preston, Stephanie D and de Waal, Frans B M},
file = {:Users/gmac/mendeley/Preston, de Waal/Preston, de Waal - 2002 - Empathy Its ultimate and proximate bases.pdf:pdf},
journal = {Behavioral and Brain Sciences},
month = {jan},
pages = {1--72},
title = {{Empathy: Its ultimate and proximate bases}},
url = {papers3://publication/uuid/864591FD-8D21-4FB8-82C1-9DD415647989},
volume = {25},
year = {2002}
}
@article{Forand2011,
abstract = {Obtaining a postdoctoral position is a common and sometimes necessary step for psychologists' career development. However, in contrast to the internship application process, there is little formal guidance for postdoctoral applicants. By using professional resources and the experiences of individuals familiar with the postdoctoral process, we provide a detailed look at the process of obtaining a postdoctoral position. We cover the search, application, interview, and acceptance process, and provide some advice for dealing with common problems.},
author = {Forand, Nicolas R and Applebaum, Allison J},
file = {:Users/gmac/mendeley/Forand, Applebaum/Forand, Applebaum - 2011 - Demystifying the Postdoctoral Experience A Guide for Applicants.pdf:pdf},
journal = {The Behavior Therapist},
number = {5},
pages = {80,82--86},
title = {{Demystifying the Postdoctoral Experience: A Guide for Applicants}},
volume = {34},
year = {2011}
}
@article{Parncutt2011,
author = {Parncutt, Richard},
file = {:Users/gmac/mendeley/Parncutt/Parncutt - 2011 - The Tonic as Triad Key Profiles as Pitch Salience Profiles of Tonic Triads.pdf:pdf},
journal = {Music Perception: An Interdisciplinary Journal},
month = {apr},
number = {4},
pages = {333--366},
publisher = {University of California Press},
title = {{The Tonic as Triad: Key Profiles as Pitch Salience Profiles of Tonic Triads}},
url = {http://www.jstor.org/stable/info/10.1525/mp.2011.28.4.333 papers3://publication/doi/10.1525/mp.2011.28.4.333},
volume = {28},
year = {2011}
}
@article{Tierney2013a,
annote = {There is limited evidence that neural synchronization strength to auditory events at short timescales in the IC is linked to synchronization strength at longer timescales in the auditory cortex. Tierney and Kraus {*Tierney:2013ia} compared variability in tapping along with a metronome to IC synchronization strength to the speech sound /da/. They found that the variability in inter-tap-intervals was related to two measures of ABR variability: response consistency and inter-trial phase locking. To measure response consistency for each participant, half of the trials were randomly selected and averaged, and cross-correlated with the other half of responses. This was done 100 times, and the average of cross-correlations gave the final measure of response consistency. Inter-trial phase locking was calculated by averaging FFTs of all trials

tapping variability correlates with subcortical f0 synchrony. links between IC and cerebellum might mean that synchrony is improved in both with musicianship},
author = {Tierney, A and Kraus, Nina},
file = {:Users/gmac/mendeley/Tierney, Kraus/Tierney, Kraus - 2013 - The Ability to Move to a Beat Is Linked to the Consistency of Neural Responses to Sound.pdf:pdf},
journal = {Journal of Neuroscience},
month = {sep},
number = {38},
pages = {14981--14988},
title = {{The Ability to Move to a Beat Is Linked to the Consistency of Neural Responses to Sound}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0612-13.2013 papers3://publication/doi/10.1523/JNEUROSCI.0612-13.2013},
volume = {33},
year = {2013}
}
@article{Marsh1968,
author = {Marsh, James T and Warden, F G},
journal = {Laryngoscope},
month = {jan},
pages = {1149--1163},
title = {{Sound Evoked Frequency-Following Responses in the Central Auditory Pathway}},
url = {papers3://publication/uuid/FB76F6E9-17BB-48BC-91B1-3F67CC328CE6},
volume = {78},
year = {1968}
}
@article{Moore2000,
author = {Moore, Jean K},
file = {:Users/gmac/mendeley/Moore/Moore - 2000 - Organization of the Human Superior Olivary Complex.pdf:pdf},
journal = {Microscopy Research and Technique},
month = {oct},
pages = {403--412},
title = {{Organization of the Human Superior Olivary Complex}},
url = {papers3://publication/uuid/82FB3ABE-F2C5-4EE5-BF14-7E7DD6ACC671},
volume = {51},
year = {2000}
}
@article{Ross2012,
author = {Ross, Bernhard and Jamali, Shahab and Miyazaki, Takahiro and Fujioka, Takako},
file = {:Users/gmac/mendeley/Ross et al/Ross et al. - 2012 - Synchronization of beta and gamma oscillations in the somatosensory evoked neuromagnetic steady-state response.pdf:pdf},
journal = {Experimental Neurology},
keywords = {beta,gamma,haptics},
month = {aug},
title = {{Synchronization of beta and gamma oscillations in the somatosensory evoked neuromagnetic steady-state response}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0014488612003287 papers3://publication/doi/10.1016/j.expneurol.2012.08.019},
year = {2012}
}
@article{Singer2006,
author = {Singer, Tania and Seymour, Ben and O'Doherty, John P and Stephan, Klaas E and Dolan, Raymond J and Frith, Chris D},
file = {:Users/gmac/mendeley/Singer et al/Singer et al. - 2006 - Empathic neural responses are modulated by the perceived fairness of others.pdf:pdf},
journal = {Nature},
month = {jan},
number = {7075},
pages = {466--469},
title = {{Empathic neural responses are modulated by the perceived fairness of others}},
url = {http://www.nature.com/doifinder/10.1038/nature04271 papers3://publication/doi/10.1038/nature04271},
volume = {439},
year = {2006}
}
@article{Krampe2000,
abstract = {Professional pianists performed 2 bimanual rhythms at a wide range of different tempos. The polyrhythmic task required the combination of 2 isochronous sequences (3 against 4) between the hands; in the syncopated rhythm task successive keystrokes formed intervals of identical (isochronous) durations. At slower tempos, pianists relied on integrated timing control merging successive intervals between the hands into a common reference frame. A timer-motor model is proposed based on the concepts of rate fluctuation and the distinction between target specification and timekeeper execution processes as a quantitative account of performance at slow tempos. At rapid rates expert pianists used hand-independent, parallel timing control. In alternative to a model based on a single central clock, findings support a model of flexible control structures with multiple timekeepers that can work in parallel to accommodate specific task constraints.},
author = {Krampe, R T and Kliegl, R and Mayr, U and Engbert, R and Vorberg, D},
doi = {10.1037/0096-1523.26.1.206},
file = {:Users/gmac/mendeley/Krampe et al/Krampe et al. - 2000 - The fast and the slow of skilled bimanual rhythm production parallel versus integrated timing.pdf:pdf},
isbn = {0096-1523 (Print)},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
number = {I},
pages = {206--233},
pmid = {10696614},
title = {{The fast and the slow of skilled bimanual rhythm production: parallel versus integrated timing.}},
volume = {26},
year = {2000}
}
@article{Phillips-Silver2010,
abstract = {Entrainment has been studied in a variety of contexts including music perception, dance, verbal communication, and motor coordination more generally. Here we seek to provide a unifying framework that incorporates the key aspects of entrainment as it has been studied in these varying domains. We propose that there are a number of types of entrainment that build upon pre-existing adaptations that allow organisms to perceive stimuli as rhythmic, to produce periodic stimuli, and to integrate the two using sensory feedback. We suggest that social entrainment is a special case of spatiotemporal coordination where the rhythmic signal originates from another individual. We use this framework to understand the function and evolutionary basis for coordinated rhythmic movement and to explore questions about the nature of entrainment in music and dance. The framework of entrainment presented here has a number of implications for the vocal learning hypothesis and other proposals for the evolution of coordinated rhythmic behavior across an array of species.},
annote = {This is a test note.},
author = {Phillips-Silver, Jessica and Aktipis, C Athena and Bryant, Gregory A},
doi = {10.1525/mp.2010.28.1.3},
file = {:Users/gmac/mendeley/Phillips-Silver, Aktipis, Bryant/Phillips-Silver, Aktipis, Bryant - 2010 - The Ecology of Entrainment Foundations of Coordinated Rhythmic Movement.pdf:pdf},
journal = {Music Perception},
keywords = {coordination,entrainment,spatiotemporal},
number = {1},
pages = {3--14},
title = {{The Ecology of Entrainment: Foundations of Coordinated Rhythmic Movement}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3137907/},
volume = {28},
year = {2010}
}
@article{Kishon-Rabin2011,
author = {Kishon-Rabin, Liat and Amir, Ofer and Vexler, Yifat and Zaltz, Yael},
file = {:Users/gmac/mendeley/Kishon-Rabin et al/Kishon-Rabin et al. - 2011 - Pitch Discrimination Are Professional Musicians Better than Non-Musicians.pdf:pdf},
journal = {Journal of Basic & Clinical Physiology & Pharmacology},
month = {apr},
pages = {125--143},
title = {{Pitch Discrimination: Are Professional Musicians Better than Non-Musicians?}},
url = {http://www.degruyter.com/dg/viewarticle.fullcontentlink:pdfeventlink/$002fj$002fjbcpp.2001.12.2$002fjbcpp.2001.12.2.125$002fjbcpp.2001.12.2.125.pdf?t:ac=j$002fjbcpp.2001.12.2$002fjbcpp.2001.12.2.125$002fjbcpp.2001.12.2.125.xml papers3://publication/uuid/6},
volume = {12},
year = {2011}
}
@article{Sarampalis2009,
author = {Sarampalis, Anastasios and Kalluri, Sridhar and Edwards, Brent and Hafter, Ervin},
file = {:Users/gmac/mendeley/Sarampalis et al/Sarampalis et al. - 2009 - Objective Measures of Listening Effort Effects of Background Noise and Noise Reduction.pdf:pdf},
journal = {Journal of Speech, Language, and Hearing Research},
month = {oct},
pages = {1230--1240},
title = {{Objective Measures of Listening Effort: Effects of Background Noise and Noise Reduction}},
url = {papers3://publication/uuid/21036342-9E1A-4686-8C62-E4B4A29D5D7B},
volume = {52},
year = {2009}
}
@article{Ekman1994,
abstract = {J. A. Russell (1994) misrepresents what universality means, misinterprets the evidence from past studies, and fails to consider or report findings that disagree with his position. New data are introduced that decisively answer the central question that Russell raises about the use of a forced-choice format in many of the past studies. This article also shows that his many other qualms about other aspects of the design of the studies of literate cultures have no merit. Russell's critique of the preliterate cultures is inaccurate; he does not fully disclose what those who studied preliterate subjects did or what they concluded that they had found. Taking account of all of Russell's qualms, my analysis shows that the evidence from both literate and preliterate cultures is overwhelming in support of universals in facial expressions.},
address = {Human Interaction Laboratory, Langley Porter Psychiatric Institute, University of California, San Francisco 94143.},
author = {Ekman, Paul},
file = {:Users/gmac/mendeley/Ekman/Ekman - 1994 - Strong evidence for universals in facial expressions a reply to Russell's mistaken critique.pdf:pdf},
journal = {Psychological Bulletin},
month = {mar},
number = {2},
pages = {268--287},
title = {{Strong evidence for universals in facial expressions: a reply to Russell's mistaken critique.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=8165272&retmode=ref&cmd=prlinks papers3://publication/uuid/7EF05CEC-688B-47F5-BCCA-BDE052CB5D76},
volume = {115},
year = {1994}
}
@article{Weisz2014,
abstract = {Hearing Research, 307 (2014) 16-28. doi:10.1016/j.heares.2013.07.009},
author = {Weisz, Nathan and Obleser, Jonas},
file = {:Users/gmac/mendeley/Weisz, Obleser/Weisz, Obleser - 2014 - Synchronisation signatures in the listening brain A perspective from non-invasive neuroelectrophysiology.pdf:pdf},
journal = {Hearing Research},
month = {jan},
number = {c},
pages = {16--28},
publisher = {Elsevier B.V.},
title = {{Synchronisation signatures in the listening brain: A perspective from non-invasive neuroelectrophysiology}},
url = {http://dx.doi.org/10.1016/j.heares.2013.07.009 papers3://publication/doi/10.1016/j.heares.2013.07.009},
volume = {307},
year = {2014}
}
@article{Leow2014,
abstract = {Slowed gait in patients with Parkinson's disease (PD) can be improved when patients synchronize footsteps to isochronous metronome cues, but limited retention of such improvements suggest that permanent cueing regimes are needed for long-term improvements. If so, music might make permanent cueing regimes more pleasant, improving adherence; however, music cueing requires patients to synchronize movements to the "beat," which might be difficult for patients with PD who tend to show weak beat perception. One solution may be to use high-groove music, which has high beat salience that may facilitate synchronization, and affective properties, which may improve motivation to move. As a first step to understanding how beat perception affects gait in complex neurological disorders, we examined how beat perception ability affected gait in neurotypical adults. Synchronization performance and gait parameters were assessed as healthy young adults with strong or weak beat perception synchronized to low-groove music, high-groove music, and metronome cues. High-groove music was predicted to elicit better synchronization than low-groove music, due to its higher beat salience. Two musical tempi, or rates, were used: (1) preferred tempo: beat rate matched to preferred step rate and (2) faster tempo: beat rate adjusted to 22.5% faster than preferred step rate. For both strong and weak beat-perceivers, synchronization performance was best with metronome cues, followed by high-groove music, and worst with low-groove music. In addition, high-groove music elicited longer and faster steps than low-groove music, both at preferred tempo and at faster tempo. Low-groove music was particularly detrimental to gait in weak beat-perceivers, who showed slower and shorter steps compared to uncued walking. The findings show that individual differences in beat perception affect gait when synchronizing footsteps to music, and have implications for using music in gait rehabilitation.},
author = {Leow, Li-Ann and Parrott, Taylor and Grahn, Jessica A},
doi = {10.3389/fnhum.2014.00811},
file = {:Users/gmac/mendeley/Leow, Parrott, Grahn/Leow, Parrott, Grahn - 2014 - Individual differences in beat perception affect gait responses to low- and high-groove music.pdf:pdf},
isbn = {1662-5161},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscienceuman neuroscience},
number = {October},
pages = {811},
pmid = {25374521},
title = {{Individual differences in beat perception affect gait responses to low- and high-groove music.}},
volume = {8},
year = {2014}
}
@article{Pascual-Leone1995,
abstract = {1. We used transcranial magnetic stimulation (TMS) to study the role of plastic changes of the human motor system in the acquisition of new fine motor skills. We mapped the cortical motor areas targeting the contralateral long finger flexor and extensor muscles in subjects learning a one-handed, five-finger exercise on the piano. In a second experiment, we studied the different effects of mental and physical practice of the same five-finger exercise on the modulation of the cortical motor areas targeting muscles involved in the task. 2. Over the course of 5 days, as subjects learned the one-handed, five-finger exercise through daily 2-h manual practice sessions, the cortical motor areas targeting the long finger flexor and extensor muscles enlarged, and their activation threshold decreased. Such changes were limited to the cortical representation of the hand used in the exercise. No changes of cortical motor outputs occurred in control subjects who underwent daily TMS mapping but did not practice on the piano at all (control group 1). 3. We studied the effect of increased hand use without specific skill learning in subjects who played the piano at will for 2 h each day using only the right hand but who were not taught the five-finger exercise (control group 2) and who did not practice any specific task. In these control subjects, the changes in cortical motor outputs were similar but significantly less prominent than in those occurring in the test subjects, who learned the new skill.(ABSTRACT TRUNCATED AT 250 WORDS)},
address = {Human Cortical Physiology Unit, National Institute of Neurological Disorders and Stroke, National Institutes of Health, Bethesda, Maryland 20892, USA.},
author = {Pascual-Leone, A and Nguyet, D and Cohen, L G and Brasil-Neto, J P and Cammarota, A and Hallett, M},
journal = {Journal of Neurophysiology},
month = {sep},
number = {3},
pages = {1037--1045},
title = {{Modulation of muscle responses evoked by transcranial magnetic stimulation during the acquisition of new fine motor skills.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=7500130&retmode=ref&cmd=prlinks papers3://publication/uuid/BF63D4CC-21B3-44CB-B2DE-9AC216F80524},
volume = {74},
year = {1995}
}
@article{Davidson1993,
author = {Davidson, Jane W},
file = {:Users/gmac/mendeley/Davidson/Davidson - 1993 - Visual Perception of Performance Manner in the Movements of Solo Musicians.pdf:pdf},
journal = {Psychology of Music},
month = {jan},
pages = {103--113},
title = {{Visual Perception of Performance Manner in the Movements of Solo Musicians}},
url = {papers3://publication/uuid/31394F31-91B8-428A-96B9-950D836633E4},
volume = {21},
year = {1993}
}
@article{Rizzolatti2004,
author = {Rizzolatti, Giacomo and Craighero, Laila},
file = {:Users/gmac/mendeley/Rizzolatti, Craighero/Rizzolatti, Craighero - 2004 - The Mirror-Neuron System.pdf:pdf},
journal = {Annual Review of Neuroscience},
keywords = {MNS,mu},
month = {jul},
number = {1},
pages = {169--192},
title = {{The Mirror-Neuron System}},
url = {http://www.annualreviews.org/doi/abs/10.1146/annurev.neuro.27.070203.144230 papers3://publication/doi/10.1146/annurev.neuro.27.070203.144230},
volume = {27},
year = {2004}
}
@article{Freeman1993,
author = {Freeman, J S and Cody, F W J and Schady, W},
file = {:Users/gmac/mendeley/Freeman, Cody, Schady/Freeman, Cody, Schady - 1993 - The influence of external timing cues upon the rhythm ofvoluntarymovements inParkinson's disease.pdf:pdf},
journal = {Journal of Neurology, Neurosurgery, and Psychiatry},
month = {jan},
pages = {1078--1084},
title = {{The influence of external timing cues upon the rhythm ofvoluntarymovements inParkinson's disease}},
url = {http://jnnp.bmj.com/content/56/10/1078.full.pdf papers3://publication/doi/10.1136/jnnp.56.10.1078},
volume = {56},
year = {1993}
}
@article{Thorpe2012,
author = {Thorpe, M and Ockelford, A and Aksentijevic, A},
file = {:Users/gmac/mendeley/Thorpe, Ockelford, Aksentijevic/Thorpe, Ockelford, Aksentijevic - 2012 - An empirical exploration of the zygonic model of expectation in music.pdf:pdf},
journal = {Psychology of Music},
month = {jun},
number = {4},
pages = {429--470},
title = {{An empirical exploration of the zygonic model of expectation in music}},
url = {http://pom.sagepub.com/cgi/doi/10.1177/0305735610392103 papers3://publication/doi/10.1177/0305735610392103},
volume = {40},
year = {2012}
}
@article{Muri1995,
author = {M{\"{u}}ri, R M and Rivaud, S and Vermersch, A I and L{\'{e}}ger, J M and Pierrot-Deseilligny, C},
file = {:Users/gmac/mendeley/M{\"{u}}ri et al/M{\"{u}}ri et al. - 1995 - Effects of transcranial magnetic stimulationover the region of the supplementary motor area during sequences of me.pdf:pdf},
journal = {Experimental Brain Research},
month = {jan},
pages = {163--166},
title = {{Effects of transcranial magnetic stimulationover the region of the supplementary motor area during sequences of memory-guided saccades}},
url = {papers3://publication/uuid/B520EC58-27E1-407E-A936-E9F89F7DE4E2},
volume = {104},
year = {1995}
}
@article{Blood2001,
abstract = {We used positron emission tomography to study neural mechanisms underlying intensely pleasant emotional responses to music. Cerebral blood flow changes were measured in response to subject-selected music that elicited the highly pleasurable experience of "shivers-down-the-spine" or "chills." Subjective reports of chills were accompanied by changes in heart rate, electromyogram, and respiration. As intensity of these chills increased, cerebral blood flow increases and decreases were observed in brain regions thought to be involved in reward/motivation, emotion, and arousal, including ventral striatum, midbrain, amygdala, orbitofrontal cortex, and ventral medial prefrontal cortex. These brain structures are known to be active in response to other euphoria-inducing stimuli, such as food, sex, and drugs of abuse. This finding links music with biologically relevant, survival-related stimuli via their common recruitment of brain circuitry involved in pleasure and reward.},
author = {Blood, A J and Zatorre, R J},
doi = {10.1073/pnas.191355898},
file = {:Users/gmac/mendeley/Blood, Zatorre/Blood, Zatorre - 2001 - Intensely pleasurable responses to music correlate with activity in brain regions implicated in reward and emoti.pdf:pdf},
isbn = {0027-8424 (Print)\r0027-8424 (Linking)},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Adult,Amygdala,Amygdala: physiology,Brain,Brain: physiology,Cerebrovascular Circulation,Emotions,Female,Functional Laterality,Heart Rate,Hippocampus,Hippocampus: physiology,Humans,Male,Music,Music: psychology,Organ Specificity,Prefrontal Cortex,Prefrontal Cortex: physiology,Regression Analysis,Respiration,Reward,Tomography, Emission-Computed},
number = {20},
pages = {11818--23},
pmid = {11573015},
title = {{Intensely pleasurable responses to music correlate with activity in brain regions implicated in reward and emotion.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11573015},
volume = {98},
year = {2001}
}
@article{Turpin1979,
author = {Turpin, G and Siddle, DAT},
file = {:Users/gmac/mendeley/Turpin, Siddle/Turpin, Siddle - 1979 - Effects of stimulus intensity on electrodermal activity.pdf:pdf},
journal = {Psychophysiology},
title = {{Effects of stimulus intensity on electrodermal activity}},
volume = {16},
year = {1979}
}
@article{Rosen1992,
abstract = {The temporal properties of speech appear to play a more important role in linguistic contrasts than has hitherto been appreciated. Therefore, a new framework for describing the acoustic structure of speech based purely on temporal aspects has been developed. From this point of view, speech can be said to be comprised of three main temporal features, based on dominant fluctuation rates: envelope, periodicity, and fine-structure. Each feature has distinct acoustic manifestations, auditory and perceptual correlates, and roles in linguistic contrasts. The applicability of this three-featured temporal system is discussed in relation to hearing-impaired and normal listeners.},
author = {Rosen, S.},
doi = {10.1098/rstb.1992.0070},
file = {:Users/gmac/mendeley/Rosen/Rosen - 1992 - Temporal Information in Speech Acoustic, Auditory and Linguistic Aspects.pdf:pdf},
isbn = {0962-8436 (Print)},
issn = {0962-8436},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
number = {1278},
pages = {367--373},
pmid = {1354376},
title = {{Temporal Information in Speech: Acoustic, Auditory and Linguistic Aspects}},
url = {http://rstb.royalsocietypublishing.org/cgi/doi/10.1098/rstb.1992.0070},
volume = {336},
year = {1992}
}
@article{Juslin2003,
author = {Juslin, Patrik N and Laukka, Petri},
file = {:Users/gmac/mendeley/Juslin, Laukka/Juslin, Laukka - 2003 - Communication of emotions in vocal expression and music performance Different channels, same code.pdf:pdf},
journal = {Psychological Bulletin},
month = {jan},
number = {5},
pages = {770--814},
title = {{Communication of emotions in vocal expression and music performance: Different channels, same code?}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-2909.129.5.770 papers3://publication/doi/10.1037/0033-2909.129.5.770},
volume = {129},
year = {2003}
}
@article{Mather2016,
author = {Mather, Mara},
doi = {10.1146/annurev-psych-122414-033540},
file = {:Users/gmac/mendeley/Mather/Mather - 2016 - The Affective Neuroscience of Aging.pdf:pdf},
journal = {Annual Review of Psychology},
keywords = {affective neuroscience,aging,amygdala,emotion,ventromedial prefrontal},
pages = {213--238},
title = {{The Affective Neuroscience of Aging}},
volume = {67},
year = {2016}
}
@article{Repp2013a,
annote = {- ability to perceive underlying beat requires basal ganglia (Grahn & Brett 2009)},
author = {Repp, Bruno H and Su, Yi-Huang},
file = {:Users/gmac/mendeley/Repp, Su/Repp, Su - 2013 - Sensorimotor synchronization A review of recent research (2006–2012).pdf:pdf},
journal = {Psychonomic Bulletin & Review},
month = {feb},
title = {{Sensorimotor synchronization: A review of recent research (2006–2012)}},
url = {http://link.springer.com/10.3758/s13423-012-0371-2 papers3://publication/doi/10.3758/s13423-012-0371-2},
year = {2013}
}
@article{Nozaradan2011,
annote = {Methods
- Cz = active, non-inverting
- ipsilateral earlobe = reference, inverting
- forehead or contralateral earlobe = ground},
author = {Nozaradan, Sylvie and Peretz, I and Missal, M and Mouraux, A},
file = {:Users/gmac/mendeley/Nozaradan et al/Nozaradan et al. - 2011 - Tagging the Neuronal Entrainment to Beat and Meter.pdf:pdf},
journal = {Journal of Neuroscience},
month = {jul},
number = {28},
pages = {10234--10240},
title = {{Tagging the Neuronal Entrainment to Beat and Meter}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0411-11.2011 papers3://publication/doi/10.1523/JNEUROSCI.0411-11.2011},
volume = {31},
year = {2011}
}
@article{DeBoer2008,
author = {de Boer, J and Thornton, A R D},
file = {:Users/gmac/mendeley/de Boer, Thornton/de Boer, Thornton - 2008 - Neural Correlates of Perceptual Learning in the Auditory Brainstem Efferent Activity Predicts and Reflects Im.pdf:pdf},
journal = {Journal of Neuroscience},
month = {may},
number = {19},
pages = {4929--4937},
title = {{Neural Correlates of Perceptual Learning in the Auditory Brainstem: Efferent Activity Predicts and Reflects Improvement at a Speech-in-Noise Discrimination Task}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0902-08.2008 papers3://publication/doi/10.1523/JNEUROSCI.0902-08.2008},
volume = {28},
year = {2008}
}
@article{Obleser2012,
author = {Obleser, Jonas and Herrmann, Bjorn and Henry, Molly J},
file = {:Users/gmac/mendeley/Obleser, Herrmann, Henry/Obleser, Herrmann, Henry - 2012 - Neural oscillations in speech don't be enslaved by the envelope.pdf:pdf},
journal = {Frontiers in Human Neuroscience},
month = {aug},
number = {250},
pages = {1--4},
title = {{Neural oscillations in speech: don't be enslaved by the envelope}},
url = {papers3://publication/doi/10.3389/fnhum.2012.00250/full},
volume = {6},
year = {2012}
}
@article{Steinberg1992,
author = {Steinberg, Reinhard and Gunther, Wilfried and Stiltz, Irene and Rondot, Pierre},
file = {:Users/gmac/mendeley/Steinberg et al/Steinberg et al. - 1992 - EEG-Mapping During Music Stimulation.pdf:pdf},
journal = {Psychomusicology},
keywords = {EEG,neuropsychology},
month = {oct},
number = {2},
pages = {157--170},
title = {{EEG-Mapping During Music Stimulation}},
url = {papers3://publication/uuid/0EA3CF3C-C3E0-4EB1-BFC2-7A21C87D3E85},
volume = {11},
year = {1992}
}
@article{Russo2011,
author = {Russo, Frank A and Ives, D Timothy and Goy, Huiwen and Pichora-Fuller, M Kathleen and Patterson, Roy D},
file = {:Users/gmac/mendeley/Russo et al/Russo et al. - 2011 - Age-Related Difference in Melodic Pitch Perception Is Probably Mediated by Temporal Processing Empirical and Compu.pdf:pdf},
journal = {Ear & Hearing},
month = {sep},
number = {5},
pages = {1--10},
title = {{Age-Related Difference in Melodic Pitch Perception Is Probably Mediated by Temporal Processing: Empirical and Computational Evidence}},
url = {http://s3.amazonaws.com/academia.edu.documents/30635665/12-Russo_Ives_Goy_Pichora-Fuller_Patterson.pdf?AWSAccessKeyId=AKIAIR6FSIMDFXPEERSA&Expires=1373381235&Signature=KJJna+MjaLUhTc/D3zKYLzMCfnk=&response-content-disposition=inline papers3://public},
volume = {32},
year = {2011}
}
@article{Smith1994,
abstract = {Investigated the ability of 48 adults (aged 17-45 yrs) and 49 children (aged 6-12 yrs) to reproduce 18 rhythmic sequences played on a drum machine. The Ss were given Progressive Matrices intelligence tests and a hearing test. Drawings that represented the rhythmic sequences with long and short durations were classified as metric; drawings that grouped long and short durations together were classified as figural. 24 adults produced metric drawings; 24 produced figural drawings. Of the 49 children, 9 made metric drawings, 9 made figural drawings, 6 made counting drawings, and 25 drawings were ambiguous. It is concluded that figural drawers possess metric skills and that accuracy of a figural drawing may be an indicator of the ability to engage in metric action. This ability may be usefully exploited in musical education. (PsycINFO Database Record (c) 2004 APA, all rights reserved)},
author = {Smith, Karen C and Cuddy, Lola L and Upitis, Rena},
doi = {10.1177/0305735694222002},
file = {:Users/gmac/mendeley/Smith, Cuddy, Upitis/Smith, Cuddy, Upitis - 1994 - Figural and metric understanding of rhythm.pdf:pdf},
isbn = {0305-7356},
issn = {0305-7356},
journal = {Psychology of Music},
keywords = {6-12 vs 17-45 yr olds,Age Differences,Auditory Discrimination,Drawing,Human,Musical Ability,Pattern Discrimination,Rhythm,ability to reproduce figural vs metric drawings of},
number = {2},
pages = {117--135},
title = {{Figural and metric understanding of rhythm}},
url = {http://www.sagepublications.com/%5Cnhttp://ids.library.utoronto.ca/ids70/gateway.php?mode=pdf&an=1995-16966-001&db=psycinfo-set-c&s1=21e0ad893198063d04c948b7955bc7e1&s2=f4e61ca44894ff02d7b1cd740b2a19cd},
volume = {22},
year = {1994}
}
@article{Ding2016a,
abstract = {Speech and music have structured rhythms, but these rhythms are rarely compared empirically. This study, based on large corpora, quantitatively characterizes and compares a major acoustic correlate of spoken and musical rhythms, the slow (0.25- 32 Hz) temporal modulations in sound intensity. We show that the speech modulation spectrum is highly consistent cross 9 languages (including languages with typologically different rhythmic characteristics, such as English, French, and Mandarin Chinese). A different, but similarly consistent modulation spectrum is observed for Western classical music played by 6 different instruments. Western music, including classical music played by single instruments, symphonic, jazz, and rock music, contains more energy than speech in the low modulation frequency range below 4 Hz. The temporal modulations of speech and music show broad but well-separated peaks around 5 and 2 Hz, respectively. These differences in temporal modulations alone, without any spectral details, can discriminate speech and music with high accuracy. Speech and music therefore show distinct and reliable statistical regularities in their temporal modulations that likely facilitate their perceptual analysis and its neural foundations.},
author = {Ding, Nai and Patel, Aniruddh and Chen, Lin and Butler, Henry and Luo, Cheng and Poeppel, David},
doi = {10.1101/059683},
file = {:Users/gmac/mendeley/Ding et al/Ding et al. - 2016 - Temporal Modulations Reveal Distinct Rhythmic Properties of Speech and Music.pdf:pdf},
isbn = {1044071060},
journal = {bioRxiv},
keywords = {corresponding author,music,rhythm,speech,temporal modulations},
number = {1},
pages = {059683},
title = {{Temporal Modulations Reveal Distinct Rhythmic Properties of Speech and Music}},
url = {http://www.biorxiv.org/content/early/2016/06/18/059683.abstract},
volume = {1},
year = {2016}
}
@article{Earl2001,
author = {Earl, Peter E},
file = {:Users/gmac/mendeley/Earl/Earl - 2001 - Simon's travel theorem and the demand for live music.pdf:pdf},
journal = {Journal of Economic Psychology},
keywords = {audience,performance},
month = {jun},
pages = {335--358},
title = {{Simon's travel theorem and the demand for live music}},
url = {papers3://publication/uuid/6D9AE8DC-9259-40C5-96CB-06DB150A3162},
volume = {22},
year = {2001}
}
@article{Musacchia2005,
annote = {- particiapants weren't necessarily experienced lip readers
- perhaps with experienced (e.g. deaf) lipreaders there wouldn't be a delay because seeing is how they hear
- could argue predictive power for auditory alone..},
author = {Musacchia, Gabriella and Sams, Mikko and Nicol, Trent and Kraus, Nina},
file = {:Users/gmac/mendeley/Musacchia et al/Musacchia et al. - 2005 - Seeing speech affects acoustic information processing in the human brainstem.pdf:pdf},
journal = {Experimental Brain Research},
month = {oct},
number = {1-2},
pages = {1--10},
title = {{Seeing speech affects acoustic information processing in the human brainstem}},
url = {http://link.springer.com/10.1007/s00221-005-0071-5 papers3://publication/doi/10.1007/s00221-005-0071-5},
volume = {168},
year = {2005}
}
@article{Carroll1996,
abstract = {Certain facial expressions have been theorized to be easily recognizable signals of specific emotions. If so, these expressions should override situationally based expectations used by a person in attributing an emotion to another. An alternative account is offered in which the face provides information relevant to emotion but does not signal a specific emotion. Therefore, in specified circumstances, situational rather than facial information was predicted to determine the judged emotion. This prediction was supported in 3 studies--indeed, in each of the 22 cases examined (e.g., a person in a frightening situation but displaying a reported "facial expression of anger" was judged as afraid). Situational information was especially influential when it suggested a nonbasic emotion (e.g., a person in a painful situation but displaying a "facial expression of fear" was judged as in pain).},
address = {Department of Psychology, University of British Columbia, Vancouver, Canada.},
author = {Carroll, J M and Russell, James A},
file = {:Users/gmac/mendeley/Carroll, Russell/Carroll, Russell - 1996 - Do facial expressions signal specific emotions Judging emotion from the face in context.pdf:pdf},
journal = {Journal of personality and social psychology},
month = {feb},
number = {2},
pages = {205--218},
title = {{Do facial expressions signal specific emotions? Judging emotion from the face in context.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=8636880&retmode=ref&cmd=prlinks papers3://publication/uuid/AEBE3848-D144-4A07-893B-02A9CDD7939B},
volume = {70},
year = {1996}
}
@article{Huron2006,
author = {Huron, David and Ommen, Ann},
file = {:Users/gmac/mendeley/Huron, Ommen/Huron, Ommen - 2006 - An Empirical Study of Syncopation in American Popular Music, 1890-1939.pdf:pdf},
journal = {Music Theory Spectrum},
month = {oct},
number = {2},
pages = {211--231},
title = {{An Empirical Study of Syncopation in American Popular Music, 1890-1939}},
url = {http://www.jstor.org/stable/4499860 papers3://publication/doi/10.1525/mts.2006.28.2.211},
volume = {28},
year = {2006}
}
@article{Steinbeis2008,
annote = {N400 indicates affective incongruence between chord/word primes and targets},
author = {Steinbeis, Nikolaus and Koelsch, Stefan},
editor = {Santos, Laurie},
file = {:Users/gmac/mendeley/Steinbeis, Koelsch/Steinbeis, Koelsch - 2008 - Comparing the Processing of Music and Language Meaning Using EEG and fMRI Provides Evidence for Similar and.pdf:pdf},
journal = {PLoS ONE},
keywords = {EEG,neuropsychology},
month = {may},
number = {5},
pages = {e2226},
title = {{Comparing the Processing of Music and Language Meaning Using EEG and fMRI Provides Evidence for Similar and Distinct Neural Representations}},
url = {http://dx.plos.org/10.1371/journal.pone.0002226.g005 papers3://publication/doi/10.1371/journal.pone.0002226.g005},
volume = {3},
year = {2008}
}
@article{Velasco2011,
author = {Velasco, M J and Large, Edward W},
file = {:Users/gmac/mendeley/Velasco, Large/Velasco, Large - 2011 - Pulse Detection in Syncopated Rhythms Using Neural Oscillators.pdf:pdf},
journal = {12th International Society for Music Information Retreival Converence},
keywords = {rhythm},
month = {oct},
pages = {185--190},
title = {{Pulse Detection in Syncopated Rhythms Using Neural Oscillators}},
url = {papers3://publication/uuid/BA44C73D-6DEF-4399-931B-FA76A7EC7E9B},
year = {2011}
}
@article{Keller2011,
author = {Keller, Peter E and Schubert, Emery},
file = {:Users/gmac/mendeley/Keller, Schubert/Keller, Schubert - 2011 - Cognitive and affective judgements of syncopated musical themes.pdf:pdf},
journal = {Advances in Cognitive Psychology},
month = {jan},
pages = {142--156},
title = {{Cognitive and affective judgements of syncopated musical themes}},
url = {http://versita.metapress.com/openurl.asp?genre=article&id=doi:10.2478/v10053-008-0094-0 papers3://publication/doi/10.2478/v10053-008-0094-0},
volume = {7},
year = {2011}
}
@article{Janata2012,
abstract = {The urge to move in response to music, combined with the positive affect associated with the coupling of sensory and motor processes while engaging with music (referred to as sensorimotor coupling) in a seemingly effortless way, is commonly described as the feeling of being in the groove. Here, we systematically explore this compelling phenomenon in a population of young adults. We utilize multiple levels of analysis, comprising phenomenological, behavioral, and computational techniques. Specifically, we show (a) that the concept of the groove is widely appreciated and understood in terms of a pleasurable drive toward action, (b) that a broad range of musical excerpts can be appraised reliably for the degree of perceived groove, (c) that the degree of experienced groove is inversely related to experienced difficulty of bimanual sensorimotor coupling under tapping regimes with varying levels of expressive constraint, (d) that high-groove stimuli elicit spontaneous rhythmic movements, and (e) that quantifiable measures of the quality of sensorimotor coupling predict the degree of experienced groove. Our results complement traditional discourse regarding the groove, which has tended to take the psychological phenomenon for granted and has focused instead on the musical and especially the rhythmic qualities of particular genres of music that lead to the perception of groove. We conclude that groove can be treated as a psychological construct and model system that allows for experimental exploration of the relationship between sensorimotor coupling with music and emotion.},
annote = {Keil and Feld (1994) regard participatory discrepancies— deviations from precise metronomic timing relationships—as a central source of groove (p.1)
The term groove is commonly used by musicians to refer to a pleasing state in which the creation of music becomes seemingly effortless (p.2)},
author = {Janata, Petr and Tomic, Stefan T and Haberman, Jason M},
doi = {10.1037/a0024208},
file = {:Users/gmac/mendeley/Janata, Tomic, Haberman/Janata, Tomic, Haberman - 2012 - Sensorimotor coupling in music and the psychology of the groove.pdf:pdf},
issn = {1939-2222},
journal = {Journal of Experimental Psychology: General},
keywords = {beat,emotion,popular music,rhythm,synchronization},
month = {jan},
number = {1},
pages = {54--75},
title = {{Sensorimotor coupling in music and the psychology of the groove.}},
volume = {141},
year = {2012}
}
@article{Lancaster2000,
abstract = {An automated coordinate-based system to retrieve brain labels from the 1988 Talairach Atlas, called the Talairach Daemon (TD), was previously introduced [Lancaster et al., 1997]. In the present study, the TD system and its 3-D database of labels for the 1988 Talairach atlas were tested for labeling of functional activation foci. TD system labels were compared with author-designated labels of activation coordinates from over 250 published functional brain-mapping studies and with manual atlas-derived labels from an expert group using a subset of these activation coordinates. Automated labeling by the TD system compared well with authors' labels, with a 70% or greater label match averaged over all locations. Author-label matching improved to greater than 90% within a search range of +/-5 mm for most sites. An adaptive grey matter (GM) range-search utility was evaluated using individual activations from the M1 mouth region (30 subjects, 52 sites). It provided an 87% label match to Brodmann area labels (BA 4 & BA 6) within a search range of +/-5 mm. Using the adaptive GM range search, the TD system's overall match with authors' labels (90%) was better than that of the expert group (80%). When used in concert with authors' deeper knowledge of an experiment, the TD system provides consistent and comprehensive labels for brain activation foci. Additional suggested applications of the TD system include interactive labeling, anatomical grouping of activation foci, lesion-deficit analysis, and neuroanatomy education.},
author = {Lancaster, Jack L. and Woldorff, Marty G. and Parsons, Lawrence M. and Liotti, Mario and Freitas, Catarina S. and Rainey, Lacy and Kochunov, Peter V. and Nickerson, Dan and Mikiten, Shawn A. and Fox, Peter T.},
doi = {10.1002/1097-0193(200007)10:3<120::AID-HBM30>3.0.CO;2-8},
file = {:Users/gmac/mendeley/Lancaster et al/Lancaster et al. - 2000 - Automated Talairach Atlas labels for functional brain mapping.pdf:pdf},
isbn = {1065-9471 (Print)\r1065-9471 (Linking)},
issn = {10659471},
journal = {Human Brain Mapping},
keywords = {Brain labels,Talairach Daemon,Talairach Labels,Volume occupancy},
number = {3},
pages = {120--131},
pmid = {10912591},
title = {{Automated Talairach Atlas labels for functional brain mapping}},
volume = {10},
year = {2000}
}
@article{Zatorre1979,
abstract = {Four experiments investigated perception of major and minor thirds whose component tones were sounded simultaneously. Effects akin to categorical perception of speech sounds were found. In the first experiment, musicians demonstrated relatively sharp category bound- aries in identification and peaks near the boundary in discrimination tasks of an interval continuum where the bottom note was always an F and the top note varied from A to A flat in seven equal logarithmic steps. Nonmusicians showed these effects only to a small extent. The musicians showed higher than predicted discrimination performance overall, and reaction time increases at category boundaries. In the second experiment, musicians failed to consistently identify or discriminate 'thirds which varied in absolute pitch, but retained the proper inter- val ratio. In the last two experiments, using selective adaptation, consistent shifts were found in both identification and discrimination, similar to those found in speech experiments. Manipulations of adapting and test showed that the mechanism underlying the effect appears to be centrally mediated and confined to a frequency-specific level. A multistage model of interval perception, where the first stages deal only with specific pitches may account for the results.},
author = {Zatorre, Robert J and Halpern, Andrea R},
doi = {10.3758/BF03204164},
file = {:Users/gmac/mendeley/Zatorre, Halpern/Zatorre, Halpern - 1979 - Identification, discrimination, and selective adaptation of simultaneous musical intervals.pdf:pdf},
isbn = {0031-5117 (Print)\r0031-5117 (Linking)},
issn = {0031-5117},
journal = {Perception & psychophysics},
keywords = {Auditory Perception,Humans,Music,Pitch Discrimination},
number = {5},
pages = {384--95},
pmid = {523282},
title = {{Identification, discrimination, and selective adaptation of simultaneous musical intervals.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/523282},
volume = {26},
year = {1979}
}
@article{Crowder1985a,
abstract = {Long sequences of synthetic, sine-wave triads were presented for identification according to three criteria: major/minor, happy/sad, or pleasant/unpleasant. The triads ranged in small steps from the equal-tempered minor to the major mode , and the main performance measure was how identification judgments were affected by the triads' positions along this continuum. The major/minor and happy/sad criteria produced nearly indistinguishable, increasing psychophysical functions; however,judgments of pleasantness followed a different pattern, reaching a minimum halfway between major and minor tunings, perhaps because, at this point, the triads were badly out of tune.},
author = {Crowder, Robert G.},
doi = {10.3758/BF03330169},
file = {:Users/gmac/mendeley/Crowder/Crowder - 1985 - Perception of the majorminor distinction III. Hedonic, musical, and affective discriminations.pdf:pdf},
issn = {00905054},
journal = {Bulletin of the Psychonomic Society},
number = {4},
pages = {314--316},
title = {{Perception of the major/minor distinction: III. Hedonic, musical, and affective discriminations}},
url = {http://download-v2.springer.com/static/pdf/928/art%3A10.3758%2FBF03330169.pdf?token2=exp=1431713136$\sim$acl=/static/pdf/928/art%253A10.3758%252FBF03330169.pdf*$\sim$hmac=2f9bcb0068d6d7a647c613e1ab7b061afcaac4564eaac89d4f48244e9d05a72c},
volume = {23},
year = {1985}
}
@article{Hornickel2013,
author = {Hornickel, J and Kraus, Nina},
file = {:Users/gmac/mendeley/Hornickel, Kraus/Hornickel, Kraus - 2013 - Unstable Representation of Sound A Biological Marker of Dyslexia.pdf:pdf},
journal = {Journal of Neuroscience},
month = {feb},
number = {8},
pages = {3500--3504},
title = {{Unstable Representation of Sound: A Biological Marker of Dyslexia}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4205-12.2013 papers3://publication/doi/10.1523/JNEUROSCI.4205-12.2013},
volume = {33},
year = {2013}
}
@article{Edwards2009,
author = {Edwards, E and Soltani, M and Kim, W and Dalal, S S and Nagarajan, S S and Berger, M S and Knight, R T},
file = {:Users/gmac/mendeley/Edwards et al/Edwards et al. - 2009 - Comparison of Time-Frequency Responses and the Event-Related Potential to Auditory Speech Stimuli in Human Corte.pdf:pdf},
journal = {Journal of Neurophysiology},
month = {jun},
number = {1},
pages = {377--386},
title = {{Comparison of Time-Frequency Responses and the Event-Related Potential to Auditory Speech Stimuli in Human Cortex}},
url = {http://jn.physiology.org/cgi/doi/10.1152/jn.90954.2008 papers3://publication/doi/10.1152/jn.90954.2008},
volume = {102},
year = {2009}
}
@article{Ball2012,
author = {Ball, Laura C},
file = {:Users/gmac/mendeley/Ball/Ball - 2012 - Genius without the “Great Man”New possibilities for the historian of psychology.pdf:pdf},
journal = {History of Psychology},
month = {jan},
number = {1},
pages = {72--83},
title = {{Genius without the “Great Man”:New possibilities for the historian of psychology.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0023247},
volume = {15},
year = {2012}
}
@article{Young1997,
abstract = {We report four experiments investigating the perception of photographic quality continua of interpolated ('morphed') facial expressions derived from prototypes of the 6 emotions in the Ekman and Friesen (1976) series (happiness, surprise, fear, sadness, disgust and anger). In Experiment 1, morphed images made from all possible pairwise combinations of expressions were presented in random order; subjects identified these as belonging to distinct expression categories corresponding to the prototypes at each end of the relevant continuum. This result was replicated in Experiment 2, which also included morphs made from a prototype with a neutral expression, and allowed 'neutral' as a response category. These findings are inconsistent with the view that facial expressions are recognised by locating them along two underlying dimensions, since such a view predicts that at least some transitions between categories should involve neutral regions or identification as a different emotion. Instead, they suggest that facial expressions of basic emotions are recognised by their fit to discrete categories. Experiment 3 used continua involving 6 emotions to demonstrate best discrimination of pairs of stimuli falling across category boundaries; this provides further evidence of categorical perception of facial expressions of emotion. However, in both Experiment 1 and Experiment 2, reaction time data showed that increasing distance from the prototype had a definite cost on ability to identify emotion in the resulting morphed face. Moreover, Experiment 4 showed that subjects had some insight into which emotions were blended to create specific morphed images. Hence, categorical perception effects were found even though subjects were sensitive to physical properties of these morphed facial expressions. We suggest that rapid classification of prototypes and better across boundary discriminability reflect the underlying organisation of human categorisation abilities.},
author = {Young, Andrew W. and Rowland, Duncan and Calder, Andrew J. and Etcoff, Nancy L. and Seth, a and Perrett, D I},
doi = {10.1016/S0010-0277(97)00003-6},
file = {:Users/gmac/mendeley/Young et al/Young et al. - 1997 - Facial expression megamix tests of dimensional and category accounts of emotion recognition.pdf:pdf},
isbn = {0010-0277},
issn = {0010-0277},
journal = {Cognition},
keywords = {Adult,Analysis of Variance,Discrimination (Psychology),Discrimination (Psychology): physiology,Emotions,Emotions: classification,Facial Expression,Humans,Matched-Pair Analysis,Middle Aged,Pattern Recognition,Social Perception,Visual,Visual: physiology},
number = {3},
pages = {271--313},
pmid = {9265872},
title = {{Facial expression megamix: tests of dimensional and category accounts of emotion recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9265872},
volume = {63},
year = {1997}
}
@article{Webster2005,
author = {Webster, Gregory D and Weir, Catherine G},
file = {:Users/gmac/mendeley/Webster, Weir/Webster, Weir - 2005 - Emotional Responses to Music Interactive Effects of Mode, Texture, and Tempo.pdf:pdf},
journal = {Motivation and Emotion},
month = {mar},
number = {1},
pages = {19--39},
title = {{Emotional Responses to Music: Interactive Effects of Mode, Texture, and Tempo}},
url = {http://link.springer.com/10.1007/s11031-005-4414-0 papers3://publication/doi/10.1007/s11031-005-4414-0},
volume = {29},
year = {2005}
}
@article{Fairhurst2012,
author = {Fairhurst, M T and Janata, Petr and Keller, P E},
file = {:Users/gmac/mendeley/Fairhurst, Janata, Keller/Fairhurst, Janata, Keller - 2012 - Being and Feeling in Sync with an Adaptive Virtual Partner Brain Mechanisms Underlying Dynamic Cooper.pdf:pdf},
journal = {Cerebral Cortex},
keywords = {DMN,tapping},
month = {aug},
title = {{Being and Feeling in Sync with an Adaptive Virtual Partner: Brain Mechanisms Underlying Dynamic Cooperativity}},
url = {http://www.cercor.oxfordjournals.org/cgi/doi/10.1093/cercor/bhs243 papers3://publication/doi/10.1093/cercor/bhs243},
year = {2012}
}
@article{Heyduk1975,
abstract = {Subjects heard four piano compositions that were constructed to represent differing degrees of complexity, as defined by their chordal and rhythmic properties and corroborated by subjects' complexity ratings. In line with the predictions of an optimal complexity model of musical preference. judged liking for the compositions was a unimodal function of their complexity. After each composition was rated for liking, one of the four compositions was presented and rated an additional 16 times. Also congruent with an optimal complexity model was the finding- that the affective consequences of repeated exposure varied depending upon whether the repeatedly exposed composition was more or less complex than the subject's preferred complexity level. The latter finding suggests that repeated exposure effects are a function of both situational and individual factors.},
author = {Heyduk, Ronald. G},
doi = {10.3758/BF03204003},
file = {:Users/gmac/mendeley/Heyduk/Heyduk - 1975 - Rated preference for musical compositions as it relates to complexity and exposure frequency.pdf:pdf},
isbn = {0031-5117 1532-5962},
issn = {00315117},
journal = {Perception & Psychophysics},
number = {1},
pages = {84--91},
title = {{Rated preference for musical compositions as it relates to complexity and exposure frequency}},
volume = {17},
year = {1975}
}
@article{Stevens1886,
author = {Stevens, Lewis T},
file = {:Users/gmac/mendeley/Stevens/Stevens - 1886 - On The Time-Sense.pdf:pdf},
journal = {Mind},
month = {jul},
pages = {393--404},
title = {{On The Time-Sense}},
url = {http://www.jstor.org.ezproxy.lib.ryerson.ca/stable/2247079 papers3://publication/uuid/D7C40D0A-41D1-406E-872E-424FBF16C8C4},
volume = {11},
year = {1886}
}
@article{Chisolm2007,
abstract = {This is the final report of the American Academy of Audiology Task Force on the Health-Related Quality of Life (HRQoL) Benefits of Amplification in Adults. A systematic review with meta-analysis examined evidence pertaining to the use of hearing aids for improving HRQoL for adults with sensorineural hearing loss (SNHL). Relevant search strings applied to the CENTRAL, CINAHL, Cochrane Reviews, ComDisDome, EBMR, and PubMed databases identified randomized controlled trial, quasi-experimental, and nonexperimental pre- post test designed studies. Sixteen studies met a priori criteria for inclusion in this review. A random-effects meta-analysis showed differential results for generic versus disease-specific HRQoL measures for within- and between- subject designs. Although generic measures used for within-subject designs did not demonstrate HRQoL benefits from hearing aids, mean effect sizes and confidence intervals for within-subject designs and disease-specific instruments suggested that hearing aids have a small-to-medium impact on HRQoL. Further, the between-subject studies supported at least a small effect for generic measures, and when measured by disease-specific instruments, hearing aids had medium-to-large effects on adults' HRQoL. This review concludes that hearing aids improve adults'HRQoLby reducing psychological, social, and emotional effects of SNHL. Future studies should include control groups using randomized controlled trials.},
author = {Chisolm, Theresa Hnath and Johnson, Carole E and Danhauer, Jeffrey L and Portz, Laural J P and Abrams, Harvey B and Lesner, Sharon and Mccarthy, Patricia A and Newman, Craig W},
doi = {10.3766/jaaa.18.2.7},
file = {:Users/gmac/mendeley/Chisolm et al/Chisolm et al. - 2007 - A systematic review of health-related quality of life and hearing aids final report of the American Academy of A.pdf:pdf},
journal = {Journal of the American Academy of Audiology},
keywords = {american academy of audiology on the benefits of a,hearing aids,hearing loss,meta-analysis,nonacoustic benefits,systematic review},
number = {2},
pages = {151--183},
title = {{A systematic review of health-related quality of life and hearing aids: final report of the American Academy of Audilogy Task Force on the health-related quality of life benefits of amplification in adults}},
volume = {18},
year = {2007}
}
@article{Robin2003,
abstract = {The early careers of French doctors in life sciences are characterized by the importance of temporary jobs. While most young Ph.D. researchers wish to obtain a job in the French academic sector (which grants them, among other things, lifetime employment), few of them manage to achieve this objective immediately after completing their Ph.D. A majority of young doctors have to wait for a period of time before they find stable employment in the academic sector. In the meantime, they usually find temporary research jobs. Two main types of short–term jobs can be distinguished: fixed–term research contracts (in most cases in a French public laboratory) and post–doctoral positions (temporary research jobs in a foreign country). The aim of this paper is to determine whether these different types of temporary jobs have different consequences on the careers of Ph.D. researchers.  We first discuss from a theoretical perspective the impact of choosing ‘post–doc' research rather than a job on a fixed–term contract. Then, after dealing with selection biases that affect the access to these temporary jobs, we will use survival data analysis to estimate the impact of both types of temporary positions on the probability of entering the academic sector. The analysis is based on a database on the early careers of 800 young French doctors in life sciences. The main results include the following findings: the probability of a Ph.D. researcher finding stable employment is higher if he has held a post–doc position than if he has held a fixed–term contract. This result holds for both the private and public sectors. However, careers in the private sector are also affected by long–term choices, such as the decision to undertake Ph.D. research in partnership with a firm.},
author = {Robin, S. and Cahuzac, E.},
doi = {10.1111/1467-9914.00219},
file = {:Users/gmac/mendeley/Robin, Cahuzac/Robin, Cahuzac - 2003 - Knocking on Academia's Doors An Inquiry into the Early Careers of Doctors in Life Sciences.pdf:pdf},
issn = {1121-7081},
journal = {Labour},
number = {1},
pages = {1--23},
title = {{Knocking on Academia's Doors: An Inquiry into the Early Careers of Doctors in Life Sciences}},
url = {http://doi.wiley.com/10.1111/1467-9914.00219},
volume = {17},
year = {2003}
}
@article{Scherer2004,
annote = {- utilitarian vs aesthetic emotions
- music (usually) elicits aesthetic emotions which are not goal-oriented},
author = {Scherer, Klaus R},
file = {:Users/gmac/mendeley/Scherer/Scherer - 2004 - Which Emotions Can be Induced by Music What Are the Underlying Mechanisms And How Can We Measure Them.pdf:pdf},
journal = {Journal of New Music Research},
month = {sep},
number = {3},
pages = {239--251},
title = {{Which Emotions Can be Induced by Music? What Are the Underlying Mechanisms? And How Can We Measure Them?}},
url = {http://www.tandfonline.com/doi/abs/10.1080/0929821042000317822 papers3://publication/doi/10.1080/0929821042000317822},
volume = {33},
year = {2004}
}
@article{Doesburg2009,
abstract = {When attention is allocated to one visual hemifield, increased alpha power is observed in ipsilateral visual cortex. This has been attributed to synchronization of alpha-band oscillations within cortical regions which reflects inhibitory processing. Recent results, however, indicate that synchronization of alpha oscillations between cortical regions is relevant for transient functional coupling. Such coupling is thought to be involved in orienting attention to a specific region of the visual field. We thus hypothesized that alpha-band synchronization between low-level visual cortex and higher-level visual brain regions would be increased in the hemisphere contralateral to an attended location. To test this hypothesis we calculated phase synchronization between attention-related EEG source activations occurring between predictive directional cues and expected visual targets. Alpha amplitude (understood as an index of local synchronization) within low-level visual cortex was increased ipsilateral to attended locations and decreased contralateral to attended locations, consistent with alpha-band scalp topography and previous research relating local alpha power to active inhibition. Increased long-range alpha-band synchronization between low-level visual cortex and parietal cortex, however, was observed contralateral to the attended visual hemifield, whereas decreased synchronization (phase scattering) was observed in the ipsilateral hemisphere. These results identify a potential mechanism for the enhanced processing of stimuli appearing at attended locations, as long-range synchronization is thought to increase the fidelity and effectiveness of communication between brain areas. Our observation of inhibitory amplitude changes, interpreted as increased local-area synchronization, and facilitatory long-range synchronization demonstrates a functional dissociation for alpha-band synchronization across cortical scales. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Doesburg, Sam M. and Green, Jessica J and McDonald, John J. and Ward, Lawrence M.},
doi = {10.1016/j.brainres.2009.09.069},
file = {:Users/gmac/mendeley/Doesburg et al/Doesburg et al. - 2009 - From local inhibition to long-range integration A functional dissociation of alpha-band synchronization across.pdf:pdf},
isbn = {0006-8993},
issn = {00068993},
journal = {Brain Research},
keywords = {Alpha-band,Functional integration,Inhibition,Neural synchrony,Oscillatory dynamics,Selective attention},
pages = {97--110},
pmid = {19782056},
publisher = {Elsevier B.V.},
title = {{From local inhibition to long-range integration: A functional dissociation of alpha-band synchronization across cortical scales in visuospatial attention}},
volume = {1303},
year = {2009}
}
@article{Aiken2006,
author = {Aiken, Steven J and Picton, Terence W},
file = {:Users/gmac/mendeley/Aiken, Picton/Aiken, Picton - 2006 - Envelope Following Responses to Natural Vowels.pdf:pdf},
journal = {Audiology and Neurotology},
month = {jan},
number = {4},
pages = {213--232},
title = {{Envelope Following Responses to Natural Vowels}},
url = {http://www.karger.com/doi/10.1159/000092589 papers3://publication/doi/10.1159/000092589},
volume = {11},
year = {2006}
}
@article{Aarts2013,
abstract = {Major depressive disorder (MDD) is characterized by disturbances in affect, motivation, and cognitive control processes, including error detection. However, the expression and timing of the impairments during error monitoring remain unclear in MDD. The behavior and event-related brain responses (ERPs) of 20 patients with MDD were compared with those of 20 healthy controls (HCs), while they performed a Go/noGo task. Errors during this task were associated with 2 ERP components, the error-related negativity (ERN/Ne) and the error positivity (Pe). Results show that the ERN/Ne-correct-related negativity (CRN) amplitude difference was significantly larger in MDD patients (after controlling for speed), compared with HCs, although MDD patients exhibited overactive medial frontal cortex (MFC) activation. By comparison, the subsequent Pe component was smaller in MDD patients compared with HCs and this effect was accompanied by a reduced activation of ventral anterior cingulate cortex (ACC) regions. These results suggest that MDD has multiple cascade effects on early error monitoring brain mechanisms.},
address = {Department of Experimental Clinical and Health Psychology, Ghent University.},
author = {Aarts, Kristien and Vanderhasselt, Marie-Anne and Otte, Georges and Baeken, Chris and Pourtois, Gilles},
file = {:Users/gmac/mendeley/Aarts et al/Aarts et al. - 2013 - Electrical brain imaging reveals the expression and timing of altered error monitoring functions in major depressi.pdf:pdf},
journal = {Journal of abnormal psychology},
month = {nov},
number = {4},
pages = {939--950},
title = {{Electrical brain imaging reveals the expression and timing of altered error monitoring functions in major depression.}},
url = {http://psycnet.apa.org/journals/abn/122/4/939/ papers3://publication/doi/10.1037/a0034616},
volume = {122},
year = {2013}
}
@article{DeBruin2010,
author = {de Bruin, Natalie and Doan, Jon B and Turnbull, George and Suchowersky, Oksana and Bonfield, Stephan and Hu, Bin and Brown, Lesley A},
file = {:Users/gmac/mendeley/de Bruin et al/de Bruin et al. - 2010 - Walking with Music Is a Safe and Viable Tool for Gait Training in Parkinson's Disease The Effect of a 13-Week F.pdf:pdf},
journal = {Parkinson's Disease},
month = {jan},
number = {2},
pages = {1--9},
title = {{Walking with Music Is a Safe and Viable Tool for Gait Training in Parkinson's Disease: The Effect of a 13-Week Feasibility Study on Single and Dual Task Walking}},
url = {http://www.hindawi.com/journals/pd/2010/483530/ papers3://publication/doi/10.1016/j.apmr.2008.09.559},
volume = {2010},
year = {2010}
}
@article{Longuet-Higgins1984,
abstract = {The assignment of a rhythmic interpretation to a piece of metrical music calls for the postulation of an underlying meter and the parsing of the note values according to this meter. In this article we develop the implica- tions of this view, which include the following propositions. 1. Any given sequence of note values is in principle rhythmically ambiguous, although this ambiguity is seldom apparent to the listener. 2. In choosing a rhythmic interpretation for a given note sequence the listener seems to be guided by a strong assumption: if the sequence can be interpreted as the realization of an unsynco- pated passage, then that is how he will interpret it. 3. Phrasing can make an important difference to the rhythmic interpretation that the listener assigns to a given sequence. Phrasing can therefore serve a structural function as well as a purely ornamental one.},
author = {Longuet-Higgins, H.C. and Lee, C.S.},
doi = {10.2307/40285271},
file = {:Users/gmac/mendeley/Longuet-Higgins, Lee/Longuet-Higgins, Lee - 1984 - The rhythmic interpretation of monophonic music.pdf:pdf},
isbn = {07307829},
issn = {07307829},
journal = {Music Perception},
number = {4},
pages = {424--440},
title = {{The rhythmic interpretation of monophonic music}},
volume = {1},
year = {1984}
}
@article{Ross2011,
author = {Ross, Elliott D and Monnot, Marilee},
doi = {10.1016/j.neuropsychologia.2010.12.024},
file = {:Users/gmac/mendeley/Ross, Monnot/Ross, Monnot - 2010 - Affective prosody What do comprehension errors tell us about hemispheric lateralization of emotions , sex and agi.pdf:pdf},
issn = {0028-3932},
journal = {Neuropsychologia},
number = {5},
pages = {866--877},
publisher = {Elsevier Ltd},
title = {{Affective prosody : What do comprehension errors tell us about hemispheric lateralization of emotions , sex and aging effects , and ... appraisal}},
volume = {49},
year = {2010}
}
@article{Lachaux1999,
abstract = {This article presents, for the first time, a practical method for the direct quantification of frequency-specific synchronization (i.e., transient phase-locking) between two neuroelectric signals. The motivation for its development is to be able to examine the role of neural synchronies as a putative mechanism for long-range neural integration during cognitive tasks. The method, called phase-locking statistics (PLS), measures the significance of the phase covariance between two signals with a reasonable time-resolution (<100 ms). Unlike the more traditional method of spectral coherence, PLS separates the phase and amplitude components and can be directly interpreted in the framework of neural integration. To validate synchrony values against background fluctuations, PLS uses surrogate data and thus makes no a priori assumptions on the nature of the experimental data. We also apply PLS to investigate intracortical recordings from an epileptic patient performing a visual discrimination task. We find large-scale synchronies in the gamma band (45 Hz), e.g., between hippocampus and frontal gyrus, and local synchronies, within a limbic region, a few cm apart. We argue that whereas long-scale effects do reflect cognitive processing, short-scale synchronies are likely to be due to volume conduction. We discuss ways to separate such conduction effects from true signal synchrony.},
address = {Laboratoire de Neurosciences Cognitives et Imagerie C{\'{e}}r{\'{e}}brale, CNRS UPR 40 H{\^{o}}pital de La Salp{\^{e}}tri{\`{e}}re, Paris, France.},
author = {Lachaux, J P and Rodriguez, E and Martinerie, J and Varela, F J},
file = {:Users/gmac/mendeley/Lachaux et al/Lachaux et al. - 1999 - Measuring phase synchrony in brain signals.pdf:pdf},
journal = {Human Brain Mapping},
month = {jan},
number = {4},
pages = {194--208},
title = {{Measuring phase synchrony in brain signals.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=10619414&retmode=ref&cmd=prlinks papers3://publication/uuid/44F23FF2-F96A-4A9E-A45A-E1C3ABCDF7A3},
volume = {8},
year = {1999}
}
@article{Hausdorff2007,
author = {Hausdorff, Jeffrey M and Lowenthal, Justine and Herman, Talia and Gruendlinger, Leor and Peretz, Chava and Giladi, Nir},
file = {:Users/gmac/mendeley/Hausdorff et al/Hausdorff et al. - 2007 - Rhythmic auditory stimulation modulates gait variability in Parkinson's disease.pdf:pdf},
journal = {European Journal of Neuroscience},
month = {oct},
number = {8},
pages = {2369--2375},
title = {{Rhythmic auditory stimulation modulates gait variability in Parkinson's disease}},
url = {http://doi.wiley.com/10.1111/j.1460-9568.2007.05810.x papers3://publication/doi/10.1111/j.1460-9568.2007.05810.x},
volume = {26},
year = {2007}
}
@article{Mullensiefen2014,
author = {M{\"{u}}llensiefen, Daniel and Gingras, Bruno and Musil, Jason and Stewart, Lauren},
file = {:Users/gmac/mendeley/M{\"{u}}llensiefen et al/M{\"{u}}llensiefen et al. - 2014 - The Musicality of Non-Musicians An Index for Assessing Musical Sophistication in the General Population.pdf:pdf},
journal = {PLoS ONE},
month = {feb},
number = {2},
pages = {1--23},
title = {{The Musicality of Non-Musicians: An Index for Assessing Musical Sophistication in the General Population}},
url = {papers3://publication/doi/10.1371/journal.pone.0089642},
volume = {9},
year = {2014}
}
@article{Aviezer2008,
abstract = {Current theories of emotion perception posit that basic facial expressions signal categorically discrete emotions or affective dimensions of valence and arousal. In both cases, the information is thought to be directly "read out" from the face in a way that is largely immune to context. In contrast, the three studies reported here demonstrated that identical facial configurations convey strikingly different emotions and dimensional values depending on the affective context in which they are embedded. This effect is modulated by the similarity between the target facial expression and the facial expression typically associated with the context. Moreover, by monitoring eye movements, we demonstrated that characteristic fixation patterns previously thought to be determined solely by the facial expression are systematically modulated by emotional context already at very early stages of visual processing, even by the first time the face is fixated. Our results indicate that the perception of basic facial expressions is not context invariant and can be categorically altered by context at early perceptual levels.},
address = {Department of Psychology, Hebrew University of Jerusalem, Jerusalem 91905, Israel. hillel.aviezer@mail.huji.ac.il},
author = {Aviezer, Hillel and Hassin, Ran R and Ryan, Jennifer and Grady, Cheryl and Susskind, Josh and Anderson, Adam and Moscovitch, Morris and Bentin, Shlomo},
file = {:Users/gmac/mendeley/Aviezer et al/Aviezer et al. - 2008 - Angry, disgusted, or afraid Studies on the malleability of emotion perception.pdf:pdf},
journal = {Psychological Science},
month = {jul},
number = {7},
pages = {724--732},
title = {{Angry, disgusted, or afraid? Studies on the malleability of emotion perception.}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/j.1467-9280.2008.02148.x papers3://publication/doi/10.1111/j.1467-9280.2008.02148.x},
volume = {19},
year = {2008}
}
@article{Nyberg2012,
abstract = {Trends in Cognitive Sciences, 16 (2012) 292-305. 10.1016/j.tics.2012.04.005},
author = {Nyberg, Lars and L{\"{o}}vd{\'{e}}n, Martin and Riklund, Katrine and Lindenberger, Ulman and B{\"{a}}ckman, Lars},
file = {:Users/gmac/mendeley/Nyberg et al/Nyberg et al. - 2012 - Memory aging and brain maintenance.pdf:pdf},
journal = {Trends in Cognitive Sciences},
month = {may},
number = {5},
pages = {292--305},
publisher = {Elsevier Ltd},
title = {{Memory aging and brain maintenance}},
url = {http://dx.doi.org/10.1016/j.tics.2012.04.005 papers3://publication/doi/10.1016/j.tics.2012.04.005},
volume = {16},
year = {2012}
}
@article{Baldwin1896,
annote = {ontogeny
- physico-genetic
- neuro-genetic
- psycho-genetic},
author = {Baldwin, J Mark},
file = {:Users/gmac/mendeley/Baldwin/Baldwin - 1896 - A New Factor in Evolution.pdf:pdf},
journal = {The American Naturalist},
month = {jun},
pages = {441--451},
title = {{A New Factor in Evolution}},
url = {http://www.jstor.org.ezproxy.lib.ryerson.ca/stable/2453130?seq=2 papers3://publication/uuid/C73D3AF1-78D4-4A98-B0E5-820FD8DBD5AE},
volume = {30},
year = {1896}
}
@article{Darwin2010,
author = {Darwin, Charles},
file = {:Users/gmac/mendeley/Darwin/Darwin - 2010 - A Biographical Sketch of an Infant.pdf:pdf},
journal = {Annals of Neurosciences},
month = {oct},
number = {4},
title = {{A Biographical Sketch of an Infant}},
url = {http://www.annalsofneurosciences.org/journal/index.php/annal/article/view/272 papers3://publication/doi/10.5214/ans.0972.7531.1017409},
volume = {17},
year = {2010}
}
@article{Bones2015,
author = {Bones, O and Plack, C J},
file = {:Users/gmac/mendeley/Bones, Plack/Bones, Plack - 2015 - Losing the Music Aging Affects the Perception and Subcortical Neural Representation of Musical Harmony.pdf:pdf},
journal = {Journal of Neuroscience},
month = {mar},
number = {9},
pages = {4071--4080},
title = {{Losing the Music: Aging Affects the Perception and Subcortical Neural Representation of Musical Harmony}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3214-14.2015 papers3://publication/doi/10.1523/JNEUROSCI.3214-14.2015},
volume = {35},
year = {2015}
}
@incollection{Russo2014,
author = {Russo, Frank A and Liskovoi, Lisa},
booktitle = {Music in the Social and Behavioral Science: An Encyclopedia},
editor = {Thompson, William Forde},
file = {:Users/gmac/mendeley/Russo, Liskovoi/Russo, Liskovoi - 2014 - Physiological Responses, Peripheral.pdf:pdf},
isbn = {9781452283036},
pages = {862--865},
publisher = {SAGE Publications},
title = {{Physiological Responses, Peripheral}},
year = {2014}
}
@article{Manning2015,
author = {Manning, Fiona C and Schutz, Michael},
file = {:Users/gmac/mendeley/Manning, Schutz/Manning, Schutz - 2015 - Movement Enhances Perceived Timing in the Absence of Auditory Feedback.pdf:pdf},
journal = {Timing & Time Perception},
month = {may},
number = {1-2},
pages = {3--12},
title = {{Movement Enhances Perceived Timing in the Absence of Auditory Feedback}},
url = {http://booksandjournals.brillonline.com/content/journals/10.1163/22134468-03002037 papers3://publication/doi/10.1163/22134468-03002037},
volume = {3},
year = {2015}
}
@article{Ammirante2016,
abstract = {Humans show a striking advantage for synchronizing movements with discretely-timed auditory metronomes (e.g., clicking sounds) over temporally-matched visual metronomes (e.g., flashing lights), suggesting enhanced auditory-motor coupling for rhythmic processing. Does the auditory advantage persist for other modalities (not just vision)? Here non-musicians finger-tapped to the beat of auditory, tactile, and bimodal metronomes. Stimulus magnitude and rhythmic complexity were also manipulated. In conditions involving a large area of stimulation and simple rhythmic sequences, a slight tactile advantage was found (albeit a non-significant one). While this finding offers a challenge to the hypothesis of enhanced auditory-motor coupling for rhythmic processing, other findings clearly support it. First, performance was nearly identical between auditory and bimodal conditions on all dependent measures. This suggests that, rather than integrating information across modalities, participants timed their movements with the presumably more reliable auditory cue. Second, there was a robust advantage with auditory information for synchronization with complex rhythm sequences; moreover, in complex sequences a statistical index of error correction was found only when auditory information was present. Finally, higher order grouping was evident only when auditory information was present.},
author = {Ammirante, P and Patel, A D and Russo, Frank A},
doi = {10.3758/s13423-016-1067-9},
file = {:Users/gmac/mendeley/Ammirante, Patel, Russo/Ammirante, Patel, Russo - 2016 - Synchronizing to auditory and tactile metronomes a test of the auditory-motor enhancement hypothesis.pdf:pdf},
isbn = {1972952943},
issn = {1069-9384},
journal = {Psychonomic bulletin & review},
keywords = {Sensorimotor synchronization,Vibrotactile percepti,sensorimotor synchronization,vibrotactile},
pages = {0--34},
pmid = {27246088},
title = {{Synchronizing to auditory and tactile metronomes: a test of the auditory-motor enhancement hypothesis}},
url = {http://dx.doi.org/10.3758/s13423-016-1067-9},
volume = {under revi},
year = {2016}
}
@article{Dupuis2010,
annote = {- measure of interest was the number of sentences in which the participants' choice of emotion was consistent with affective prosody
- speaker was 25 years old - just like the young group and unlike the old group (need age-matched groups)
- forced choice -- do they REALLY know what emotion is being expressed? (need more emotions)

Expt 1:
- discriminate happy/sad sentences
- happy/sad prosody was in/congruent with semantic content
- old/young equal for congruent; both worse for incongruent, esp happy prosody; old esp worse for incongruent
- interaction between congruency x age
- RT was equal, % of sentence heard before response was equal

Expt 2:
- read/repeated sentences prior to responding happy/sad
- no interaction between congruency x age: repeating sentences increased consistency of older adults' responses
- "While sad sentences were produced more slowly than happy sentences, participants responded faster to sad than to happy sentences, suggesting that more time was required to choose, prepare, or execute a response to the happy sentences." (p.23) --> ignores the possibility of processing occurring during repetition
- happy sentences were shorter, louder, higher pitch
- "Thus, the age-related inconsistencies in discriminating emotion reported in Experiment 1, especially when the cues were incongruent, seem to be related more to cognitive slowing than to auditory aging or age-related differences in the ability to produce affective prosody" (p.24)

Expt 3:
- postpone repetition until after response, or pause for 4s before response
- increased time on incongruent for older to respond didn't increase performance},
author = {Dupuis, Kate and Pichora-Fuller, M Kathleen},
file = {:Users/gmac/mendeley/Dupuis, Pichora-Fuller/Dupuis, Pichora-Fuller - 2010 - Use of affective prosody by young and older adults.pdf:pdf},
journal = {Psychology and Aging},
month = {jan},
number = {1},
pages = {16--29},
title = {{Use of affective prosody by young and older adults.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0018777 papers3://publication/doi/10.1037/a0018777},
volume = {25},
year = {2010}
}
@incollection{Scherer2001,
address = {New York},
author = {Scherer, Klaus R and Zentner, M R},
booktitle = {Music and emotion: Theory and research},
editor = {Juslin, Patrik N and Sloboda, John A},
month = {jan},
pages = {361--392},
publisher = {Oxford University Press},
title = {{Emotional effects of music: production rules BT  - Music and emotion: Theory and research}},
url = {papers3://publication/uuid/92DD7BB0-574B-4A24-9EB1-1F9713D2D009},
year = {2001}
}
@article{Russo2007,
author = {Russo, Frank A and Jones, Jeffery A},
file = {:Users/gmac/mendeley/Russo, Jones/Russo, Jones - 2007 - Urgency is a non-monotonic function of pulse rate.pdf:pdf},
journal = {The Journal of the Acoustical Society of America},
month = {jan},
number = {5},
pages = {EL185},
title = {{Urgency is a non-monotonic function of pulse rate}},
url = {http://scitation.aip.org/content/asa/journal/jasa/122/5/10.1121/1.2784112 papers3://publication/doi/10.1121/1.2784112},
volume = {122},
year = {2007}
}
@article{Lancaster1997,
abstract = {A forward-transform method for retrieving brain labels from the 1988 Talairach Atlas using x-y-z coordinates is presented. A hierarchical volume-occupancy labeling scheme was created to simplify the organization of atlas labels using volume and subvolumetric components. Segmentation rules were developed to define boundaries that were not given explicitly in the atlas. The labeling scheme and segmentation rules guided the segmentation and labeling of 160 contiguous regions within the atlas. A unique three-dimensional (3-D) database label server called the Talairach Daemon (http://ric.uthscsa.edu/projects) was developed for serving labels keyed to the Talairach coordinate system. Given an x-y-z Talairach coordinate, a corresponding hierarchical listing of labels is returned by the server. The accuracy and precision of the forward-transform labeling method is now under evaluation.},
author = {Lancaster, Jack L. and Rainey, Lacy and Summerlin, J. L. and Freitas, Catarina S. and Fox, Peter T. and Evans, A. C. and Toga, A. W. and Mazziotta, J. C.},
doi = {10.1002/(SICI)1097-0193(1997)5:4<238::AID-HBM6>3.0.CO;2-4},
file = {:Users/gmac/mendeley/Lancaster et al/Lancaster et al. - 1997 - Automated labeling of the human brain A preliminary report on the development and evaluation of a forward-tran.pdf:pdf},
isbn = {1065-9471 (Print)\r1065-9471 (Linking)},
issn = {10659471},
journal = {Human Brain Mapping},
keywords = {Brain labeling,Naming hierarchy,Segmentation,Spatial normalization,Talairach Daemon,Talairach' Atlas},
number = {4},
pages = {238--242},
pmid = {20408222},
title = {{Automated labeling of the human brain: A preliminary report on the development and evaluation of a forward-transform method}},
volume = {5},
year = {1997}
}
@article{Ermolaeva1980,
author = {Ermolaeva, V Yu and Borgest, A N},
file = {:Users/gmac/mendeley/Ermolaeva, Borgest/Ermolaeva, Borgest - 1980 - Intercortical connections of the auditory areas with the motor area.pdf:pdf},
journal = {Neuroscience and Behavioral Physiology},
month = {jan},
number = {3},
pages = {210--215},
title = {{Intercortical connections of the auditory areas with the motor area}},
url = {http://download.springer.com.myaccess.library.utoronto.ca/static/pdf/181/art%253A10.1007%252FBF01182212.pdf?auth66=1385501421_8bd2ead8db0bac924b961537dbd52cdc&ext=.pdf papers3://publication/uuid/5F578992-1E00-44F4-B685-232FC8375E53},
volume = {10},
year = {1980}
}
@article{Gerken1975,
author = {Gerken, George M and Moushegian, George and Stillman, Robert D and Rupert, Allen L},
file = {:Users/gmac/mendeley/Gerken et al/Gerken et al. - 1975 - Human Frequency-Following Responses to Monaural and Binaural Stimuli.pdf:pdf},
journal = {Electroencephalography and Clinical Neurophysiology},
month = {jan},
pages = {379--386},
title = {{Human Frequency-Following Responses to Monaural and Binaural Stimuli}},
url = {papers3://publication/uuid/B31B1A59-5144-4BD8-91C7-48AC66B34BFF},
volume = {38},
year = {1975}
}
@article{Merletti2015,
author = {Merletti, Author Roberto and Torino, Politecnico},
doi = {10.1016/S1050-6411(15)00177-7},
file = {:Users/gmac/mendeley/Merletti, Torino/Merletti, Torino - 2015 - Standards for Reporting EMG Data.pdf:pdf},
issn = {10506411},
journal = {Journal of Electromyography and Kinesiology},
number = {5},
pages = {I--II},
title = {{Standards for Reporting EMG Data}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1050641115001777},
volume = {25},
year = {2015}
}
@book{Stumpf1890,
author = {Stumpf, Carl},
month = {jan},
publisher = {Hirzel},
title = {{No Title}},
url = {papers3://publication/uuid/1C690FD6-135A-40E1-B730-F41673403A31},
year = {1890}
}
@article{Kothe2013,
abstract = {OBJECTIVE: The past two decades have seen dramatic progress in our ability to model brain signals recorded by electroencephalography, functional near-infrared spectroscopy, etc., and to derive real-time estimates of user cognitive state, response, or intent for a variety of purposes: to restore communication by the severely disabled, to effect brain-actuated control and, more recently, to augment human-computer interaction. Continuing these advances, largely achieved through increases in computational power and methods, requires software tools to streamline the creation, testing, evaluation and deployment of new data analysis methods.\n\nAPPROACH: Here we present BCILAB, an open-source MATLAB-based toolbox built to address the need for the development and testing of brain-computer interface (BCI) methods by providing an organized collection of over 100 pre-implemented methods and method variants, an easily extensible framework for the rapid prototyping of new methods, and a highly automated framework for systematic testing and evaluation of new implementations.\n\nMAIN RESULTS: To validate and illustrate the use of the framework, we present two sample analyses of publicly available data sets from recent BCI competitions and from a rapid serial visual presentation task. We demonstrate the straightforward use of BCILAB to obtain results compatible with the current BCI literature.\n\nSIGNIFICANCE: The aim of the BCILAB toolbox is to provide the BCI community a powerful toolkit for methods research and evaluation, thereby helping to accelerate the pace of innovation in the field, while complementing the existing spectrum of tools for real-time BCI experimentation, deployment and use.},
author = {Kothe, Christian Andreas and Makeig, Scott},
doi = {10.1088/1741-2560/10/5/056014},
file = {:Users/gmac/mendeley/Kothe, Makeig/Kothe, Makeig - 2013 - BCILAB a platform for brain-computer interface development.pdf:pdf},
isbn = {1741-2560},
issn = {1741-2552},
journal = {Journal of neural engineering},
keywords = {Algorithms,Artifacts,Automation,Brain-Computer Interfaces,Calibration,Computer Graphics,Computer Systems,Data Interpretation, Statistical,Electroencephalography,Electroencephalography: statistics & numerical dat,Evoked Potentials,Evoked Potentials: physiology,Humans,Imagination,Imagination: physiology,Models, Neurological,Neurosciences,Photic Stimulation,Prosthesis Design,Reproducibility of Results,Software,User-Computer Interface},
number = {5},
pages = {056014},
pmid = {23985960},
title = {{BCILAB: a platform for brain-computer interface development.}},
url = {http://stacks.iop.org/1741-2552/10/i=5/a=056014},
volume = {10},
year = {2013}
}
@article{Juslin2011,
author = {Juslin, Patrik N and Lindstr{\"{o}}m, Erik},
file = {:Users/gmac/mendeley/Juslin, Lindstr{\"{o}}m/Juslin, Lindstr{\"{o}}m - 2011 - Musical Expression of Emotions Modelling Listeners' Judgements of Composed and Performed Features.pdf:pdf},
journal = {Music Analysis},
month = {oct},
number = {1-3},
pages = {334--364},
publisher = {Blackwell Publishing Ltd},
title = {{Musical Expression of Emotions: Modelling Listeners' Judgements of Composed and Performed Features}},
url = {http://doi.wiley.com/10.1111/j.1468-2249.2011.00323.x},
volume = {29},
year = {2011}
}
@article{Musacchia2007,
author = {Musacchia, Gabriella and Sams, Mikko and Skoe, Erika and Kraus, Nina},
file = {:Users/gmac/mendeley/Musacchia et al/Musacchia et al. - 2007 - Musicians have enhanced subcortical auditory and audiovisual processing of speech and music.pdf:pdf},
journal = {Proceedings of the National Acadamy of Sciences},
month = {oct},
pages = {15894--15898},
title = {{Musicians have enhanced subcortical auditory and audiovisual processing of speech and music}},
url = {papers3://publication/uuid/1C2C2463-D157-4245-8FF9-7A89BC08620D},
volume = {104},
year = {2007}
}
@article{Polich1995,
author = {Polich, John and Kok, Albert},
file = {:Users/gmac/mendeley/Polich, Kok/Polich, Kok - 1995 - Cognitive and biological determinants of P300 an integrative review.pdf:pdf},
journal = {Biological Psychology},
month = {jan},
pages = {103--146},
title = {{Cognitive and biological determinants of P300: an integrative review}},
volume = {41},
year = {1995}
}
@article{Motz2013,
abstract = {Brain and Cognition, 81 (2013) 329-336. doi:10.1016/j.bandc.2013.01.005},
author = {Motz, Benjamin A and Erickson, Molly A and Hetrick, William P},
file = {:Users/gmac/mendeley/Motz, Erickson, Hetrick/Motz, Erickson, Hetrick - 2013 - To the beat of your own drum Cortical regularization of non-integer ratio rhythms toward metrical patte.pdf:pdf},
journal = {Brain and Cognition},
month = {apr},
number = {3},
pages = {329--336},
publisher = {Elsevier Inc.},
title = {{To the beat of your own drum: Cortical regularization of non-integer ratio rhythms toward metrical patterns}},
url = {http://dx.doi.org/10.1016/j.bandc.2013.01.005 papers3://publication/doi/10.1016/j.bandc.2013.01.005},
volume = {81},
year = {2013}
}
@article{Russo2008,
abstract = {OBJECTIVES: To examine age-related differences in listening to speech in music. DESIGN: In the first experiment, the effect of music familiarity on word identification was compared with a standard measure of word identification in multitalker babble. The average level of the backgrounds was matched and two speech-to-background ratios were tested. In the second experiment, recognition recall was measured for background music heard during a word identification task. RESULTS: For older adults, word identification did not depend on the type of background, but for younger adults word identification was better when the background was familiar music than when it was unfamiliar music or babble. Younger listeners remembered background music better than older listeners, with the pattern of false alarms suggesting that younger listeners consciously processed the background music more than older listeners. In other words, younger listeners attempted to "tune in" the music background, but older listeners attempted to "tune out" the background. CONCLUSIONS: These findings reveal age-related differences in listening to speech in music. When older listeners are confronted with a music background they tend to focus attention on the speech foreground. In contrast, younger listeners attend to both the speech foreground and music background. When music is familiar, this strategy adopted by younger listeners seems to be beneficial to word identification.},
author = {Russo, Frank A and Pichora-Fuller, M Kathleen},
doi = {10.1097/AUD.0b013e31817bdd1f},
file = {:Users/gmac/mendeley/Russo, Pichora-Fuller/Russo, Pichora-Fuller - 2008 - Tune in or tune out age-related differences in listening to speech in music.pdf:pdf},
isbn = {1538-4667},
issn = {0196-0202},
journal = {Ear and hearing},
number = {5},
pages = {746--760},
pmid = {18596643},
title = {{Tune in or tune out: age-related differences in listening to speech in music.}},
volume = {29},
year = {2008}
}
@article{Izard1992,
abstract = {From the cognitive theory perspective that emotions are cognition dependent and contain cognitive components, Ortony and Turner (1990) questioned the validity of the concept of basic emotions. They argued that the so-called basic emotions were neither psychologically or biologically "primitive" nor "irreducible building blocks" for generating the "great variety of emotional experiences." In the biosocial theory tradition, researchers have identified multiple noncognitive activators of emotion and demonstrated the usefulness of defining the essential components of emotion as phenomena that do not require cognitive mediators or constituents. In this framework, emotions are seen as basic because their biological and social functions are essential in evolution and adaptation. Particular emotions are called basic because they are assumed to have innate neural substrates, innate and universal expressions, and unique feeling-motivational states. The great variety of emotional experiences is explained as a function of emotion-cognition interactions that result in affective-cognitive structures.},
author = {Izard, C E},
doi = {10.1037/0033-295X.99.3.561},
file = {:Users/gmac/mendeley/Izard/Izard - 1992 - Basic emotions, relations among emotions, and emotion-cognition relations.pdf:pdf},
isbn = {1939-1471},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Arousal,Arousal: physiology,Cognition,Cognition: physiology,Emotions,Emotions: physiology,Facial Expression,Humans,Psychophysiology},
number = {3},
pages = {561--5},
pmid = {1502277},
title = {{Basic emotions, relations among emotions, and emotion-cognition relations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1502277},
volume = {99},
year = {1992}
}
@article{Hartley2010a,
abstract = {Hearing loss is a common sensory impairment experienced by older persons. Evidence shows that the use of hearing aids and/or assistive listening devices (ALDs) can benefit those with a hearing loss but that historically the uptake and use of these technologies has remained relatively low compared with the number of people who report a hearing loss.},
author = {Hartley, David and Rochtchina, Elena and Newall, Philip and Golding, Maryanne and Mitchell, Paul},
doi = {10.3766/jaaa.21.10.4},
file = {:Users/gmac/mendeley/Hartley et al/Hartley et al. - 2010 - Use of Hearing Aids and Assistive Listening Devices in an Older Australian Population.pdf:pdf},
issn = {10500545},
journal = {Journal of the American Academy of Audiology},
keywords = {abbreviations,aging,ald 5 assistive listening,assistive listening device,behind the ear,blue mountains hearing study,bmhs 5 blue mountains,bte 5,device,ehls 5 epidemiology of,fm 5 frequency modulation,hearing aids,hearing loss,hearing loss study,hearing study,hhie-s 5,prevalence studies,self-reported handicap},
number = {2010},
pages = {642--653},
pmid = {21376005},
title = {{Use of Hearing Aids and Assistive Listening Devices in an Older Australian Population.}},
volume = {21},
year = {2010}
}
@incollection{Ekman1999,
author = {Ekman, Paul},
booktitle = {Handbook of Cognition and Emotion},
chapter = {3},
editor = {Dalgleish, T and Power, M},
file = {:Users/gmac/mendeley/Ekman/Ekman - 1999 - Basic Emotions.pdf:pdf},
pages = {45--60},
title = {{Basic Emotions}},
url = {papers3://publication/uuid/41AF424D-A3C0-4EA1-89FF-2DB1EE861BC5},
year = {1999}
}
@article{Livingstone2009,
author = {Livingstone, Steven R and Thompson, William Forde and Russo, Frank A},
doi = {10.1525/mp.2009.26.5.475},
file = {:Users/gmac/mendeley/Livingstone, Thompson, Russo/Livingstone, Thompson, Russo - 2009 - Facial Expressions and Emotional Singing A Study of Perception and Production with Motion Capture.pdf:pdf},
issn = {0730-7829},
journal = {Music Perception},
keywords = {emotion,facial expression,music cognition,singing,synchronization},
month = {jun},
number = {5},
pages = {475--488},
title = {{Facial Expressions and Emotional Singing: A Study of Perception and Production with Motion Capture and Electromyography}},
url = {http://mp.ucpress.edu/cgi/doi/10.1525/mp.2009.26.5.475},
volume = {26},
year = {2009}
}
@book{Buzsaki2006,
address = {New York, NY},
author = {Buzsaki, Gyorgy},
file = {:Users/gmac/mendeley/Buzsaki/Buzsaki - 2006 - Rhythms of the Brain.pdf:pdf},
month = {jan},
publisher = {Oxford University Press},
title = {{Rhythms of the Brain}},
year = {2006}
}
@article{Ortony1990,
abstract = {A widespread assumption in theories of emotion is that there exists a small set of basic emotions. From a biological perspective, this idea is manifested in the belief that there might be neurophysiological and anatomical substrates corresponding to the basic emotions. From a psychological perspective, basic emotions are often held to be the primitive building blocks of other, nonbasic emotions. The content of such claims is examined, and the results suggest that there is no coherent nontrivial notion of basic emotions as the elementary psychological primitives in terms of which other emotions can be explained. Thus, the view that there exist basic emotions out of which all other emotions are built, and in terms of which they can be explained, is questioned, raising the possibility that this position is an article of faith rather than an empirically or theoretically defensible basis for the conduct of emotion research. This suggests that perhaps the notion of basic emotions will not lead to significant progress in the field. An alternative approach to explaining the phenomena that appear to motivate the postulation of basic emotions is presented.},
address = {Institute for the Learning Sciences, Northwestern University, Evanston, Illinois 60201.},
author = {Ortony, A and Turner, T J},
file = {:Users/gmac/mendeley/Ortony, Turner/Ortony, Turner - 1990 - What's basic about basic emotions.pdf:pdf},
journal = {Psychological Review},
month = {jul},
number = {3},
pages = {315--331},
title = {{What's basic about basic emotions?}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=1669960&retmode=ref&cmd=prlinks papers3://publication/uuid/D0549CCE-373A-42B3-B961-69B3CB5B432F},
volume = {97},
year = {1990}
}
@article{Jantzen2004,
abstract = {The continuation paradigm is often used to investigate the behavioral and neural mechanisms of timing. Typically, a movement rate is established by pacing with a metronome. Then, the metronome is turned off and the subject continues at the established rate. Performance during continuation is assumed to be based on internal timing mechanisms. Here, we investigated the degree to which the neural activity underlying time representation depends on the initial pacing context, that is, whether pacing was established by moving in-phase (the usual procedure) or anti-phase (syncopation) with an auditory metronome. Functional MRI was measured from 14 subjects during four conditions: synchronized pacing, synchronized continuation, syncopated pacing, and syncopated continuation. In general, movements were timed consistently for all four conditions. However, a much broader network of activation was engaged during syncopation compared with synchronization, including increased activation in supplementary motor area, left premotor area, right thalamus, bilateral inferior frontal gyrus, and cerebellum. No differences were found when comparing continuation with the preceding pacing phase except for decreased activity in auditory-related regions due to the absence of the metronome. These results demonstrate that the cortical and subcortical areas recruited to support a simple motor timing task depend crucially on the method used to establish the temporal reference. Thus, the neural mechanisms underlying time and timing are highly flexible, reflecting the context in which the timing is established.},
address = {Center for Complex Systems and Brain Sciences, Florida Atlantic University, 777 Glades Road, Boca Raton, FL 33431, USA. jantzen@ccs.fau.edu},
author = {Jantzen, Kelly J and Steinberg, Fred L and Kelso, J A Scott},
file = {:Users/gmac/mendeley/Jantzen, Steinberg, Kelso/Jantzen, Steinberg, Kelso - 2004 - Brain networks underlying human timing behavior are influenced by prior context.pdf:pdf},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = {apr},
number = {17},
pages = {6815--6820},
title = {{Brain networks underlying human timing behavior are influenced by prior context.}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0401300101 papers3://publication/doi/10.1073/pnas.0401300101},
volume = {101},
year = {2004}
}
@article{Iversen2016,
abstract = {Humans have the ability to flexibly synchronize motor output with sensory input, such as when dancing, performing, walking in step with a partner, or just tapping a foot along with music. The study of these behaviors, collectively called sensory-motor synchronization (SMS) offers an important window into human timing behavior and the neural mechanisms that support it. The study of SMS also provides insight into how the brain actively shapes our perception, general cognitive functions and our cultural social identity as humans. In this brief review, we will place SMS into a larger conceptual framework and highlight a rapidly expanding body of recent research.},
author = {Iversen, John Rehner and Balasubramaniam, Ramesh},
doi = {10.1016/j.cobeha.2016.02.027},
file = {:Users/gmac/mendeley/Iversen, Balasubramaniam/Iversen, Balasubramaniam - 2016 - Synchronization and temporal processing.pdf:pdf},
issn = {23521546},
journal = {Current Opinion in Behavioral Sciences},
pages = {175--180},
publisher = {Elsevier Ltd},
title = {{Synchronization and temporal processing}},
url = {http://dx.doi.org/10.1016/j.cobeha.2016.02.027},
volume = {8},
year = {2016}
}
@article{Patel2014,
abstract = {Every human culture has some form of music with a beat: a perceived periodic pulse that structures the perception of musical rhythm and which serves as a framework for synchronized movement to music.},
author = {Patel, Aniruddh D and Iversen, John R},
file = {:Users/gmac/mendeley/Patel, Iversen/Patel, Iversen - 2014 - The evolutionary neuroscience of musical beat perception the Action Simulation for Auditory Prediction (ASAP) hy.pdf:pdf},
journal = {Frontiers in Systems Neuroscience},
month = {may},
pages = {1--14},
title = {{The evolutionary neuroscience of musical beat perception: the Action Simulation for Auditory Prediction (ASAP) hypothesis}},
volume = {8},
year = {2014}
}
@article{Lim1997,
abstract = {Overlapping phasic skin conductance responses (SCRs) obtained using short interstimulus interval (ISI) paradigms such as those employed in cognitive research, confound measurement of each discrete phasic SCR as well as the tonic skin conductance level (SCL). We report a method of resolving this problem using a modelling technique that takes advantage of the stereotyped nature of the within-subject SCR waveform. A four-parameter sigmoid-exponential SCR model that describes the entire response, was developed and extended to five-, six- and eight-parameter skin conductance (SC) models. These SC models were successfully curve-fitted to more than 60 SC segments, each containing one SCR or two overlapping SCRs on a sloping baseline obtained from 20 normal subjects. The SC segments were consequently decomposed into their components: the tail of the previous response, one or two SCRs and the SCL. The SCRs free of the complication of overlap were then quantified. The raw SCRs of the same data set were also measured using a standard method. The standard measurement showed a significant reduction of 15% in amplitude and 140 ms in peak latency compared to our method. The basic four SCR model parameters-onset time, rise time, decay time constant and gain-showed increasing inter-subject variability in that order. These SCR model parameters may be studied as variables in normal and patient groups and as indices of treatment response. This quantitative method also provides a means to assess the relationships between central and autonomic psychophysiologic measures.},
author = {Lim, Chong L. and Rennie, Chris and Barry, Robert J. and Bahramali, Homayoun and Lazzaro, Ilario and Manor, Barry and Gordon, Evian},
doi = {10.1016/S0167-8760(96)00713-1},
file = {:Users/gmac/mendeley/Lim et al/Lim et al. - 1997 - Decomposing skin conductance into tonic and phasic components.pdf:pdf},
isbn = {0167-8760 (Print)\r0167-8760 (Linking)},
issn = {01678760},
journal = {International Journal of Psychophysiology},
keywords = {Electrodermal activity modelling measurement scori,Orienting reflex,Skin conductance level,Skin conductance response,Sympathetic autonomic response},
number = {2},
pages = {97--109},
pmid = {9101335},
title = {{Decomposing skin conductance into tonic and phasic components}},
volume = {25},
year = {1997}
}
@article{Cullen2014,
author = {Cullen, F. T. and Vose, B.},
doi = {10.1177/1043986214541603},
file = {:Users/gmac/mendeley/Cullen, Vose/Cullen, Vose - 2014 - How to Be a Successful Graduate Student.pdf:pdf},
isbn = {1043986214541},
issn = {1043-9862},
journal = {Journal of Contemporary Criminal Justice},
keywords = {1,1859,1999,charles dickens,criminal justice education,in a tale of,it was the best,it was the worst,later in this sen-,mentoring,of times,opens with the memorable,p,phrase,professional development,two cities},
number = {4},
pages = {362--377},
title = {{How to Be a Successful Graduate Student}},
url = {http://ccj.sagepub.com/cgi/doi/10.1177/1043986214541603},
volume = {30},
year = {2014}
}
@article{Dupuis2015,
author = {Dupuis, Kate and Pichora-Fuller, M Kathleen},
doi = {10.1044/2015},
file = {:Users/gmac/mendeley/Dupuis, Pichora-Fuller/Dupuis, Pichora-Fuller - 2015 - Aging Affects Identification of Vocal Emotions in Semantically Neutral Sentences.pdf:pdf},
journal = {Journal of Speech, Language, and Hearing Research},
number = {June},
pages = {1061--1077},
title = {{Aging Affects Identification of Vocal Emotions in Semantically Neutral Sentences}},
volume = {58},
year = {2015}
}
@article{Temperley2011,
author = {Temperley, Nicholas and Temperley, David},
file = {:Users/gmac/mendeley/Temperley, Temperley/Temperley, Temperley - 2011 - Music-Language Correlations and the Scotch Snap.pdf:pdf},
journal = {Music Perception},
month = {aug},
number = {1},
pages = {51--63},
title = {{Music-Language Correlations and the "Scotch Snap"}},
url = {papers3://publication/doi/10.1525/mp.2011.29.1.51},
volume = {29},
year = {2011}
}
@article{Izard1994,
abstract = {The idea of innate and universal facial expressions that have links with human emotions was given the status of scientific hypothesis by Darwin (1872/1965). Substantial evidence, old and new, supports his hypothesis. Much of the evidence is independent of language, but Russell's (1994) criticisms of the hypothesis focus on language-dependent data. In this article, it is argued that Russell's critique was off target in that his arguments relate only to a hypothesis of the universality of semantic attributions and overstated in that he used questionable logic in designing studies to support his claims. It is also argued that Russell misinterpreted the relation between the universality hypothesis and differential emotions theory. Finally, new evidence is presented that supports the Darwinian hypothesis of the innateness and universality of the facial expressions of a limited set of emotions and the efficacy of the most commonly used method of testing it.},
address = {Department of Psychology, University of Delaware, Newark 19716-2577.},
author = {Izard, C E},
file = {:Users/gmac/mendeley/Izard/Izard - 1994 - Innate and universal facial expressions evidence from developmental and cross-cultural research.pdf:pdf},
journal = {Psychological Bulletin},
month = {mar},
number = {2},
pages = {288--299},
title = {{Innate and universal facial expressions: evidence from developmental and cross-cultural research.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=8165273&retmode=ref&cmd=prlinks papers3://publication/uuid/36D8DF05-9ECF-41B3-8F9E-F6AAAB62F0EF},
volume = {115},
year = {1994}
}
@article{Nachev2008,
author = {Nachev, Parashkev and Kennard, Christopher and Husain, Masud},
file = {:Users/gmac/mendeley/Nachev, Kennard, Husain/Nachev, Kennard, Husain - 2008 - Functional role of the supplementary and pre-supplementary motor areas.pdf:pdf},
journal = {Nature Reviews Neuroscience},
month = {oct},
number = {11},
pages = {856--869},
title = {{Functional role of the supplementary and pre-supplementary motor areas}},
url = {http://www.nature.com/doifinder/10.1038/nrn2478 papers3://publication/doi/10.1038/nrn2478},
volume = {9},
year = {2008}
}
@article{Juslin2015,
author = {Juslin, Patrik N and Barradas, Gon{\c{c}}alo and Eerola, Tuomas},
file = {:Users/gmac/mendeley/Juslin, Barradas, Eerola/Juslin, Barradas, Eerola - 2015 - From Sound to Significance Exploring the Mechanisms Underlying Emotional Reactions to Music.pdf:pdf},
journal = {American Journal of Psychology},
number = {3},
pages = {281--304},
title = {{From Sound to Significance : Exploring the Mechanisms Underlying Emotional Reactions to Music}},
volume = {128},
year = {2015}
}
@article{Peeters2011,
abstract = {The analysis of musical signals to extract audio descriptors that can potentially characterize their timbre has been disparate and often too focused on a particular small set of sounds. The Timbre Toolbox provides a comprehensive set of descriptors that can be useful in perceptual research, as well as in music information retrieval and machine-learning approaches to content-based retrieval in large sound databases. Sound events are first analyzed in terms of various input representations (short-term Fourier transform, harmonic sinusoidal components, an auditory model based on the equivalent rectangular bandwidth concept, the energy envelope). A large number of audio descriptors are then derived from each of these representations to capture temporal, spectral, spectrotemporal, and energetic properties of the sound events. Some descriptors are global, providing a single value for the whole sound event, whereas others are time-varying. Robust descriptive statistics are used to characterize the time-varying descriptors. To examine the information redundancy across audio descriptors, correlational analysis followed by hierarchical clustering is performed. This analysis suggests ten classes of relatively independent audio descriptors, showing that the Timbre Toolbox is a multidimensional instrument for the measurement of the acoustical structure of complex sound signals.},
author = {Peeters, Geoffroy and Giordano, Bruno L. and Susini, Patrick and Misdariis, Nicolas and McAdams, Stephen},
doi = {10.1121/1.3642604},
file = {:Users/gmac/mendeley/Peeters et al/Peeters et al. - 2011 - The Timbre Toolbox Extracting audio descriptors from musical signals.pdf:pdf},
isbn = {1520-8524 (Electronic)\r0001-4966 (Linking)},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
number = {5},
pages = {2902--2916},
pmid = {22087919},
title = {{The Timbre Toolbox: Extracting audio descriptors from musical signals}},
url = {http://asa.scitation.org/doi/10.1121/1.3642604},
volume = {130},
year = {2011}
}
@misc{Getz2013,
address = {Toronto, ON},
author = {Getz, Laura and Barton, Scott and Kubovy, Michael},
booktitle = {Auditory Perception, Cognition, and Action Meeting},
file = {:Users/gmac/mendeley/Getz, Barton, Kubovy/Getz, Barton, Kubovy - 2013 - An Investigation of the Perceptual Experience of Syncopation.pdf:pdf},
month = {nov},
pages = {1},
title = {{An Investigation of the Perceptual Experience of Syncopation}},
url = {papers3://publication/uuid/D9289DC2-4AB0-4AF9-A15D-3ED7E87CA357},
year = {2013}
}
@article{Desjardins2013,
abstract = {The initial timing of face-specific effects in event-related potentials (ERPs) is a point of contention in face- processing research. The occasional reports of a larger P100 to face stimuli compared to other image categories is often attributed to differences in low-level stimulus characteristics. Separating the P100 from the classic N170 effect has not been done except by adjusting stimuli to control for low-level stimulus characteristics, which yields robust face effects only after 130 ms. In the present study we use a stimulus set with minimal controls for low-level characteristics. This produces significantly larger (p , 0.01) P100 and N170 amplitudes for images of faces compared to houses in a group effect. However, with independent component analysis (ICA), we demonstrate that (a) the P100 scalp effect stems from a neural network that is indeed independent of that producing the N170 effect, despite the N170 component being active at the time of the P100; (b) compared to the N170 effect, the P100 effect is less reliable even when it is present because of intersubject variability; and (c) some individuals show a component with a larger response to houses over faces at the time of the P100 that is undetectable at the scalp because the activation of larger spatiotemporally overlapping activity cancels its field projection. Thus, with ICA, we are able to account for the general finding in the literature of a consistent N170 face effect and a less reliable P100 face effect at the level of anatomically independent electrocortical processes.},
author = {Desjardins, J A and Segalowitz, S J},
doi = {10.1167/13.5.22.doi},
file = {:Users/gmac/mendeley/Desjardins, Segalowitz/Desjardins, Segalowitz - 2013 - Deconstructing the early visual electrocortical responses to face and house stimuli.pdf:pdf},
issn = {1534-7362},
journal = {Journal of Vision},
number = {2013},
pages = {1--18},
pmid = {23620532},
title = {{Deconstructing the early visual electrocortical responses to face and house stimuli}},
url = {http://www.journalofvision.org/content/13/5/22.short},
volume = {13(5)},
year = {2013}
}
@article{Luo2007,
abstract = {How natural speech is represented in the auditory cortex constitutes a major challenge for cognitive neuroscience. Although many single-unit and neuroimaging studies have yielded valuable insights about the processing of speech and matched complex sounds, the mechanisms underlying the analysis of speech dynamics in human auditory cortex remain largely unknown. Here, we show that the phase pattern of theta band (4–8 Hz) responses recorded from human auditory cortex with magnetoencephalography (MEG) reliably tracks and discriminates spoken sentences and that this discrimination ability is correlated with speech intelligibility. The findings suggest that an ∼200 ms temporal window (period of theta oscillation) segments the incoming speech signal, resetting and sliding to track speech dynamics. This hypothesized mechanism for cortical speech analysis is based on the stimulus-induced modulation of inherent cortical rhythms and provides further evidence implicating the syllable as a computational primitive for the representation of spoken language.},
author = {Luo, Huan and Poeppel, David},
doi = {10.1016/j.neuron.2007.06.004},
file = {:Users/gmac/mendeley/Luo, Poeppel/Luo, Poeppel - 2007 - Phase Patterns of Neuronal Responses Reliably Discriminate Speech in Human Auditory Cortex.pdf:pdf},
issn = {08966273},
journal = {Neuron},
keywords = {SYSNEURO},
month = {jun},
number = {6},
pages = {1001--1010},
title = {{Phase Patterns of Neuronal Responses Reliably Discriminate Speech in Human Auditory Cortex}},
url = {http://www.sciencedirect.com/science/article/pii/S0896627307004138},
volume = {54},
year = {2007}
}
@article{Keller2014,
abstract = {Human interaction often requires simultaneous precision and flexibility in the coordination of rhythmic behaviour between individuals engaged in joint activity, for example, playing a musical duet or dancing with a partner. This review article addresses the psychological processes and brain mechanisms that enable such rhythmic interpersonal coordination. First, an overview is given of research on the cognitive-motor processes that enable individuals to represent joint action goals and to anticipate, attend and adapt to other's actions in real time. Second, the neurophysiological mechanisms that underpin rhythmic interpersonal coordination are sought in studies of sensorimotor and cognitive processes that play a role in the representation and integration of self- and other-related actions within and between individuals' brains. Finally, relationships between social-psychological factors and rhythmic interpersonal coordination are considered from two perspectives, one concerning how social-cognitive tendencies (e.g. empathy) affect coordination, and the other concerning how coordination affects interpersonal affiliation, trust and prosocial behaviour. Our review highlights musical ensemble performance as an ecologically valid yet readily controlled domain for investigating rhythm in joint action.},
author = {Keller, Peter E and Novembre, Giacomo and Hove, Michael J},
doi = {10.1098/rstb.2013.0394},
file = {:Users/gmac/mendeley/Keller, Novembre, Hove/Keller, Novembre, Hove - 2014 - Rhythm in joint action psychological and neurophysiological mechanisms for real-time interpersonal coord.pdf:pdf},
isbn = {1471-2970 (Electronic) 0962-8436 (Linking)},
issn = {1471-2970},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Cognition,Cognition: physiology,Humans,Interpersonal Relations,Joints,Joints: physiology,Movement,Movement: physiology,Music,Music: psychology,Periodicity,Psychomotor Performance,Psychomotor Performance: physiology},
number = {1658},
pages = {20130394},
pmid = {25385772},
title = {{Rhythm in joint action: psychological and neurophysiological mechanisms for real-time interpersonal coordination.}},
url = {http://rstb.royalsocietypublishing.org/content/369/1658/20130394#sec-1},
volume = {369},
year = {2014}
}
@article{Kendall1990,
author = {Kendall, Roger A and Carterette, Edward C},
file = {:Users/gmac/mendeley/Kendall, Carterette/Kendall, Carterette - 1990 - The Communication of Musical Expression.pdf:pdf},
journal = {Music Perception},
month = {jan},
pages = {129--164},
title = {{The Communication of Musical Expression}},
url = {papers3://publication/uuid/68AF0E0E-2D2B-44A7-9AE3-B22422698768},
volume = {8},
year = {1990}
}
@article{DallaBella2001,
author = {{Dalla Bella}, Simone and Peretz, Isabelle and Rousseau, Luc and Gosselin, Nathalie},
file = {:Users/gmac/mendeley/Dalla Bella et al/Dalla Bella et al. - 2001 - A developmental study of the affective value of tempo and mode in music.pdf:pdf},
journal = {Cognitive Brain Research},
month = {jan},
pages = {B1--B10},
title = {{A developmental study of the affective value of tempo and mode in music}},
url = {papers3://publication/uuid/50C50349-B0B6-4F3E-99DF-7ECC43BB5A09},
volume = {80},
year = {2001}
}
@article{Parbery-Clark2012,
abstract = {NBA, 33 (2012) 1483.e1-1483.e4.  doi:10.1016/j.neurobiolaging.2011.12.015},
author = {Parbery-Clark, A and Anderson, S and Hittner, E and Kraus, Nina},
file = {:Users/gmac/mendeley/Parbery-Clark et al/Parbery-Clark et al. - 2012 - Musical experience offsets age-related delays in neural timing.pdf:pdf},
journal = {Neurobiology of Aging},
month = {jul},
number = {7},
pages = {1483.e1--1483.e4},
publisher = {Elsevier Inc.},
title = {{Musical experience offsets age-related delays in neural timing}},
url = {http://dx.doi.org/10.1016/j.neurobiolaging.2011.12.015 papers3://publication/doi/10.1016/j.neurobiolaging.2011.12.015},
volume = {33},
year = {2012}
}
@article{Haller2002,
author = {Haller, Heiko and Krauss, Stefan},
file = {:Users/gmac/mendeley/Haller, Krauss/Haller, Krauss - 2002 - Misinterpretations of Significance A Problem Students Share with Their Teachers.pdf:pdf},
journal = {Methods of Psychological Research Online},
keywords = {stats},
month = {jan},
number = {1},
pages = {1--20},
title = {{Misinterpretations of Significance: A Problem Students Share with Their Teachers?}},
url = {http://www.dgps.de/fachgruppen/methoden/mpr-online/ papers3://publication/uuid/4339F25A-2F0C-4F7A-8A6A-7A07E719415A},
volume = {7},
year = {2002}
}
@article{Grahn2013b,
abstract = {From established musicians to musically untrained children, music seems to have a universal, automatic impact on the movement of the human body. Sensing a beat in rhythm may compel some individuals to move. Through neuroimaging techniques and investigation of neurological patient groups, researchers have discovered that several movement areas of the brain respond to rhythms, whether regular, musical rhythms or irregular rhythms. In addition, a specific response to rhythms with a beat is routinely observed in the basal ganglia, a crucial set of brain structures for movement control. These new findings about the brain's response to rhythm have led researchers to investigate the possible mechanisms through which music may affect movement. Beat-based rhythms may increase activity in the basal ganglia and consequently improve basal ganglia function in disorders such as Parkinson's disease. Alternatively, ii is possible that other, intact, brain regions may compensate for impaired function. Although much research remains to be done, current findings about how rhythm relates to the control of movement may have implications for therapeutic approaches to rehabilitation. (PsycINFO Database Record (c) 2014 APA, all rights reserved)(journal abstract)},
author = {Grahn, Jessica A and Watson, Sarah L.},
doi = {10.1093/mtp/31.1.25},
file = {:Users/gmac/mendeley/Grahn, Watson/Grahn, Watson - 2013 - Perspectives on rhythm processing in motor regions of the brain.pdf:pdf},
issn = {20537387},
journal = {Music Therapy Perspectives},
number = {1},
pages = {25--30},
title = {{Perspectives on rhythm processing in motor regions of the brain}},
volume = {31},
year = {2013}
}
@article{Pollard1987,
author = {Pollard, P and Richardson, J T E},
file = {:Users/gmac/mendeley/Pollard, Richardson/Pollard, Richardson - 1987 - On the Probability of Making Type I Errors.pdf:pdf},
journal = {Psychological Bulletin},
keywords = {stats},
month = {jan},
number = {1},
pages = {159--163},
title = {{On the Probability of Making Type I Errors}},
url = {http://search.proquest.com.ezproxy.lib.ryerson.ca/psycinfo/docview/614316930/fulltextPDF/13A38B9FA945AFF2B45/1?accountid=13631 papers3://publication/uuid/9A0F7E6C-8643-47A3-B3D0-22F637414A26},
volume = {102},
year = {1987}
}
@article{Costa2004,
abstract = {Fifty-one tonal and atonal classical melodies were evaluated by 29 stu- dents on 10 bipolar adjective scales that focused on emotional evalua- tion along four factors: Significant predictors for each factor were obtained through ridge regression analyses. Predictors were quantified characteristics of each melody: the distribution of intervals according to interval size, the mode, and tonal strength (C. L. Krumhansl, 1990). Valence was best predicted by mode. Aesthetic judgment was predicted by the interval distribution and by tonal strength. Melodies judged pleasant contained more perfect fourths and minor sevenths and fewer augmented fourths; they were also high in tonal strength. Activity and potency were best predicted by the interval distribution. Activity, a sense of instability and motion, was conveyed by a greater occurrence of minor seconds, aug- mented fourths, and intervals larger than the octave. Potency, an expres- sion of vigor and power, was marked by a greater occurrence of unisons and octaves. Thus the emotional expression of a melody appears to be related to the distributions of its interval categories, its mode, and its tonal strength},
author = {Costa, Marco and Fine, Philip and {Ricci Bitti}, Pio Enrico},
doi = {10.1525/mp.2004.22.1.1},
file = {:Users/gmac/mendeley/Costa, Fine, Ricci Bitti/Costa, Fine, Ricci Bitti - 2004 - Interval Distributions, Mode, and Tonal Strength of Melodies as Predictors of Perceived Emotion.pdf:pdf},
isbn = {0520057295},
issn = {0730-7829},
journal = {Music Perception},
number = {1},
pages = {1--14},
title = {{Interval Distributions, Mode, and Tonal Strength of Melodies as Predictors of Perceived Emotion}},
volume = {22},
year = {2004}
}
@article{VanNoordt2015,
abstract = {The human medial frontal cortex and especially the anterior cingulate cortex (ACC) have been implicated in several aspects of performance monitoring. We examined event-related EEG during a general process of controlling attention by using a novel paradigm to elicit a medial frontal negativity (MFN) to stimuli that indicate potential changes in future response demands. Independent components analysis revealed that the latent factors that accounted for MFN activity to such changes also accounted for activity associated with the error-related negativity and the NoGo inhibitory N2. Given that the medial frontal activation to these changes varied reliably across subjects simply as a function of potential need to alter responses in the absence of error commission and response inhibition, we propose that the underlying basis for medial frontal activation in situations demanding ongoing monitoring of performance involves an increase in attention control, a factor common to all MFN paradigms.},
author = {van Noordt, Stefon J R and Desjardins, James A. and Segalowitz, Sidney J.},
doi = {10.1016/j.neuroimage.2015.04.021},
file = {:Users/gmac/mendeley/van Noordt, Desjardins, Segalowitz/van Noordt, Desjardins, Segalowitz - 2015 - Watch out! Medial frontal cortex is activated by cues signaling potential changes in respons.pdf:pdf},
isbn = {1095-9572 (Electronic)\r1053-8119 (Linking)},
issn = {10959572},
journal = {NeuroImage},
keywords = {Anterior cingulate cortex,ERN,Independent components analysis,Performance monitoring,Robust estimation,Task switching},
pages = {356--370},
pmid = {25887260},
publisher = {Elsevier Inc.},
title = {{Watch out! Medial frontal cortex is activated by cues signaling potential changes in response demands}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2015.04.021},
volume = {114},
year = {2015}
}
@article{Schellenberg2008,
author = {Schellenberg, E Glenn and Peretz, Isabelle and Vieillard, Sandrine},
file = {:Users/gmac/mendeley/Schellenberg, Peretz, Vieillard/Schellenberg, Peretz, Vieillard - 2008 - Liking for happy- and sad-sounding music Effects of exposure.pdf:pdf},
journal = {Cognition & Emotion},
month = {feb},
number = {2},
pages = {218--237},
title = {{Liking for happy- and sad-sounding music: Effects of exposure}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02699930701350753 papers3://publication/doi/10.1080/02699930701350753},
volume = {22},
year = {2008}
}
@incollection{Livingstone2005,
address = {Brisbane: ACMA},
author = {Livingstone, Steven R and Muhlberger, Ralf and Brown, Andrew},
booktitle = {Australasian Computer Music Conference},
editor = {Opie, T and Brown, A R},
file = {:Users/gmac/mendeley/Livingstone, Muhlberger, Brown/Livingstone, Muhlberger, Brown - 2005 - Playing with Affect Music Performance with Awareness of Score and Audience BT - Australasian Com.pdf:pdf},
month = {jan},
pages = {92--98},
title = {{Playing with Affect: Music Performance with Awareness of Score and Audience BT  - Australasian Computer Music Conference}},
url = {papers3://publication/uuid/568679CE-92A8-43CE-B8D2-616867A38A29},
year = {2005}
}
@article{Hurt-Thaut2014,
abstract = {Background: The risk of falling over the age of 65 is 33% for healthy elderly and 40% for a person with Parkinson's disease over a one year period. A training program to reduce this risk could have significant impacts on health care cost and assist in maintenance of patient safety, independence, and quality of life. Objective: The purpose of this study was to investigate whether a home-based Rhythmic Auditory Stimulation (RAS) gait training program would have an effect on gait parameters associated with falls in healthy elderly and PD patients with a history of frequent falls. Method: Twenty healthy elderly and twenty PD patients were randomly assigned to a continuous treatment group which underwent 24 weeks with RAS, or a control group which trained intermittently eight weeks with RAS, eight weeks without, for twenty-four weeks. Changes in ankle dorsiflexion, cadence, velocity, stride length, the Berg Balance Scale, fear of falling, the Barthel Index, the timed "up and go" test (TUG) and frequency and severity of falls were evaluated. Results: The results for the healthy elderly indicated a statistically significant increase in degrees of dorsiflexion, velocity, cadence, stride length, and the Berg Balance Scale in both groups at each time point, with large effect sizes. Results for the PD treatment groups indicated that there were significant differences in dorsiflexion ( p<.009), cadence (p<.009), velocity ( p<.0001), stride length (p<.0003), severity level 1 falls (p<.003), and fear of falling ( p<.0004), when comparing treatments, with large effect sizes. A correlation matrix combining all 40 participants revealed a significant correlation between fear of falling and severity level 1 falls at 8 weeks (0.48, p<.004); severity level 2 falls at all time periods [baseline (0.42, p<.01), 8 weeks (0.42, p<.01), 16 weeks (0.42, p<.01), and 24 weeks (0.42, p<.01)]; and severity level 3 falls at 24 week 0.35, p<.04). Other correlations with falls in the healthy elderly group included severity level 2 falls and the Berg Balance scale (0.65, p<0.002), severity level 2 and 3 falls (0.65, p< .002), severity level 3 falls and stride length (0.57, p<.002) and velocity (0.65, p>.002). Significant interactions were seen between the intermittent and continuous treatment groups in dorsiflexion [ F (2,72)=9.54, p<.0002], stride length [ F (2,72)=8.17, p<.0006], velocity [F (2,72)=7.92, p<.0006], fear of falling [ F (2, 72)=12.97, p<.0001], and the Berg Scale [F (2,72)=1.92, p<.15]. Conclusions: The findings offer evidence that continuous and intermittent RAS treatment over time can be effective tools to reduce falls in healthy elderly and patients with Parkinson's disease, however continuous RAS treatment results in greater gains in gait parameters associated with safety. Two single variables, the Berg Balance Scale and velocity were seen as a significant fall predictor for healthy elderly. The Barthel Index was a significant indicator for falls with injury for the Parkinson's participants.},
author = {Hurt-Thaut, Corene P.},
file = {:Users/gmac/mendeley/Hurt-Thaut/Hurt-Thaut - 2014 - Rhythmic auditory stimulation to reduce falls in healthy elderly and patients with parkinson's disease A randomized.pdf:pdf},
institution = {Colorado State University},
title = {{Rhythmic auditory stimulation to reduce falls in healthy elderly and patients with parkinson's disease: A randomized control trial}},
type = {Dissertation},
year = {2014}
}
@article{Bonnard2013,
author = {Bonnard, Damien and Micheyl, Christophe and Semal, Catherine and Dauman, Ren{\'{e}} and Demany, Laurent},
file = {:Users/gmac/mendeley/Bonnard et al/Bonnard et al. - 2013 - Auditory discrimination of frequency ratios The octave singularity.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
month = {jan},
number = {3},
pages = {788--801},
publisher = {American Psychological Association},
title = {{Auditory discrimination of frequency ratios: The octave singularity}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0030095 papers3://publication/doi/10.1037/a0030095},
volume = {39},
year = {2013}
}
@article{Juslin2013a,
abstract = {Physics of Life Reviews, 10 (2013) 235–266. 10.1016/j.plrev.2013.05.008},
author = {Juslin, Patrik N},
file = {:Users/gmac/mendeley/Juslin/Juslin - 2013 - From everyday emotions to aesthetic emotions Towards a unified theory of musical emotions.pdf:pdf},
journal = {Physics of Life Reviews},
month = {sep},
number = {3},
pages = {235--266},
publisher = {Elsevier B.V.},
title = {{From everyday emotions to aesthetic emotions: Towards a unified theory of musical emotions}},
url = {http://dx.doi.org/10.1016/j.plrev.2013.05.008 papers3://publication/doi/10.1016/j.plrev.2013.05.008},
volume = {10},
year = {2013}
}
@article{Fujioka2006,
author = {Fujioka, Takako and Ross, Bernhard and Kakigi, Ryusuke and Pantev, Christo and Trainor, Laurel J},
file = {:Users/gmac/mendeley/Fujioka et al/Fujioka et al. - 2006 - One year of musical training affects development of auditory cortical-evoked fields in young children.pdf:pdf},
journal = {Brain},
month = {sep},
number = {10},
pages = {2593--2608},
title = {{One year of musical training affects development of auditory cortical-evoked fields in young children}},
url = {http://www.brain.oxfordjournals.org/cgi/doi/10.1093/brain/awl247 papers3://publication/doi/10.1093/brain/awl247},
volume = {129},
year = {2006}
}
@article{Juchniewicz2008,
author = {Juchniewicz, J},
file = {:Users/gmac/mendeley/Juchniewicz/Juchniewicz - 2008 - The influence of physical movement on the perception of musical performance.pdf:pdf},
journal = {Psychology of Music},
keywords = {audience,performance},
month = {apr},
number = {4},
pages = {417--427},
title = {{The influence of physical movement on the perception of musical performance}},
url = {http://pom.sagepub.com/cgi/doi/10.1177/0305735607086046 papers3://publication/doi/10.1177/0305735607086046},
volume = {36},
year = {2008}
}
@article{Ekman2011,
author = {Ekman, Paul and Cordaro, D},
file = {:Users/gmac/mendeley/Ekman, Cordaro/Ekman, Cordaro - 2011 - What is Meant by Calling Emotions Basic.pdf:pdf},
journal = {Emotion Review},
month = {sep},
number = {4},
pages = {364--370},
title = {{What is Meant by Calling Emotions Basic}},
url = {http://emr.sagepub.com/cgi/doi/10.1177/1754073911410740 papers3://publication/doi/10.1177/1754073911410740},
volume = {3},
year = {2011}
}
@article{Krishnan1992,
author = {Krishnan, Ananthanarayan and Durrant, J D},
file = {:Users/gmac/mendeley/Krishnan, Durrant/Krishnan, Durrant - 1992 - The Frequency-Following Response and the Onset Response Evaluation of Frequency Specificity Using a Forward-M.pdf:pdf},
journal = {Ear & Hearing},
month = {jan},
pages = {228--232},
title = {{The Frequency-Following Response and the Onset Response: Evaluation of Frequency Specificity Using a Forward-Masking Paradigm}},
url = {papers3://publication/uuid/E1A0704F-FF33-4FE4-B3A9-AF68EA197A11},
volume = {13},
year = {1992}
}
@article{Madison2014a,
abstract = {Groove is the experience of wanting to move when hearing music, such as snapping fingers or tapping feet. This is a central aspect of much music, in particular of music intended for dancing. While previous research has found considerable consistency in ratings of groove across individuals, it remains unclear how groove is induced, that is, what are the physical properties of the acoustic signal that differ between more and less groove-inducing versions. Here, we examined this issue with a performance experiment, in which four musicians performed six simple and six complex melodies in two conditions with the intention of minimizing and maximizing groove. Analyses of rhythmical and temporal properties from the performances demonstrated some general effects. For example, more groove was associated with more notes on faster metrical levels and syncopation, and less groove was associated with deadpan timing and destruction of the regular pulse.We did not observe that deviations from the metrical grid [i.e., micro-timing (MT)] were a predictor of groove. A listener experiment confirmed that the musicians' manipulations had the intended effects on the experience of groove. A Brunswikian lens model was applied, which estimates the performer-perceiver communication across the two experiments. It showed that the communication achievement for simple melodies was 0.62, and that the matching of performers' and listeners' use of nine rhythmical cues was 0.83. For complex melodies with an already high level of groove, the corresponding values were 0.39 and 0.34, showing that it was much more difficult to “take out” groove from musical structures designed to induce groove.},
author = {Madison, Guy and Sioros, George},
doi = {10.3389/fpsyg.2014.00894},
file = {:Users/gmac/mendeley/Madison, Sioros/Madison, Sioros - 2014 - What musicians do to induce the sensation of groove in simple and complex melodies, and how listeners perceive.pdf:pdf},
journal = {Frontiers in Psychology},
keywords = {groove,micro-timing,movement,music,musicians,rhythm,syncopation},
pages = {1--14},
title = {{What musicians do to induce the sensation of groove in simple and complex melodies, and how listeners perceive it}},
volume = {5},
year = {2014}
}
@article{Sohmer1977,
author = {Sohmer, H and Pratt, H and Kinarti, R},
file = {:Users/gmac/mendeley/Sohmer, Pratt, Kinarti/Sohmer, Pratt, Kinarti - 1977 - Sources of Frequency Following Responses (FFR) in Man.pdf:pdf},
journal = {Electroencephalography and Clinical Neurophysiology},
month = {jan},
pages = {656--664},
title = {{Sources of Frequency Following Responses (FFR) in Man}},
url = {papers3://publication/uuid/E7C4BDA4-EB98-461C-B688-C8F9B93A7827},
volume = {42},
year = {1977}
}
@article{Khalsa2009b,
abstract = {A network of cortical brain regions, including the insula and anterior cingulate cortex (ACC), has been proposed as the critical and sole substrate for interoceptive awareness. Combingin lesion and pharacological approaches in human, we found that the insula and ACC were not critical for awaress of heartbeat sensations. Instead, this awareness was mediated by both somatosensory afferents from teh skin and a network that included the insula and ACC. Together, these pathways enable the core human experience of the cardiovascular state of the body.},
author = {Khalsa, Sahib S and Rudrauf, David and Feinstein, Justin S and Tranel, Daniel},
doi = {10.1038/nn.2411},
file = {:Users/gmac/mendeley/Khalsa et al/Khalsa et al. - 2009 - The pathways of interoceptive awareness.PDF:PDF},
journal = {Nature Neuroscience},
pages = {1494--1496},
title = {{The pathways of interoceptive awareness}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0022-3514.87.5.684},
volume = {12},
year = {2009}
}
@article{Keil2004,
author = {Keil, Andreas and Gruber, Thomas and M{\"{u}}ller, Matthias M and Moratti, Stephan and Stolarova, Margarita and Bradley, Margaret M and Lang, Peter J},
file = {:Users/gmac/mendeley/Keil et al/Keil et al. - 2004 - Early modulation of visual perception by emotional arousal Evidence from steady-state visual evoked brain potential.pdf:pdf},
month = {aug},
pages = {1--12},
title = {{Early modulation of visual perception by emotional arousal: Evidence from steady-state visual evoked brain potentials}},
url = {papers3://publication/uuid/62BFEC3F-EA3B-4006-86D9-37A9ECD92328},
year = {2004}
}
@article{Orbelo2005,
author = {Orbelo, Diana M and Grim, Michael A and Talbott, Richard E and Ross, Elliott D},
doi = {10.1177/0891988704272214},
file = {:Users/gmac/mendeley/Orbelo et al/Orbelo et al. - 2005 - Impaired Comprehension of Affective Prosody in Elderly Subjects Is Not Predicted by Age-Related Hearing Loss or A.pdf:pdf},
journal = {Journal of Geriatric Psychiatry and Neurology},
keywords = {affective prosody is the,aging,aprosodia,attitudinal prosody,cognition,discourse,emotional and attitu-,gesture,hearing,is an essential component,naled in speech and,of,person,s affective state,sig-,the interpretation of another},
number = {1},
pages = {25--32},
title = {{Impaired Comprehension of Affective Prosody in Elderly Subjects Is Not Predicted by Age-Related Hearing Loss or Age-Related Cognitive Decline}},
volume = {18},
year = {2005}
}
@article{McNeely2012,
abstract = {Gait and balance impairments in people with Parkinson disease (PD) may lead to falls and serious injuries. Therefore, it is critical to improve our understanding of the nature of these impairments, including how they respond to prescribed anti-Parkinson medication. This is particularly important for complex balance and gait tasks that may be associated with falls. We evaluated motor function, functional balance, and gait performance during various gait tasks in 22 people with PD OFF and ON medication (PD OFF, PD ON) and 20 healthy older adults. Although MDS-UPDRS-III score, Berg Balance Scale, Mini-Balance Evaluations Systems test, and Timed-Up-and-Go improved in PD with medication, impairments persisted in all measures on medication, compared to controls. Dual task Timed-Up-and-Go did not improve with medication, and PD ON required more time than controls. Gait velocity and stride length improved similarly with medication in PD across forward, fast, backward, dual task forward, and dual task backward gait tasks. Cadence did not change with medication, nor did it differ between PD ON and controls. Velocity and stride length were reduced in PD ON compared to controls. Velocity reductions in PD ON during fast gait were cadence-mediated, while velocity reductions in backward gait were stride length-mediated. Our results suggest functional balance improves with medication in PD and gait performance improves with medication, regardless of task complexity. Remaining impairments on medication highlight the need to examine additional therapeutic options for individuals with PD to reduce the risk of falls. ?? 2012 Elsevier B.V.},
author = {McNeely, Marie E. and Duncan, Ryan P. and Earhart, Gammon M.},
doi = {10.1016/j.gaitpost.2012.02.009},
file = {:Users/gmac/mendeley/McNeely, Duncan, Earhart/McNeely, Duncan, Earhart - 2012 - Medication improves balance and complex gait performance in Parkinson disease.pdf:pdf},
isbn = {1879-2219 (Electronic)\r0966-6362 (Linking)},
issn = {09666362},
journal = {Gait and Posture},
number = {1},
pages = {144--148},
pmid = {22418585},
publisher = {Elsevier B.V.},
title = {{Medication improves balance and complex gait performance in Parkinson disease}},
volume = {36},
year = {2012}
}
@article{Lunner2003,
author = {Lunner, Thomas},
file = {:Users/gmac/mendeley/Lunner/Lunner - 2003 - Cognitive function in relation to hearing aid use.pdf:pdf},
journal = {International journal of Audiology},
month = {oct},
pages = {49--58},
title = {{Cognitive function in relation to hearing aid use}},
url = {https://www.researchgate.net/profile/Thomas_Lunner/publication/10612950_Cognitive_function_in_relation_to_hearing_aid_use/file/9c9605270284bd3de5.pdf papers3://publication/uuid/6A12EC59-A409-4266-B809-30DABC98B915},
volume = {42},
year = {2003}
}
@article{Sanger2012,
abstract = {To further test and explore the hypothesis that synchronous oscillatory brain activity supports interpersonally coordinated behavior during dyadic music performance, we simultaneously recorded the electroencephalogram (EEG) from the brains of each of 12 guitar duets repeatedly playing a modified Rondo in two voices by C.G. Scheidler.},
author = {S{\"{a}}nger, Johanna and M{\"{u}}ller, Viktor and Lindenberger, Ulman},
file = {:Users/gmac/mendeley/S{\"{a}}nger, M{\"{u}}ller, Lindenberger/S{\"{a}}nger, M{\"{u}}ller, Lindenberger - 2012 - Intra- and interbrain synchronization and network properties when playing guitar in duets.pdf:pdf},
journal = {Frontiers in Human Neuroscience},
month = {nov},
pages = {1--19},
title = {{Intra- and interbrain synchronization and network properties when playing guitar in duets}},
url = {http://www.frontiersin.org/Human_Neuroscience/10.3389/fnhum.2012.00312/abstract papers3://publication/doi/10.3389/fnhum.2012.00312/abstract},
year = {2012}
}
@article{Etzel2006,
abstract = {Music is used to induce moods in experimental settings as well as for therapeutic purposes. Prior studies suggest that subjects listening to certain types of music experience strong moods and show physiological responses associated with the induced emotions. We hypothesized that cardiovascular and respiratory patterns could discriminate moods induced via music. 18 healthy subjects listened to 12 music clips, four each to induce happiness, sadness, and fear, while cardiovascular and respiratory responses were recorded using an electrocardiogram and chest strain-gauge belt. After each clip subjects completed a questionnaire. Subjects consistently reported experiencing the targeted mood, suggesting successful mood induction. Cardiovascular activity was measured by calculating time domain measures and heart rate changes during each clip. Respiratory activity was measured by total, inspiration, and expiration lengths as well as changes in mean respiration rate during each clip. Evaluation of individuals' patterns and mixed-model analyses were performed. Contrary to expectations, the time domain measures of subjects' cardiovascular responses did not vary significantly between the induced moods, although a heart rate deceleration was found during the sadness inductions and acceleration during the fear inductions. The time domain respiratory measures varied with clip type: the mean breath length was longest for the sad induction, intermediate during fear, and shortest during the happiness induction. However, analysis using normalized least mean squares adaptive filters to measure time correlation indicated that much of this difference may be attributable to entrainment of respiration to characteristics of the music which varied between the stimuli. Our findings point to the difficulty in detecting psychophysiological correlates of mood induction, and further suggest that part of this difficulty may arise from failure to differentiate it from tempo-related contributions when music is used as the inducer. ?? 2005 Elsevier B.V. All rights reserved.},
author = {Etzel, Joset A. and Johnsen, Erica L. and Dickerson, Julie and Tranel, Daniel and Adolphs, Ralph},
doi = {10.1016/j.ijpsycho.2005.10.025},
file = {:Users/gmac/mendeley/Etzel et al/Etzel et al. - 2006 - Cardiovascular and respiratory responses during musical mood induction.pdf:pdf},
isbn = {0167-8760 (Print)},
issn = {01678760},
journal = {International Journal of Psychophysiology},
keywords = {Cardiovascular and respiratory responses,Mood,Music},
number = {1},
pages = {57--69},
pmid = {16460823},
title = {{Cardiovascular and respiratory responses during musical mood induction}},
volume = {61},
year = {2006}
}
@article{Moors2013,
author = {Moors, A and Ellsworth, Phoebe C and Scherer, Klaus R and Frijda, N H},
file = {:Users/gmac/mendeley/Moors et al/Moors et al. - 2013 - Appraisal Theories of Emotion State of the Art and Future Development.pdf:pdf},
journal = {Emotion Review},
month = {mar},
number = {2},
pages = {119--124},
title = {{Appraisal Theories of Emotion: State of the Art and Future Development}},
url = {http://emr.sagepub.com/cgi/doi/10.1177/1754073912468165 papers3://publication/doi/10.1177/1754073912468165},
volume = {5},
year = {2013}
}
@article{Buhmann2016,
author = {Buhmann, Jeska and Desmet, Frank and Moens, Bart and {Van Dyck}, Edith and Leman, Marc},
doi = {10.1371/journal.pone.0154414},
file = {:Users/gmac/mendeley/Buhmann et al/Buhmann et al. - 2016 - Spontaneous Velocity Effect of Musical Expression on Self-Paced Walking.PDF:PDF},
issn = {1932-6203},
journal = {Plos One},
number = {5},
pages = {e0154414},
title = {{Spontaneous Velocity Effect of Musical Expression on Self-Paced Walking}},
url = {http://dx.plos.org/10.1371/journal.pone.0154414},
volume = {11},
year = {2016}
}
@article{Allport1927,
author = {Allport, Gordon W},
file = {:Users/gmac/mendeley/Allport/Allport - 1927 - Concepts of Trait and Personality.pdf:pdf},
journal = {Psychological Bulletin},
month = {jan},
pages = {284--293},
title = {{Concepts of Trait and Personality}},
url = {papers3://publication/uuid/9EE359BA-C350-4CA2-9803-D7D5010752E6},
volume = {24},
year = {1927}
}
@article{Krishnan2002,
author = {Krishnan, Ananthanarayan},
doi = {10.1016/S0378-5955(02)00327-1},
file = {:Users/gmac/mendeley/Krishnan/Krishnan - 2002 - Human frequency-following responses representation of steady-state synthetic vowels.pdf:pdf},
isbn = {0378-5955},
issn = {03785955},
journal = {Hearing research},
pages = {192--201},
pmid = {12062771},
title = {{Human frequency-following responses: representation of steady-state synthetic vowels.}},
volume = {166},
year = {2002}
}
@article{Harrison1984,
abstract = {In order to determine the possible source of the later vertex positive waves of the guinea pig auditory brainstem response (ABR), we have measured field potentials on the surface and at depths through inferior colliculus whilst making concurrent recordings of single unit responses (using identical broadband click stimuli). We find neurones, restricted to the antero-ventral inferior colliculus, with characteristic frequencies in excess of 12 kHz which have well synchronized onset responses short enough (c. 5 ms) to contribute to the P5 wave of the ABR.},
author = {Harrison, R V and Palmer, A R},
doi = {10.3109/14992028409042136},
file = {:Users/gmac/mendeley/Harrison, Palmer/Harrison, Palmer - 1984 - Neurone response latency in the inferior colliculus in relation to the auditory brainstem responses (ABR) in t.pdf:pdf},
isbn = {0105-0397 (Print)\r0105-0397 (Linking)},
issn = {0105-0397},
journal = {Scandinavian audiology},
keywords = {Animals,Auditory,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Brain Mapping,Brain Stem,Brain Stem: physiology,Evoked Potentials,Guinea Pigs,Inferior Colliculi,Inferior Colliculi: physiology,Neurons,Neurons: physiology,Pitch Perception,Pitch Perception: physiology,Reaction Time,Reaction Time: physiology},
number = {4},
pages = {275--81},
pmid = {6523046},
title = {{Neurone response latency in the inferior colliculus in relation to the auditory brainstem responses (ABR) in the guinea pig.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6523046},
volume = {13},
year = {1984}
}
@article{Nozaradan2013,
author = {Nozaradan, Sylvie and Zerouali, Younes and Peretz, Isabelle and Mouraux, Andre},
file = {:Users/gmac/mendeley/Nozaradan et al/Nozaradan et al. - 2013 - Capturing with EEG the Neural Entrainment and Coupling Underlying Sensorimotor Synchronization to the Beat.pdf:pdf},
journal = {Cerebral Cortex},
month = {oct},
number = {2013},
pages = {2261--2611},
title = {{Capturing with EEG the Neural Entrainment and Coupling Underlying Sensorimotor Synchronization to the Beat}},
url = {http://cercor.oxfordjournals.org/cgi/content/abstract/bht261v1 papers3://publication/doi/10.1093/cercor/bht261},
volume = {0},
year = {2013}
}
@article{Nombela2013,
abstract = {Previous research has noted that music can improve gait in several pathological conditions, including Parkinson's disease, Huntington's disease and stroke. Current research into auditory-motor interactions and the neural bases of musical rhythm perception has provided important insights for developing potential movement therapies. Specifically, neuroimaging studies show that rhythm perception activates structures within key motor networks, such as premotor and supplementary motor areas, basal ganglia and the cerebellum - many of which are compromised to varying degrees in Parkinson's disease. It thus seems likely that automatic engagement of motor areas during rhythm perception may be the connecting link between music and motor improvements in Parkinson's disease. This review seeks to describe the link, address core questions about its underlying mechanisms, and examine whether it can be utilized as a compensatory mechanism. ?? 2013 The Authors.},
author = {Nombela, Cristina and Hughes, Laura E. and Owen, Adrian M. and Grahn, Jessica A},
doi = {10.1016/j.neubiorev.2013.08.003},
file = {:Users/gmac/mendeley/Nombela et al/Nombela et al. - 2013 - Into the groove Can rhythm influence Parkinson's disease.pdf:pdf},
isbn = {1873-7528 (Electronic)\r0149-7634 (Linking)},
issn = {01497634},
journal = {Neuroscience and Biobehavioral Reviews},
keywords = {Cadence,Entrainment,Gait,Motor training,Music,Parkinson's disease,Rhythm},
number = {10},
pages = {2564--2570},
pmid = {24012774},
publisher = {Elsevier Ltd},
title = {{Into the groove: Can rhythm influence Parkinson's disease?}},
url = {http://dx.doi.org/10.1016/j.neubiorev.2013.08.003},
volume = {37},
year = {2013}
}
@article{Mitchell2011,
author = {Mitchell, Rachel L C and Kingston, Rachel A and Bou{\c{c}}as, Sofia L Barbosa},
doi = {10.1037/a0021861},
file = {:Users/gmac/mendeley/Mitchell, Kingston, Bou{\c{c}}as/Mitchell, Kingston, Bou{\c{c}}as - 2011 - The Specificity of Age-Related Decline in Interpretation of Emotion Cues From Prosody.pdf:pdf},
journal = {Psychology and Aging},
keywords = {adults find it difficult,aging,emerging evidence suggests older,emotion,emotions from prosodic features,generic,however,in emotion interpretation or,of speech,prosody,reflects a specific decline,social cognition,to infer,whether this},
number = {2},
pages = {406--414},
title = {{The Specificity of Age-Related Decline in Interpretation of Emotion Cues From Prosody}},
volume = {26},
year = {2011}
}
@article{Rodger2016,
author = {Rodger, Matthew W. M. and Craig, Cathy M.},
doi = {10.3389/fnins.2016.00272},
file = {:Users/gmac/mendeley/Rodger, Craig/Rodger, Craig - 2016 - Beyond the Metronome Auditory Events and Music May Afford More than Just Interval Durations as Gait Cues in Parki.pdf:pdf},
issn = {1662-453X},
journal = {Frontiers in Neuroscience},
keywords = {affordances,auditory cues,gait,music,parkinson,s disease},
number = {June},
title = {{Beyond the Metronome: Auditory Events and Music May Afford More than Just Interval Durations as Gait Cues in Parkinson's Disease}},
url = {http://journal.frontiersin.org/article/10.3389/fnins.2016.00272},
volume = {10},
year = {2016}
}
@incollection{Large2008,
address = {Bingley, UK},
annote = {- "When humans "synchronize" musical interaction, we enter into a form of temporal coordination that is among the most elaborate observed in nature."
- pulse and meter are perceptual; they are not properties of the stimulus},
author = {Large, Edward W},
booktitle = {Psychology of Time},
editor = {Grondin, Simon},
month = {jan},
number = {6},
pages = {189--231},
publisher = {Emerald Group Publishing Limited},
title = {{Resonating to Musical Rhythm: Theory and Experiment BT - Psychology of Time}},
year = {2008}
}
@article{Cattell1890,
author = {Cattell, J M},
file = {:Users/gmac/mendeley/Cattell/Cattell - 1890 - Mental Tests and Measurements.pdf:pdf},
journal = {Mind},
month = {jan},
pages = {373--380},
title = {{Mental Tests and Measurements}},
url = {papers3://publication/uuid/51DBB3ED-4239-4883-997C-44691DED5182},
volume = {15},
year = {1890}
}
@article{Fadiga2002,
abstract = {The precise neural mechanisms underlying speech perception are still to a large extent unknown. The most accepted view is that speech perception depends on auditory-cognitive mechanisms specifically devoted to the analysis of speech sounds. An alternative view is that, crucial for speech perception, it is the activation of the articulatory (motor) gestures that generate these sounds. The listener understands the speaker when his/her articulatory gestures are activated (motor theory of speech perception). Here, by using transcranial magnetic stimulation (TMS), we demonstrate that, during speech listening, there is an increase of motor-evoked potentials recorded from the listeners' tongue muscles when the presented words strongly involve, when pronounced, tongue movements. Although these data do not prove the motor theory of speech perception, they demonstrate for the first time that word listening produces a phoneme specific activation of speech motor centres.},
address = {Dipartimento di Scienze Biomediche e Terapie Avanzate, Sezione di Fisiologia Umana, Universit{\`{a}} di Ferrara, via Fossato di Mortara 17/19, 44100 Ferrara, Italy. fdl@unife.it},
author = {Fadiga, Luciano and Craighero, Laila and Buccino, Giovanni and Rizzolatti, Giacomo},
file = {:Users/gmac/mendeley/Fadiga et al/Fadiga et al. - 2002 - Speech listening specifically modulates the excitability of tongue muscles a TMS study.pdf:pdf},
journal = {The European journal of neuroscience},
month = {jan},
number = {2},
pages = {399--402},
title = {{Speech listening specifically modulates the excitability of tongue muscles: a TMS study.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=11849307&retmode=ref&cmd=prlinks papers3://publication/uuid/8EDBD77E-0C77-4FEF-BFD0-557CEF7185BA},
volume = {15},
year = {2002}
}
@article{Burgoon1993,
author = {Burgoon, Judee K},
file = {:Users/gmac/mendeley/Burgoon/Burgoon - 1993 - Interpersonal Expectations, Expenctancy Violations, and Emotional Communication.pdf:pdf},
journal = {Journal of Language and Social Psychology},
month = {mar},
pages = {30--48},
title = {{Interpersonal Expectations, Expenctancy Violations, and Emotional Communication}},
url = {papers3://publication/uuid/052A552D-2991-4DF8-B538-391EDE428D70},
volume = {12},
year = {1993}
}
@article{Su2011,
abstract = {Abstract Auditory and motor systems interact in pro- cessing auditory rhythms. This study investigated the effect of intuitive body movement, such as head nodding or foot tapping, on listeners' ability to entrain to the pulse of an auditory sequence. A pulse-finding task was employed using ... 
},
author = {Su, Yi-Huang and P{\"{o}}ppel, Ernst},
file = {:Users/gmac/mendeley/Su, P{\"{o}}ppel/Su, P{\"{o}}ppel - 2011 - Body movement enhances the extraction of temporal structures in auditory sequences.pdf:pdf},
journal = {Psychological Research},
month = {jun},
number = {3},
pages = {373--382},
publisher = {Springer-Verlag},
title = {{Body movement enhances the extraction of temporal structures in auditory sequences}},
url = {http://link.springer.com/10.1007/s00426-011-0346-3 papers3://publication/doi/10.1007/s00426-011-0346-3},
volume = {76},
year = {2011}
}
@article{McLachlan2013,
author = {McLachlan, Neil and Marsh, James T and Light, Maria and Wilson, Sarah},
file = {:Users/gmac/mendeley/McLachlan et al/McLachlan et al. - 2013 - Consonance and Pitch.pdf:pdf},
journal = {Journal of Experimental Psychology: General},
keywords = {dissonance},
month = {jan},
title = {{Consonance and Pitch.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0030830 papers3://publication/doi/10.1037/a0030830},
year = {2013}
}
@article{Snyder2004,
annote = {Analysis:
1. epoching
2. baseline correction
3. artifact rejection (threshold=50 µV); channels with fewer than half trials left over excluded

Power modulation refers to a mean increase in power (i.e. square of amplitude) of the ongoing EEG across trials whereas phase coherence refers to a similarity in phase of the ongoing EEG across trials. Therefore, if phase coherence increases from pre-stimulus to post-stimulus periods this implies stimulus-related phase modulation of the EEG.},
author = {Snyder, Joel S and Large, Edward W},
file = {:Users/gmac/mendeley/Snyder, Large/Snyder, Large - 2004 - Tempo dependence of middle- and long-latency auditory responses power and phase modulation of the EEG at multiple.pdf:pdf},
journal = {Clinical Neurophysiology},
keywords = {rhythm},
month = {aug},
number = {8},
pages = {1885--1895},
title = {{Tempo dependence of middle- and long-latency auditory responses: power and phase modulation of the EEG at multiple time-scales}},
volume = {115},
year = {2004}
}
@incollection{Juslin2001,
address = {New York},
author = {Juslin, Patrik N},
booktitle = {Music and emotion: Theory and research},
editor = {Juslin, Patrik N and Sloboda, John A},
month = {jan},
number = {14},
pages = {309--337},
publisher = {Oxford University Press},
title = {{Communicating emotion in music performance: a review and theoretical framework BT  - Music and emotion: Theory and research}},
url = {papers3://publication/uuid/BA1DE03D-FFF2-465E-99DC-AB54EB7B83BA},
year = {2001}
}
@article{Ellenberger2005,
author = {Ellenberger, H F},
file = {:Users/gmac/mendeley/Ellenberger/Ellenberger - 2005 - The story of Anna O A critical review with new data.pdf:pdf},
journal = {Journal of the History of the Behavioral Sciences},
month = {dec},
pages = {267--279},
title = {{The story of "Anna O": A critical review with new data}},
url = {papers3://publication/uuid/19BC01EB-A055-4927-85F2-EA4E67F45A07},
volume = {8},
year = {2005}
}
@article{Owren2010,
author = {Owren, Michael J and Rendall, Drew and Ryan, Michael J},
file = {:Users/gmac/mendeley/Owren, Rendall, Ryan/Owren, Rendall, Ryan - 2010 - Redefining animal signaling influence versus information in communication.pdf:pdf},
journal = {Biology & Philosophy},
month = {jul},
number = {5},
pages = {755--780},
title = {{Redefining animal signaling: influence versus information in communication}},
url = {http://link.springer.com/10.1007/s10539-010-9224-4 papers3://publication/doi/10.1007/s10539-010-9224-4},
volume = {25},
year = {2010}
}
@article{Zatorre2007,
author = {Zatorre, Robert J and Chen, Joyce L and Penhune, Virginia B},
file = {:Users/gmac/mendeley/Zatorre, Chen, Penhune/Zatorre, Chen, Penhune - 2007 - When the brain plays music auditory–motor interactions in music perception and production.pdf:pdf},
journal = {Nature Reviews Neuroscience},
month = {jul},
number = {7},
pages = {547--558},
title = {{When the brain plays music: auditory–motor interactions in music perception and production}},
url = {http://www.nature.com/doifinder/10.1038/nrn2152},
volume = {8},
year = {2007}
}
@article{Nicolaou2017,
author = {Nicolaou, Nicoletta and Malik, Asad and Daly, Ian and Weaver, James and Hwang, Faustina and Kirke, Alexis and Roesch, Etienne B. and Williams, Duncan and Miranda, Eduardo R. and Nasuto, Slawomir J.},
doi = {10.3389/fnhum.2017.00502},
file = {:Users/gmac/mendeley/Nicolaou et al/Nicolaou et al. - 2017 - Directed Motor-Auditory EEG Connectivity Is Modulated by Music Tempo.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
keywords = {brain,coherence analysis,coherence analysis, imaginary coherency, electroen,connectivity analysis,eeg,electroen,electroencephalography,frontiers in human neuroscience,frontiersin,imaginary coherency,music tempo,org,www},
number = {October},
pages = {1--16},
title = {{Directed Motor-Auditory EEG Connectivity Is Modulated by Music Tempo}},
volume = {11},
year = {2017}
}
@article{McDermott2010,
author = {McDermott, Josh H and Lehr, Andriana J and Oxenham, Andrew J},
file = {:Users/gmac/mendeley/McDermott, Lehr, Oxenham/McDermott, Lehr, Oxenham - 2010 - Individual Differences Reveal the Basis of Consonance.pdf:pdf},
journal = {Current Biology},
keywords = {dissonance},
month = {jun},
number = {11},
pages = {1035--1041},
publisher = {Elsevier Ltd},
title = {{Individual Differences Reveal the Basis of Consonance}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0960982210004574},
volume = {20},
year = {2010}
}
@article{Friston2010,
abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories - optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
archivePrefix = {arXiv},
arxivId = {arXiv:1507.02142v2},
author = {Friston, Karl},
doi = {10.1038/nrn2787},
eprint = {arXiv:1507.02142v2},
file = {:Users/gmac/mendeley/Friston/Friston - 2010 - The free-energy principle a unified brain theory.pdf:pdf},
isbn = {1471-0048 (Electronic)\r1471-003X (Linking)},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
number = {2},
pages = {127--138},
pmid = {20068583},
title = {{The free-energy principle: a unified brain theory?}},
url = {http://www.nature.com/doifinder/10.1038/nrn2787},
volume = {11},
year = {2010}
}
@article{McGarry2012,
abstract = {Abstract Previous studies demonstrate that perception of action presented audio -visually facilitates greater mirror neuron system (MNS) activity in humans (Kaplan and Iacoboni in Cogn Process 8 (2): 103–113, 2007) and non-human primates (Keysers et al. in Exp Brain ... 
},
author = {McGarry, Lucy M and Russo, Frank A and Schalles, Matt D and Pineda, Jaime A},
file = {:Users/gmac/mendeley/McGarry et al/McGarry et al. - 2012 - Audio-visual facilitation of the mu rhythm.pdf:pdf},
journal = {Experimental Brain Research},
keywords = {MNS,mu},
month = {mar},
number = {4},
pages = {527--538},
title = {{Audio-visual facilitation of the mu rhythm}},
url = {http://www.springerlink.com/index/10.1007/s00221-012-3046-3 papers3://publication/doi/10.1007/s00221-012-3046-3},
volume = {218},
year = {2012}
}
@article{Taylor2008,
author = {Taylor, Paul C J and Walsh, Vincent and Eimer, Martin},
file = {:Users/gmac/mendeley/Taylor, Walsh, Eimer/Taylor, Walsh, Eimer - 2008 - Combining TMS and EEG to study cognitive function and cortico–cortico interactions.pdf:pdf},
journal = {Behavioural Brain Research},
month = {aug},
number = {2},
pages = {141--147},
publisher = {Elsevier B.V.},
title = {{Combining TMS and EEG to study cognitive function and cortico–cortico interactions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0166432808001782 papers3://publication/doi/10.1016/j.bbr.2008.03.033},
volume = {191},
year = {2008}
}
@book{Davidson2003,
address = {New York, NY},
editor = {Davidson, Richard J and Scherer, Klaus R and Goldsmith, H Hill},
month = {jan},
pages = {1199},
title = {{No Title}},
year = {2003}
}
@article{Bertin-Mahieux2011,
abstract = {We introduce the Million Song Dataset, a freely-available collection of audio features and metadata for a million con- temporary popular music tracks. We describe its creation process, its content, and its possible uses. Attractive fea- tures of the Million Song Database include the range of ex- isting resources to which it is linked, and the fact that it is the largest current research dataset in our ﬁeld. As an illustra- tion, we present year prediction as an example application, a task that has, until now, been difﬁcult to study owing to the absence of a large set of suitable data. We show positive results on year prediction, and discuss more generally the future development of the dataset.},
author = {Bertin-Mahieux, Thierry and Ellis, Daniel P.W. and Whitman, Brian and Lamere, Paul},
doi = {10.1145/2187980.2188222},
file = {:Users/gmac/mendeley/Bertin-Mahieux et al/Bertin-Mahieux et al. - 2011 - The Million Song Dataset.pdf:pdf},
isbn = {9781450312301},
issn = {1450312306},
journal = {Ismir},
keywords = {music information retrieval,recommender systems},
pages = {591--596},
title = {{The Million Song Dataset}},
url = {http://ismir2011.ismir.net/papers/OS6-1.pdf%5Cnhttp://academiccommons.columbia.edu/catalog/ac:148381},
year = {2011}
}
@article{Polonenko2010,
abstract = {This study evaluated how closely the DSL v5.0 a prescription could be approximated with hearing aids, its relationship to preferred listening levels (PLLs) of adults with acquired hearing loss, and the self-reported outcomes of the resulting fittings.},
author = {Polonenko, Melissa J and Scollie, Susan D and Moodie, Sheila and Seewald, Richard C and Laurnagaray, Diana and Shantz, Juliane and Richards, Andrea},
doi = {10.3109/14992021003713122},
file = {:Users/gmac/mendeley/Polonenko et al/Polonenko et al. - 2010 - Fit to targets, preferred listening levels, and self-reported outcomes for the DSL v5.0 a hearing aid prescrip.pdf:pdf},
isbn = {1499-2027},
issn = {1708-8186},
journal = {International journal of audiology},
keywords = {80 and over,Adult,Aged,Algorithms,Attitude to Health,Audiometry,Auditory Perception,DSL v5.0a,DSL v5.0a Factors,Feasibility Studies,Female,Follow-Up Studies,Hearing Aids,Hearing Loss,Hearing Loss: psychology,Hearing Loss: therapy,Humans,Male,Middle Aged,Prosthesis Fitting,Prosthesis Fitting: methods,Pure-Tone,Regression Analysis,Severity of Illness Index,Time,Treatment Outcome},
number = {8},
pages = {550--60},
pmid = {20438300},
title = {{Fit to targets, preferred listening levels, and self-reported outcomes for the DSL v5.0 a hearing aid prescription for adults.}},
volume = {49},
year = {2010}
}
@article{Dunn2010,
abstract = {Theories proposing that how one thinks and feels is influenced by feedback from the body remain controversial. A central but untested prediction of many of these proposals is that how well individuals can perceive subtle bodily changes (interoception) determines the strength of the relationship between bodily reactions and cognitive-affective processing. In Study 1, we demonstrated that the more accurately participants could track their heartbeat, the stronger the observed link between their heart rate reactions and their subjective arousal (but not valence) ratings of emotional images. In Study 2, we found that increasing interoception ability either helped or hindered adaptive intuitive decision making, depending on whether the anticipatory bodily signals generated favored advantageous or disadvantageous choices. These findings identify both the generation and the perception of bodily responses as pivotal sources of variability in emotion experience and intuition, and offer strong supporting evidence for bodily feedback theories, suggesting that cognitive-affective processing does in significant part relate to “following the heart.”},
author = {Dunn, Barnaby D. and Galton, Hannah C. and Morgan, Ruth and Evans, Davy and Oliver, Clare and Meyer, Marcel and Cusack, Rhodri and Lawrence, Andrew D. and Dalgleish, Tim},
doi = {10.1177/0956797610389191},
file = {:Users/gmac/mendeley/Dunn et al/Dunn et al. - 2010 - Listening to Your Heart.pdf:pdf},
isbn = {1467-9280 (Electronic)\n0956-7976 (Linking)},
issn = {0956-7976},
journal = {Psychological Science},
keywords = {10,11,25,are used daily,arousal,bodily feedback,decision making,emotion,interoception,james-lange theory of emotion,received 3,revision accepted 6,somatic marker hypothesis,some metaphorical expressions that,such as},
number = {12},
pages = {1835--1844},
pmid = {21106893},
title = {{Listening to Your Heart}},
volume = {21},
year = {2010}
}
@inproceedings{Stober2016a,
abstract = {We introduce and compare several strategies for learning discriminative features from electroencephalography (EEG) recordings using deep learning techniques. EEG data are generally only available in small quantities, they are high-dimensional with a poor signal-to-noise ratio, and there is considerable variability between individual subjects and recording sessions. Our proposed techniques specifically address these challenges for feature learning. Cross-trial encoding forces auto-encoders to focus on features that are stable across trials. Similarity-constraint encoders learn features that allow to distinguish between classes by demanding that two trials from the same class are more similar to each other than to trials from other classes. This tuple-based training approach is especially suitable for small datasets. Hydra-nets allow for separate processing pathways adapting to subsets of a dataset and thus combine the advantages of individual feature learning (better adaptation of early, low-level processing) with group model training (better generalization of higher-level processing in deeper layers). This way, models can, for instance, adapt to each subject individually to compensate for differences in spatial patterns due to anatomical differences or variance in electrode positions. The different techniques are evaluated using the publicly available OpenMIIR dataset of EEG recordings taken while participants listened to and imagined music.},
archivePrefix = {arXiv},
arxivId = {1511.04306},
author = {Stober, Sebastian and Sternin, Avtial and Owen, Adrian M and Grahn, Jessica A},
booktitle = {ICLR 2016},
eprint = {1511.04306},
file = {:Users/gmac/mendeley/Stober et al/Stober et al. - 2016 - Deep Feature Learning for EEG Recordings.pdf:pdf},
pages = {1--24},
title = {{Deep Feature Learning for EEG Recordings}},
url = {https://arxiv.org/pdf/1511.04306.pdf http://arxiv.org/abs/1511.04306},
year = {2016}
}
@article{Chandrasekaran2009,
author = {Chandrasekaran, Bharath and Hornickel, Jane and Skoe, Erika and Nicol, Trent and Kraus, Nina},
file = {:Users/gmac/mendeley/Chandrasekaran et al/Chandrasekaran et al. - 2009 - Context-Dependent Encoding in the Human Auditory Brainstem Relates to Hearing Speech in Noise Implication.pdf:pdf},
journal = {Neuron},
month = {nov},
number = {3},
pages = {311--319},
publisher = {Elsevier Ltd},
title = {{Context-Dependent Encoding in the Human Auditory Brainstem Relates to Hearing Speech in Noise: Implications for Developmental Dyslexia}},
url = {http://dx.doi.org/10.1016/j.neuron.2009.10.006 papers3://publication/doi/10.1016/j.neuron.2009.10.006},
volume = {64},
year = {2009}
}
@misc{Dimberg1990,
abstract = {The aim of this paper is to review data from my laboratory, which were collected in an attempt to determine whether the facial EMG response is a general component of the emotional reaction. In a number of studies it was found that facial reactions: first, are spontaneously elicited and differ according to the kind of emotional stimuli to which subjects are exposed; second, are sensitive to learning; third, are consistent with how the subjects perceive the stimuli and their own specific emotions; fourth, are congruent with autonomic responses; fifth, are more pronounced for females than for males; and finally, differ among subjects with specific fears. These data converge to indicate that facial muscle activity is a general component of the emotional reaction and demonstrate that the facial EMG technique is a sensitive tool for measuring emotional reactions.},
author = {Dimberg, U},
booktitle = {Psychophysiology},
doi = {10.1111/j.1469-8986.1990.tb01962.x},
file = {:Users/gmac/mendeley/Dimberg/Dimberg - 1990 - Facial electromyography and emotional reactions.pdf:pdf},
isbn = {0048-5772},
issn = {00485772},
number = {5},
pages = {481--494},
pmid = {2274612},
title = {{Facial electromyography and emotional reactions}},
volume = {27},
year = {1990}
}
@article{Loehr2011,
author = {Loehr, Janeen D and Large, Edward W and Palmer, Caroline},
file = {:Users/gmac/mendeley/Loehr, Large, Palmer/Loehr, Large, Palmer - 2011 - Temporal coordination and adaptation to rate change in music performance.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
month = {jan},
number = {4},
pages = {1292--1309},
publisher = {American Psychological Association},
title = {{Temporal coordination and adaptation to rate change in music performance.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0023102 papers3://publication/doi/10.1037/a0023102},
volume = {37},
year = {2011}
}
@article{Phillips-Silver2008,
author = {Phillips-Silver, Jessica and Trainor, Laurel J},
file = {:Users/gmac/mendeley/Phillips-Silver, Trainor/Phillips-Silver, Trainor - 2008 - Vestibular influence on auditory metrical interpretation.pdf:pdf},
journal = {Brain and Cognition},
month = {jun},
number = {1},
pages = {94--102},
publisher = {Elsevier Inc.},
title = {{Vestibular influence on auditory metrical interpretation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0278262607001832 papers3://publication/doi/10.1016/j.bandc.2007.11.007},
volume = {67},
year = {2008}
}
@article{Klapp1998,
abstract = {If people could tap 2 rhythms independently, 1 rhythm with each hand, training people to tap the rhythms separately should enable them to tap the rhythms concurrently. However, nonmusician participants in the present experiments were unable to produce accurate intervals when lapping bimanually after they had mastered the rhythms individually. That finding implies that tapping concurrent rhythms requires an integrated sensory-motor representation incorporating the actions of both hands into a single pattern. Although training the rhythms separately cannot specify an integrated code, such specification is possible with bimanual training. Bimanual training quickly led to accurate tapping, but most participants then did not tap correctly either of the separate rhythms that had been mastered in the context of concurrent tapping. That finding suggests that the integrated representation does not code either rhythm independently.},
author = {Klapp, S T and Nelson, J M and Jagacinski, R J},
doi = {10.1080/00222899809601346},
file = {:Users/gmac/mendeley/Klapp, Nelson, Jagacinski/Klapp, Nelson, Jagacinski - 1998 - Can people tap concurrent bimanual rhythms independently.pdf:pdf},
issn = {0022-2895},
journal = {Journal of motor behavior},
number = {4},
pages = {301--22},
pmid = {20037035},
title = {{Can people tap concurrent bimanual rhythms independently?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20037035},
volume = {30},
year = {1998}
}
@article{Povel1985,
abstract = {To gain insight into the internal representation of temporal patterns , we studied the perception and reproduction of tone sequences in which only the tone-onset intervals were varied. A theory of the processing of such sequences, partly implemented as a computer ... 
},
author = {Povel, D J and Essens, P},
file = {:Users/gmac/mendeley/Povel, Essens/Povel, Essens - 1985 - Perception of temporal patterns.pdf:pdf},
journal = {Music Perception},
month = {jan},
number = {4},
pages = {411--440},
title = {{Perception of temporal patterns}},
url = {http://mp.ucpress.edu/cgi/doi/10.2307/40285311 papers3://publication/doi/10.2307/40285311},
volume = {2},
year = {1985}
}
@book{Juslin2001a,
address = {New York},
editor = {Juslin, Patrik N and Sloboda, John A},
month = {jan},
publisher = {Oxford University Press},
title = {{No Title}},
url = {papers3://publication/uuid/2671F770-81BF-4505-B4F1-77B87CD740B3},
year = {2001}
}
@article{Symons2016,
author = {Symons, Ashley E. and El-Deredy, Wael and Schwartze, Michael and Kotz, Sonja A.},
doi = {10.3389/fnhum.2016.00239},
file = {:Users/gmac/mendeley/Symons et al/Symons et al. - 2016 - The Functional Role of Neural Oscillations in Non-Verbal Emotional Communication.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
title = {{The Functional Role of Neural Oscillations in Non-Verbal Emotional Communication}},
url = {http://journal.frontiersin.org/article/10.3389/fnhum.2016.00239},
volume = {10},
year = {2016}
}
@book{London2012,
author = {London, Justin},
publisher = {Oxford University Press},
title = {{Hearing in time: Psychological aspects of musical meter}},
url = {http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780195160819.001.0001/acprof-9780195160819},
year = {2012}
}
@article{Castellano2008,
author = {Castellano, Ginevra and Mortillaro, Marcello and Camurri, Antonio and Volpe, Gualtiero},
file = {:Users/gmac/mendeley/Castellano et al/Castellano et al. - 2008 - Automated Analysis of Body Movement in Emotionally Expressive Piano Performances.pdf:pdf},
journal = {Music Perception},
month = {jan},
number = {2},
pages = {103--120},
title = {{Automated Analysis of Body Movement in Emotionally Expressive Piano Performances}},
url = {papers3://publication/doi/10.1525/MP.2008.26.2.103},
volume = {26},
year = {2008}
}
@article{Escoffier2015,
abstract = {Temporal regularities in the environment are thought to guide the allocation of attention in time. Here, we explored whether entrainment of neuronal oscillations underpins this phenomenon. Participants viewed a regular stream of images in silence, or in-synchrony or out-of-synchrony with an unmarked beat position of a slow (1.3. Hz) auditory rhythm. Focusing on occipital recordings, we analyzed evoked oscillations shortly before and event-related potentials (ERPs) shortly after image onset. The phase of beta-band oscillations in the in-synchrony condition differed from that in the out-of-synchrony and silence conditions. Additionally, ERPs revealed rhythm effects for a stimulus onset potential (SOP) and the N1. Both were more negative for the in-synchrony as compared to the out-of-synchrony and silence conditions and their amplitudes positively correlated with the beta phase effects. Taken together, these findings indicate that rhythmic expectations are supported by a reorganization of neural oscillations that seems to benefit stimulus processing at expected time points. Importantly, this reorganization emerges from global rhythmic cues, across modalities, and for frequencies significantly higher than the external rhythm. As such, our findings support the idea that entrainment of neuronal oscillations represents a general mechanism through which the brain uses predictive elements in the environment to optimize attention and stimulus perception. •Images were presented while an auditory rhythm played in the background.•Images appeared in- or out-of-synchrony with an unmarked beat position.•N1 was enhanced for images presented in- as compared to out-of-synchrony.•Beta phase before image onset differed between in- and out-of-synchrony.•Beta phase shift between both conditions predicted the N1 amplitude effect.},
author = {Escoffier, Nicolas and Herrmann, Christoph S. and Schirmer, Annett},
doi = {10.1016/j.neuroimage.2015.02.024},
file = {:Users/gmac/mendeley/Escoffier, Herrmann, Schirmer/Escoffier, Herrmann, Schirmer - 2015 - Auditory rhythms entrain visual processes in the human brain Evidence from evoked oscillations an.pdf:pdf},
isbn = {1095-9572 (Electronic) 1053-8119 (Linking)},
issn = {10959572},
journal = {NeuroImage},
keywords = {Dynamic attending,Temporal preparation,Time perception,Timing},
pages = {267--276},
pmid = {25701698},
title = {{Auditory rhythms entrain visual processes in the human brain: Evidence from evoked oscillations and event-related potentials}},
volume = {111},
year = {2015}
}
@article{Phillips-Silver2007,
author = {Phillips-Silver, Jessica and Trainor, Laurel J},
file = {:Users/gmac/mendeley/Phillips-Silver, Trainor/Phillips-Silver, Trainor - 2007 - Hearing what the body feels Auditory encoding of rhythmic movement.pdf:pdf},
journal = {Cognitive Brain Research},
month = {dec},
number = {3},
pages = {533--546},
title = {{Hearing what the body feels: Auditory encoding of rhythmic movement}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0010027706002393 papers3://publication/doi/10.1016/j.cognition.2006.11.006},
volume = {105},
year = {2007}
}
@article{Doesburg2009a,
author = {Doesburg, Sam M and Green, Jessica J and McDonald, John J and Ward, Lawrence M},
file = {:Users/gmac/mendeley/Doesburg et al/Doesburg et al. - 2009 - From local inhibition to long-range integration A functional dissociation of alpha-band synchronization acro(2).pdf:pdf},
journal = {Brain Research},
month = {nov},
number = {C},
pages = {97--110},
publisher = {Elsevier B.V.},
title = {{From local inhibition to long-range integration: A functional dissociation of alpha-band synchronization across cortical scales in visuospatial attention}},
url = {http://dx.doi.org/10.1016/j.brainres.2009.09.069 papers3://publication/doi/10.1016/j.brainres.2009.09.069},
volume = {1303},
year = {2009}
}
@article{Iversen2009,
author = {Iversen, John R and Repp, Bruno H and Patel, Aniruddh D},
file = {:Users/gmac/mendeley/Iversen, Repp, Patel/Iversen, Repp, Patel - 2009 - Top-Down Control of Rhythm Perception Modulates Early Auditory Responses.pdf:pdf},
journal = {Annals of the New York Academy of Sciences},
month = {jul},
number = {1},
pages = {58--73},
title = {{Top-Down Control of Rhythm Perception Modulates Early Auditory Responses}},
url = {http://doi.wiley.com/10.1111/j.1749-6632.2009.04579.x papers3://publication/doi/10.1111/j.1749-6632.2009.04579.x},
volume = {1169},
year = {2009}
}
@article{Tomic2008,
abstract = {Current models for capturing metric structure of recordings of music are concerned primarily with the task of tempo and beat estimation. Even though these models have the potential for extracting other metric and rhythmic information, this potential has not been realized. In this paper, a model for describing the general metric structure of audio signals and behavioral data is presented. This model employs reson filters, rather than the comb filters used in earlier models. The oscillatory nature of reson filters is investigated, as they may be better suited for extracting multiple metric levels in the onset patterns of acoustic signals. The model is tested with several types of sequences of Dirac impulses as inputs, in order to investigate the model's sensitivity to timing variations and accent structure. The model's responses to natural stimuli are illustrated, both for excerpts of recorded music from a large database utilized by tempo-estimation models, and sequences of taps from a bimanual tapping task. Finally, the relationship of the model to several other beat-finding and rhythm models is discussed, and several applications and extensions for the model are suggested.},
author = {Tomic, Stefan T and Janata, Petr},
doi = {10.1121/1.3006382},
file = {:Users/gmac/mendeley/Tomic, Janata/Tomic, Janata - 2008 - Beyond the beat modeling metric structure in music and performance.pdf:pdf},
isbn = {1520-8524 (Electronic)\r0001-4966 (Linking)},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
pages = {4024--4041},
pmid = {19206825},
title = {{Beyond the beat: modeling metric structure in music and performance.}},
volume = {124},
year = {2008}
}
@article{Moushegian1973,
author = {Moushegian, George and Rupert, Allen L and Stillman, Robert D},
file = {:Users/gmac/mendeley/Moushegian, Rupert, Stillman/Moushegian, Rupert, Stillman - 1973 - Scalp-Recorded Early Responses in man to Frequencies in the Speech Range.pdf:pdf},
journal = {Electroencephalography and Clinical Neurophysiology},
month = {jan},
pages = {665--667},
title = {{Scalp-Recorded Early Responses in man to Frequencies in the Speech Range}},
url = {papers3://publication/uuid/2B6F793F-3779-42EE-A3C5-0822634E4270},
volume = {35},
year = {1973}
}
@inproceedings{Frigo1998,
address = {Washington, DC},
author = {Frigo, Matteo and Johnson, Steven G},
booktitle = {Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing},
file = {:Users/gmac/mendeley/Frigo, Johnson/Frigo, Johnson - 1998 - FFTW An Adaptive Software Architecture for the FFT.pdf:pdf},
month = {jan},
pages = {1381--1384},
publisher = {Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing},
title = {{FFTW: An Adaptive Software Architecture for the FFT}},
url = {papers3://publication/uuid/25233A32-33DE-4F4A-8CD7-8D67B7A016ED},
volume = {3},
year = {1998}
}
@article{Limb2008,
author = {Limb, Charles J and Braun, Allen R},
file = {:Users/gmac/mendeley/Limb, Braun/Limb, Braun - 2008 - Neural Substrates of Spontaneous Musical Performance An fMRI Study of Jazz Improvisation.pdf:pdf},
journal = {PLoS ONE},
month = {feb},
number = {2},
pages = {1--9},
title = {{Neural Substrates of Spontaneous Musical Performance: An fMRI Study of Jazz Improvisation}},
url = {papers3://publication/doi/10.1371/journal.pone.0001679},
volume = {3},
year = {2008}
}
@article{Zanto2005,
annote = {- evoked response is observed when gamma oscillations are phase-locked to a stimulus, and an induced response is observed when peaks in gamma activity are time-locked to a stimulus (p.4)
- evoked gamma-band activity retained a consistent level of power across all tempos (p.5)
- induced (non–phase-locked) GBA were found to predict both the timing and intensity of event onsets (p.5)
- omission of individual events at expected times left the timing and power of induced GBA unchanged (p.5)
- with induced activity indexing expectancy and evoked activity indexing reactions to sounded events (p.5)

Analysis:
- Raw EEG data were band-pass filtered from 0.10 to 50Hz using a finite impulse response filter
- First, a time-frequency (TF) representation was computed for each trial at each electrode using a continuous one-dimensional complex Morlet wavelet transform (20–50 Hz). This yields a two-dimensional representation in which each point is represented by a complex number preserving both amplitude and phase information
- The evoked response was calculated by averaging the TF representations over trials and then calculating power'
- the induced response was determined by calculating power before averaging the TF representation over trials

- Induced activity (Panels C and D) varied more between subjects than evoked GBA in both latency and locus of peak power (p.8)
- Why does induced activity assume the perturbation was a change in beat (and adjusted accordingly) and not just an early tone in an existing, unchanged beat?
- Peak at 1350ms suggests induced was adjusting to a new IOI of $\sim$675ms, but the tone at 1125ms kept that idea from persisting beyond 1350ms (Fig.9)

- induced is calculated as total power, hence 'evoked' peaks are seen in the induced graphs},
author = {Zanto, Theodore P and Large, Edward W and Fuchs, Armin and Kelso, J A Scott},
file = {:Users/gmac/mendeley/Zanto et al/Zanto et al. - 2005 - Gamma-Band Responses to Perturbed Auditory Sequences Evidence for Synchronization of Perceptual Processes.pdf:pdf},
journal = {Music Perception},
keywords = {gamma,rhythm},
month = {apr},
pages = {535--552},
title = {{Gamma-Band Responses to Perturbed Auditory Sequences: Evidence for Synchronization of Perceptual Processes}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/j.1467-9280.1997.tb00536.x papers3://publication/doi/10.1111/j.1467-9280.1997.tb00536.x},
volume = {22},
year = {2005}
}
@article{Muthuraman2012,
abstract = {The cortical control of bimanual and unimanual movements involves complex facilitatory and inhibitory interhemispheric interactions. We analysed the part of the cortical network directly related to the motor output by corticomuscular (64 channel EEG-EMG) and cortico-cortical (EEG-EEG) coherence and delays at the frequency of a voluntarily maintained unimanual and bimanual rhythm and in the 15-30-Hz band during isometric contractions. Voluntary rhythms of each hand showed coherence with lateral cortical areas in both hemispheres and occasionally in the frontal midline region (60-80 % of the recordings and 10-30 %, respectively). They were always coherent between both hands, and this coherence was positively correlated with the interhemispheric coherence (p < 0.01). Unilateral movements were represented mainly in the contralateral cortex (60-80 vs. 10-30 % ipsilateral, p < 0.01). Ipsilateral coherence was more common in left-hand movements, paralleled by more left-right muscle coherence. Partial corticomuscular coherence most often disappeared (p < 0.05) when the contralateral cortex was the predictor, indicating a mainly indirect connection of ipsilateral/frontomesial representations with the muscle via contralateral cortex. Interhemispheric delays had a bimodal distribution (1-10 and 15-30 ms) indicating direct and subcortical routes. Corticomuscular delays (mainly 12-25 ms) indicated fast corticospinal projections and musculocortical feedback. The 15-30-Hz corticomuscular coherence during isometric contractions (60-70 % of recordings) was strictly contralaterally represented without any peripheral left-right coherence. Thus, bilateral cortical areas generate voluntary unimanual and bimanual rhythmic movements. Interhemispheric interactions as detected by EEG-EEG coherence contribute to bimanual synchronization. This is distinct from the unilateral cortical representation of the 15-30-Hz motor rhythm during isometric movements.},
author = {Muthuraman, M. and Arning, K. and Govindan, R. B. and Heute, U. and Deuschl, G. and Raethjen, J.},
doi = {10.1007/s00221-012-3276-4},
file = {:Users/gmac/mendeley/Muthuraman et al/Muthuraman et al. - 2012 - Cortical representation of different motor rhythms during bimanual movements.pdf:pdf},
isbn = {0014-4819},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Bimanual movements,Corticomuscular coherence,Motor rhythms},
number = {4},
pages = {489--504},
pmid = {23007724},
title = {{Cortical representation of different motor rhythms during bimanual movements}},
volume = {223},
year = {2012}
}
@article{Henry2012,
author = {Henry, Molly J and Obleser, Jonas},
file = {:Users/gmac/mendeley/Henry, Obleser/Henry, Obleser - 2012 - Frequency modulation entrains slow neural oscillations and optimizes human listening behavior.pdf:pdf},
journal = {Proceedings of the National Acadamy of Sciences},
month = {dec},
number = {49},
pages = {20095--20100},
title = {{Frequency modulation entrains slow neural oscillations and optimizes human listening behavior}},
url = {papers3://publication/doi/10.1073/pnas.1213390109/-/DCSupplemental},
volume = {109},
year = {2012}
}
@article{Fitch2016,
abstract = {I argue that core aspects of musical rhythm, especially "groove" and syncopation, can only be fully understood in the context of their origins in the participatory social experience of dance. Musical meter is first considered in the context of bodily movement. I then offer an interpretation of the pervasive but somewhat puzzling phenomenon of syncopation in terms of acoustic emphasis on certain offbeat components of the accompanying dance style. The reasons for the historical tendency of many musical styles to divorce themselves from their dance-based roots are also briefly considered. To the extent that musical rhythms only make sense in the context of bodily movement, researchers interested in ecologically valid approaches to music cognition should make a more concerted effort to extend their analyses to dance, particularly if we hope to understand the cognitive constraints underlying rhythmic aspects of music like meter and groove.},
author = {Fitch, W Tecumseh},
doi = {10.3389/fnhum.2016.00064},
file = {:Users/gmac/mendeley/Fitch/Fitch - 2016 - Dance, music, meter and groove A forgotten partnership.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in human neuroscience},
keywords = {dance,groove,meter,music,musicality,rhythm},
number = {March},
pages = {64},
pmid = {26973489},
title = {{Dance, music, meter and groove: A forgotten partnership.}},
url = {http://journal.frontiersin.org/article/10.3389/fnhum.2016.00064%5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4771755&tool=pmcentrez&rendertype=abstract},
volume = {10},
year = {2016}
}
@article{Ekman1990,
author = {Ekman, Paul and Levenson, Robert W and Friesen, Wallace V},
file = {:Users/gmac/mendeley/Ekman, Levenson, Friesen/Ekman, Levenson, Friesen - 1990 - Autonomic Nervous System Activity Distinguishes Among Emotions.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Science},
pages = {1208--1210},
title = {{Autonomic Nervous System Activity Distinguishes Among Emotions}},
volume = {221},
year = {1990}
}
@article{Perlovsky2012,
author = {Perlovsky, L},
file = {:Users/gmac/mendeley/Perlovsky/Perlovsky - 2012 - Cognitive function, origin, and evolution of musical emotions.pdf:pdf},
journal = {Musicae Scientiae},
month = {jul},
number = {2},
pages = {185--199},
publisher = {European Society for the Cognitive Sciences of Music},
title = {{Cognitive function, origin, and evolution of musical emotions}},
url = {http://msx.sagepub.com/lookup/doi/10.1177/1029864912448327 papers3://publication/doi/10.1177/1029864912448327},
volume = {16},
year = {2012}
}
@article{Buss2009,
author = {Buss, David M},
file = {:Users/gmac/mendeley/Buss/Buss - 2009 - The Great Struggles of Life Darwin and the Emergence of Evolutionary Psychology.pdf:pdf},
journal = {American Psychologist},
month = {mar},
number = {2},
pages = {140--148},
publisher = {American Psychological Association},
title = {{The Great Struggles of Life: Darwin and the Emergence of Evolutionary Psychology}},
url = {http://dx.doi.org/10.1037/a0013207 papers3://publication/doi/10.1037/a0013207},
volume = {64},
year = {2009}
}
@article{Krishnan2004,
author = {Krishnan, Ananthanarayan and Xu, Yisheng and Gandour, Jackson T and Cariani, Peter A},
file = {:Users/gmac/mendeley/Krishnan et al/Krishnan et al. - 2004 - Human frequency-following response representation of pitch contours in Chinese tones.pdf:pdf},
journal = {Hearing Research},
month = {mar},
pages = {1--12},
publisher = {Elsevier B.V.},
title = {{Human frequency-following response: representation of pitch contours in Chinese tones}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378595503004027 papers3://publication/doi/10.1016/S0378-5955(03)00402-7},
volume = {189},
year = {2004}
}
@article{Eerola2013,
abstract = {The aim of this study is to manipulate musical cues systematically to determine the aspects of music that contribute to emotional expression, and whether these cues operate in additive or interactive fashion, and whether the cue levels can be characterized as linear or non-linear.},
author = {Eerola, Tuomas and Friberg, Anders and Bresin, Roberto},
file = {:Users/gmac/mendeley/Eerola, Friberg, Bresin/Eerola, Friberg, Bresin - 2013 - Emotional expression in music contribution, linearity, and additivity of primary musical cues.pdf:pdf},
journal = {Frontiers in Psychology},
month = {jul},
pages = {1--12},
title = {{Emotional expression in music: contribution, linearity, and additivity of primary musical cues}},
volume = {4},
year = {2013}
}
@article{Ekman1969,
author = {Ekman, Paul and Friesen, Wallace W},
file = {:Users/gmac/mendeley/Ekman, Friesen/Ekman, Friesen - 1969 - Pan-Cultural Elements in Facial Displays of Emotion.pdf:pdf},
pages = {86--88},
title = {{Pan-Cultural Elements in Facial Displays of Emotion}},
volume = {164},
year = {1969}
}
@article{Fadiga1995,
abstract = {1. We stimulated the motor cortex of normal subjects (transcranial magnetic stimulation) while they 1) observed an experimenter grasping 3D-objects, 2) looked at the same 3D-objects, 3) observed an experimenter tracing geometrical figures in the air with his arm, and 4) detected the dimming of a light. Motor evoked potentials (MEPs) were recorded from hand muscles. 2. We found that MEPs significantly increased during the conditions in which subjects observed movements. The MEP pattern reflected the pattern of muscle activity recorded when the subjects executed the observed actions. 3. We conclude that in humans there is a system matching action observation and execution. This system resembles the one recently described in the monkey.},
address = {Istituto di Fisiologia Umana, Universit{\`{a}} di Parma, Italy.},
author = {Fadiga, L and Fogassi, L and Pavesi, G and Rizzolatti, G},
file = {:Users/gmac/mendeley/Fadiga et al/Fadiga et al. - 1995 - Motor facilitation during action observation a magnetic stimulation study.pdf:pdf},
journal = {Journal of Neurophysiology},
month = {jun},
number = {6},
pages = {2608--2611},
title = {{Motor facilitation during action observation: a magnetic stimulation study.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=7666169&retmode=ref&cmd=prlinks papers3://publication/uuid/6DF2BDAD-500F-48CA-A864-8882B0F8A1E6},
volume = {73},
year = {1995}
}
@article{Hornickel2009,
abstract = {Children with reading impairments have deficits in phonological awareness, phonemic categorization, speech-in-noise perception, and psychophysical tasks such as frequency and temporal discrimination. Many of these children also exhibit abnormal encoding of speech stimuli in the auditory brainstem, even though responses to click stimuli are normal. In typically developing children the auditory brainstem response reflects acoustic differences between contrastive stop consonants. The current study investigated whether this subcortical differentiation of stop consonants was related to reading ability and speech-in-noise performance. Across a group of children with a wide range of reading ability, the subcortical differentiation of 3 speech stimuli ([ba], [da], [ga]) was found to be correlated with phonological awareness, reading, and speech-in-noise perception, with better performers exhibiting greater differences among responses to the 3 syllables. When subjects were categorized into terciles based on phonological awareness and speech-in-noise performance, the top-performing third in each grouping had greater subcortical differentiation than the bottom third. These results are consistent with the view that the neural processes underlying phonological awareness and speech-in-noise perception depend on reciprocal interactions between cognitive and perceptual processes.},
address = {Roxelyn and Richard Pepper Department of Communication Sciences, Northwestern University, Evanston, IL 60208, USA.},
author = {Hornickel, Jane and Skoe, Erika and Nicol, Trent and Zecker, Steven and Kraus, Nina},
file = {:Users/gmac/mendeley/Hornickel et al/Hornickel et al. - 2009 - Subcortical differentiation of stop consonants relates to reading and speech-in-noise perception.pdf:pdf},
journal = {PNAS},
month = {aug},
number = {31},
pages = {13022--13027},
title = {{Subcortical differentiation of stop consonants relates to reading and speech-in-noise perception.}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0901123106 papers3://publication/doi/10.1073/pnas.0901123106},
volume = {106},
year = {2009}
}
@article{Anderson2013,
annote = {- FFR reflects temporal discharge of auditory neurons in upper midbrain
- in FFR, consonant-to-vowel transition is vulnerable in noise; steady-state vowel remains relatively unchanged (e.g. /da/)
- Because of the influence of central and cognitive factors on speech-in-noise perception, the pure-tone audiogram, a largely peripheral measure, does not adequately predict the ability to hear in background noise, especially in older adults (p3)
- the older adults with good speech-in-noise perception had more robust subcortical stimulus representation, with higher root- mean-square (RMS) and ?0 amplitudes compared to older adults with poor speech-in-noise perception (p3)
- cABR is experience-dependant
-- bilingual speakers are better at SIN, have more robust coding of F0, related to better sustained attention
-- heightens directed attention toward linguistic inputs},
author = {Anderson, Samira and Kraus, Nina},
file = {:Users/gmac/mendeley/Anderson, Kraus/Anderson, Kraus - 2013 - The Potential Role of the cABR in Assessment and Management of Hearing Impairment.pdf:pdf},
journal = {International Journal of Otolaryngology},
month = {jan},
number = {s2},
pages = {1--10},
title = {{The Potential Role of the cABR in Assessment and Management of Hearing Impairment}},
url = {http://www.hindawi.com/journals/ijol/2013/604729/ papers3://publication/doi/10.1097/01.HJ.0000395478.70959.b1},
volume = {2013},
year = {2013}
}
@book{Stumpf1883,
address = {Leipzig},
author = {Stumpf, Carl},
month = {jan},
publisher = {Hirzel},
title = {{No Title}},
url = {papers3://publication/uuid/E3B8CF34-EC95-4463-BF65-E5DAD50303BC},
year = {1883}
}
@article{Ruffman2008,
abstract = {This meta-analysis of 28 data sets (N=705 older adults, N=962 younger adults) examined age differences in emotion recognition across four modalities: faces, voices, bodies/contexts, and matching of faces to voices. The results indicate that older adults have increased difficulty recognising at least some of the basic emotions (anger, sadness, fear, disgust, surprise, happiness) in each modality, with some emotions (anger and sadness) and some modalities (face-voice matching) creating particular difficulties. The predominant pattern across all emotions and modalities was of age-related decline with the exception that there was a trend for older adults to be better than young adults at recognising disgusted facial expressions. These age-related changes are examined in the context of three theoretical perspectives-positivity effects, general cognitive decline, and more specific neuropsychological change in the social brain. We argue that the pattern of age-related change observed is most consistent with a neuropsychological model of adult aging stemming from changes in frontal and temporal volume, and/or changes in neurotransmitters. ?? 2008 Elsevier Ltd. All rights reserved.},
author = {Ruffman, Ted and Henry, Julie D. and Livingstone, Vicki and Phillips, Louise H.},
doi = {10.1016/j.neubiorev.2008.01.001},
file = {:Users/gmac/mendeley/Ruffman et al/Ruffman et al. - 2008 - A meta-analytic review of emotion recognition and aging Implications for neuropsychological models of aging.pdf:pdf},
isbn = {0149-7634},
issn = {01497634},
journal = {Neuroscience and Biobehavioral Reviews},
keywords = {Aging,Amygdala,Cingulate cortex,Emotion recognition,Frontal lobe,General cognitive decline,Neuropsychology,Neurotransmitters,Orbitofrontal cortex,Temporal lobe},
number = {4},
pages = {863--881},
pmid = {18276008},
title = {{A meta-analytic review of emotion recognition and aging: Implications for neuropsychological models of aging}},
volume = {32},
year = {2008}
}
@article{Burger2014,
abstract = {Music has the capacity to induce movement in humans. Such responses during music listening are usually spontaneous and range from tapping to full-body dancing. However, it is still unclear how humans embody musical structures to facilitate entrainment. This paper describes two experiments, one dealing with period locking to different metrical levels in full-body movement and its relationships to beat- and rhythm-related musical characteristics, and the other dealing with phase locking in the more constrained condition of sideways swaying motions. Expected in Experiment 1 was that music with clear and strong beat structures would facilitate more period-locked movement. Experiment 2 was assumed to yield a common phase relationship between participants' swaying movements and the musical beat. In both experiments optical motion capture was used to record participants' movements. In Experiment 1 a window-based period-locking probability index related to four metrical levels was established, based on acceleration data in three dimensions. Subsequent correlations between this index and musical characteristics of the stimuli revealed pulse clarity to be related to periodic movement at the tactus level, and low frequency flux to mediolateral and anteroposterior movement at both tactus and bar levels. At faster tempi higher metrical levels became more apparent in participants' movement. Experiment 2 showed that about half of the participants showed a stable phase relationship between movement and beat, with superior-inferior movement most often being synchronized to the tactus level, whereas mediolateral movement was rather synchronized to the bar level. However, the relationship between movement phase and beat locations was not consistent between participants, as the beat locations occurred at different phase angles of their movements. The results imply that entrainment to music is a complex phenomenon, involving the whole body and occurring at different metrical levels.},
author = {Burger, Birgitta and Thompson, Marc R and Luck, Geoff and Saarikallio, Suvi H and Toiviainen, Petri},
doi = {10.3389/fnhum.2014.00903},
file = {:Users/gmac/mendeley/Burger et al/Burger et al. - 2014 - Hunting for the beat in the body on period and phase locking in music-induced movement.pdf:pdf},
isbn = {1662-5161},
issn = {1662-5161},
journal = {Frontiers in human neuroscience},
keywords = {dance,entrainment,motion capture,music-induced movement,period locking,phase locking},
number = {November},
pages = {903},
pmid = {25426051},
title = {{Hunting for the beat in the body: on period and phase locking in music-induced movement.}},
url = {http://journal.frontiersin.org/Journal/10.3389/fnhum.2014.00903/abstract},
volume = {8},
year = {2014}
}
@article{Bolanowski1988,
annote = {- four independent receptor channels located in the cutaneous tissues of humans (cited in Verrillo 1992)},
author = {Bolanowski, S J Jr and Gescheider, G A and Verrillo, Ronald T and Checkosky, C M},
file = {:Users/gmac/mendeley/Bolanowski et al/Bolanowski et al. - 1988 - Four channels mediate the mechanical aspects of touch.pdf:pdf},
journal = {Journal of Economic Psychology},
keywords = {haptics},
month = {nov},
number = {5},
pages = {1680--1694},
title = {{Four channels mediate the mechanical aspects of touch}},
url = {http://scitation.aip.org/getpdf/servlet/GetPDFServlet?filetype=pdf&id=JASMAN000084000005001680000001&idtype=cvips&doi=10.1121/1.397184&prog=normal papers3://publication/uuid/51D9DBDA-F9EC-4D1A-B52C-393B021E2B51},
volume = {84},
year = {1988}
}
@article{Krumhansl1997,
author = {Krumhansl, Carol L},
file = {:Users/gmac/mendeley/Krumhansl/Krumhansl - 1997 - An Exploratory Study of Musical Emotions and Psychophysiology.pdf:pdf},
journal = {Canadian Journal of Experimental Psychology},
number = {4},
pages = {336--352},
title = {{An Exploratory Study of Musical Emotions and Psychophysiology}},
volume = {51},
year = {1997}
}
@article{Haueisen2001,
abstract = {Pianists often report that pure listening to a well-trained piece of music can involuntarily trigger the respective finger movements. We designed a magnetoencephalography (MEG) experiment to compare the motor activation in pianists and nonpianists while listening to piano pieces. For pianists, we found a statistically significant increase of activity above the region of the contralateral motor cortex. Brain surface current density (BSCD) reconstructions revealed a spatial dissociation of this activity between notes preferably played by the thumb and the little finger according to the motor homunculus. Hence, we could demonstrate that pianists, when listening to well-trained piano music, exhibit involuntary motor activity involving the contralateral primary motor cortex (M1).},
address = {Friedrich-Schiller-University, Jena, Germany. haueisen@biomag.uni-jena.de},
author = {Haueisen, J and Kn{\"{o}}sche, T R},
file = {:Users/gmac/mendeley/Haueisen, Kn{\"{o}}sche/Haueisen, Kn{\"{o}}sche - 2001 - Involuntary motor activity in pianists evoked by music perception.pdf:pdf},
journal = {Journal of Cognitive Neuroscience},
month = {aug},
number = {6},
pages = {786--792},
title = {{Involuntary motor activity in pianists evoked by music perception.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=11564322&retmode=ref&cmd=prlinks papers3://publication/doi/10.1162/08989290152541449},
volume = {13},
year = {2001}
}
@article{Ro2009,
author = {Ro, Wosuk and Kwon, Younghun},
file = {:Users/gmac/mendeley/Ro, Kwon/Ro, Kwon - 2009 - 1f Noise analysis of songs in various genre of music.pdf:pdf},
journal = {Chaos, Solitons and Fractals},
keywords = {1/f},
month = {nov},
number = {4},
pages = {2305--2311},
publisher = {Elsevier Ltd},
title = {{1/f Noise analysis of songs in various genre of music}},
url = {http://dx.doi.org/10.1016/j.chaos.2009.03.129 papers3://publication/doi/10.1016/j.chaos.2009.03.129},
volume = {42},
year = {2009}
}
@article{Large2002a,
author = {Large, Edward W and Fink, Philip and Kelso, J A Scott},
file = {:Users/gmac/mendeley/Large, Fink, Kelso/Large, Fink, Kelso - 2002 - Tracking simple and complex sequences.pdf:pdf},
journal = {Psychological Research},
month = {feb},
number = {1},
pages = {3--17},
title = {{Tracking simple and complex sequences}},
url = {http://www.springerlink.com/openurl.asp?genre=article&id=doi:10.1007/s004260100069 papers3://publication/doi/10.1007/s004260100069},
volume = {66},
year = {2002}
}
@article{Cruickshanks1998,
abstract = {There are no recent population-based data on the prevalence of hearing loss in older adults using standard audiometric testing. The population-based Epidemiology of Hearing Loss Study was designed to measure the prevalence of hearing loss in adults aged 48-92 years, residing in Beaver Dam, Wisconsin. Hearing thresholds were measured with standardized protocols using pure-tone air- and bone-conduction audiometry in sound-treated booths. The examination also included an otoscopic evaluation, screening tympanogram, and a questionnaire on hearing-related medical history, noise exposure, other potential risk factors, and self-perceived hearing handicap. Of the 4,541 eligible people, 3,753 (82.6%) participated in the hearing study (1993-1995). The average age of participants was 65.8 years, and 57.7% were women. The prevalence of hearing loss was 45.9%. The odds of hearing loss increased with age (odds ratio (OR) = 1.88 for 5 years, 95% confidence interval (CI) 1.80-1.97) and were greater for men than women (OR = 4.42, 95% CI 3.73-5.24). The male excess of hearing loss remained statistically significant after adjusting for age, education, noise exposure, and occupation (OR = 3.65). These results demonstrate that hearing loss is a very common problem affecting older adults. Epidemiologic studies are needed to understand the genetic, environmental, and sex-related determinants of age-related hearing loss and to identify potential intervention strategies.},
address = {Department of Ophthalmology and Visual Sciences, University of Wisconsin Medical School, Madison 53705-2397, USA.},
author = {Cruickshanks, Karen J and Wiley, T L and Tweed, T S and Klein, B E and Klein, R and Mares-Perlman, J A and Nondahl, D M},
file = {:Users/gmac/mendeley/Cruickshanks et al/Cruickshanks et al. - 1998 - Prevalence of hearing loss in older adults in Beaver Dam, Wisconsin. The Epidemiology of Hearing Loss Study.pdf:pdf},
journal = {American journal of epidemiology},
month = {nov},
number = {9},
pages = {879--886},
title = {{Prevalence of hearing loss in older adults in Beaver Dam, Wisconsin. The Epidemiology of Hearing Loss Study.}},
url = {http://aje.oxfordjournals.org/content/148/9/879.short papers3://publication/uuid/774159CD-80E0-48FF-8DA8-5DAF62C13FEC},
volume = {148},
year = {1998}
}
@article{Fujioka2004,
author = {Fujioka, Takako and Trainor, Laurel J and Ross, Bernhard and Kakigi, Ryusuke and Pantev, Christo},
file = {:Users/gmac/mendeley/Fujioka et al/Fujioka et al. - 2004 - Musical Training Enhances Automatic Encoding of Melodic Contour and Interval Structure.pdf:pdf},
journal = {Journal of Cognitive Neuroscience},
month = {jul},
number = {6},
pages = {1010--1021},
title = {{Musical Training Enhances Automatic Encoding of Melodic Contour and Interval Structure}},
url = {papers3://publication/uuid/615740A4-B139-49F0-9FDE-6DF229C15E33},
volume = {16},
year = {2004}
}
@inproceedings{Stober2016,
abstract = {This paper addresses the question how music information retrieval techniques originally developed to process audio recordings can be adapted for the analysis of correspond-ing brain activity data. In particular, we conducted a case study applying beat tracking techniques to extract the tempo from electroencephalography (EEG) recordings obtained from people listening to music stimuli. We point out similarities and differences in processing audio and EEG data and show to which extent the tempo can be successfully extracted from EEG signals. Furthermore, we demonstrate how the tempo extraction from EEG signals can be stabilized by applying different fusion approaches on the mid-level tempogram features.},
author = {Stober, Sebastian and Pratzlich, Thomas and Muller, Meinard},
booktitle = {17th International Society for Music Information Retrieval Conference},
file = {:Users/gmac/mendeley/Stober, Pratzlich, Muller/Stober, Pratzlich, Muller - 2016 - Brain Beats Tempo Extraction from EEG Data.pdf:pdf},
keywords = {TODO},
pages = {276--282},
title = {{Brain Beats: Tempo Extraction from EEG Data}},
url = {https://www.audiolabs-erlangen.de/content/05-fau/professor/00-mueller/03-publications/2016_StoberPM_BeatEEG_ISMIR.pdf},
year = {2016}
}
@article{Picou2016,
author = {Picou, Erin M},
doi = {10.1044/2016},
file = {:Users/gmac/mendeley/Picou/Picou - 2016 - How Hearing Loss and Age Affect Emotional Responses to Nonspeech Sounds.pdf:pdf},
journal = {Journal of Speech, Language, and Hearing Research},
number = {October},
pages = {1233--1246},
title = {{How Hearing Loss and Age Affect Emotional Responses to Nonspeech Sounds}},
volume = {59},
year = {2016}
}
@article{Keller2007,
abstract = {Ensemble musicians play in synchrony despite expressively motivated irregularities in timing. We hypothesized that synchrony is achieved by each performer internally simulating the concurrent actions of other ensemble members, relying initially on how they would perform in their stead. Hence, musicians should be better at synchronizing with recordings of their own earlier performances than with others' recordings. We required pianists to record one part from each of several piano duets, and later to play the complementary part in synchrony with their own or others' recordings. The pianists were also asked to identify their own recordings. The pianists were better at synchronizing with their own than with others' performances, and they were able to recognize their own recordings. Furthermore, synchronization accuracy and recognition were correlated: Pianists who were relatively accurate at synchronizing with their own performances were also good at recognizing them. Thus, action simulation may underlie both synchronization and self-recognition. ?? 2006 Elsevier Inc. All rights reserved.},
author = {Keller, Peter E. and Knoblich, G??nther and Repp, Bruno H.},
doi = {10.1016/j.concog.2005.12.004},
file = {:Users/gmac/mendeley/Keller, Knoblich, Repp/Keller, Knoblich, Repp - 2007 - Pianists duet better when they play with themselves On the possible role of action simulation in synchro.pdf:pdf},
isbn = {1053-8100},
issn = {10538100},
journal = {Consciousness and Cognition},
keywords = {Action identification,Action simulation,Music,Self-identity,Synchronization},
number = {1},
pages = {102--111},
pmid = {16466932},
title = {{Pianists duet better when they play with themselves: On the possible role of action simulation in synchronization}},
volume = {16},
year = {2007}
}
@article{Large2015,
abstract = {Entrainment of cortical rhythms to acoustic rhythms has been hypothesized to be the neural correlate of pulse and meter perception in music. Dynamic attending theory first proposed synchronization of endogenous perceptual rhythms nearly 40 years ago, but only recently has the pivotal role of neural synchrony been demonstrated. Significant progress has since been made in understanding the role of neural oscillations and the neural structures that support synchronized responses to musical rhythm. Synchronized neural activity has been observed in auditory and motor networks, and has been linked with attentional allocation and movement coordination. Here we describe a neurodynamic model that shows how self-organization of oscillations in interacting sensory and motor networks could be responsible for the formation of the pulse percept in complex rhythms. In a pulse synchronization study, we test the model's key prediction that pulse can be perceived at a frequency for which no spectral energy is present in the amplitude envelope of the acoustic rhythm. The result shows that participants perceive the pulse at the theoretically predicted frequency. This model is one of the few consistent with neurophysiological evidence on the role of neural oscillation, and it explains a phenomenon that other computational models fail to explain. Because it is based on a canonical model, the predictions hold for an entire family of dynamical systems, not only a specific one. Thus, this model provides a theoretical link between oscillatory neurodynamics and the induction of pulse and meter in musical rhythm.},
author = {Large, Edward W and Herrera, Jorge A and Velasco, Marc J},
doi = {10.3389/fnsys.2015.00159},
file = {:Users/gmac/mendeley/Large, Herrera, Velasco/Large, Herrera, Velasco - 2015 - Neural Networks for Beat Perception in Musical Rhythm.pdf:pdf},
issn = {1662-5137},
journal = {Frontiers in systems neuroscience},
keywords = {1,beat perception,beat perception, neural resonance, musical rhythm,,dynamical systems,events,meter in musical rhythms,musical rhythm,neural networks,neural resonance,or speech syllables,pattern of timing and,perception of pulse and,rhythm refers to the,stress in,such as musical notes,temporally structured sequences of,the sounds that humans,use for communication are},
number = {November},
pages = {159},
pmid = {26635549},
title = {{Neural Networks for Beat Perception in Musical Rhythm.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4658578&tool=pmcentrez&rendertype=abstract},
volume = {9},
year = {2015}
}
@article{Bhattacharya2001,
abstract = {... Electronic address: joydeep @oeaw.ac ... They employed the circular vari- ance of the relative phase angles onto the unit circle in the complex plane and proposed mean phase  coherence to detect phase synchrony. ... 24 J. Bhattacharya and H. Petsche, NeuroReport 12, 371 2001. ... 
},
author = {Bhattacharya, Joydeep and Petsche, Hellmuth},
file = {:Users/gmac/mendeley/Bhattacharya, Petsche/Bhattacharya, Petsche - 2001 - Enhanced phase synchrony in the electroencephalograph $\gamma$ band for musicians while listening to music.pdf:pdf},
journal = {Physical Review E},
keywords = {gamma},
month = {jun},
number = {1},
pages = {12902},
title = {{Enhanced phase synchrony in the electroencephalograph $\gamma$ band for musicians while listening to music}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.64.012902 papers3://publication/doi/10.1103/PhysRevE.64.012902},
volume = {64},
year = {2001}
}
@article{Bigand2005,
author = {Bigand, E. and Vieillard, S. and Madurell, F. and Marozeau, J. and Dacquet, A.},
doi = {10.1080/02699930500204250},
file = {:Users/gmac/mendeley/Bigand et al/Bigand et al. - 2005 - Multidimensional scaling of emotional responses to music The effect of musical expertise and of the duration of t.pdf:pdf},
issn = {0269-9931},
journal = {Cognition & Emotion},
number = {8},
pages = {1113--1139},
title = {{Multidimensional scaling of emotional responses to music: The effect of musical expertise and of the duration of the excerpts}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02699930500204250},
volume = {19},
year = {2005}
}
@article{Fidali2011,
author = {Fidali, Brian C and Poudrier, {\`{E}}ve and Repp, Bruno H},
file = {:Users/gmac/mendeley/Fidali, Poudrier, Repp/Fidali, Poudrier, Repp - 2011 - Detecting perturbations in polyrhythms effects of complexity and attentional strategies.pdf:pdf},
journal = {Psychological Research},
month = {dec},
number = {2},
pages = {183--195},
title = {{Detecting perturbations in polyrhythms: effects of complexity and attentional strategies}},
url = {http://link.springer.com/10.1007/s00426-011-0406-8 papers3://publication/doi/10.1007/s00426-011-0406-8},
volume = {77},
year = {2011}
}
@article{Ammirante2013,
author = {Ammirante, Paolo and Russo, Frank A and Good, Arla and Fels, Deborah I},
editor = {Ptito, Maurice},
file = {:Users/gmac/mendeley/Ammirante et al/Ammirante et al. - 2013 - Feeling Voices.pdf:pdf},
journal = {PLoS ONE},
keywords = {haptics},
month = {jan},
number = {1},
pages = {e53585},
title = {{Feeling Voices}},
url = {http://dx.plos.org/10.1371/journal.pone.0053585.t002 papers3://publication/doi/10.1371/journal.pone.0053585.t002},
volume = {8},
year = {2013}
}
@article{Rossignol1976,
author = {Rossignol, S and {Melvill Jones}, G},
file = {:Users/gmac/mendeley/Rossignol, Melvill Jones/Rossignol, Melvill Jones - 1976 - Audio-spinal influence in man studied by the H-reflex and its possible role on rhythmic movement synch.pdf:pdf},
journal = {Electroencephalography and Clinical Neurophysiology},
month = {jan},
pages = {83--92},
title = {{Audio-spinal influence in man studied by the H-reflex and its possible role on rhythmic movement synchronized to sound}},
url = {papers3://publication/uuid/B60715AB-400D-4C75-83FA-73404F510F08},
volume = {41},
year = {1976}
}
@article{Salsburg1985,
author = {Salsburg, David S},
file = {:Users/gmac/mendeley/Salsburg/Salsburg - 1985 - The Religion of Statistics as Practiced in Medical Journals.pdf:pdf},
journal = {The American Statistician},
keywords = {stats},
month = {aug},
number = {3},
pages = {220--223},
title = {{The Religion of Statistics as Practiced in Medical Journals}},
url = {papers3://publication/uuid/9066296A-DDE4-4D30-82F5-E80938474A05},
volume = {39},
year = {1985}
}
@article{Farbood2013,
author = {Farbood, Morwaread Mary and Marcus, Gary and Poeppel, David},
file = {:Users/gmac/mendeley/Farbood, Marcus, Poeppel/Farbood, Marcus, Poeppel - 2013 - Temporal dynamics and the identification of musical key.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
month = {jan},
number = {4},
pages = {911--918},
publisher = {American Psychological Association},
title = {{Temporal dynamics and the identification of musical key.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0031087 papers3://publication/doi/10.1037/a0031087},
volume = {39},
year = {2013}
}
@article{Ekman1964,
abstract = {The communicative value of body position and facial expression was evaluated by measuring an O's ability to detect a relationship between nonverbal and verbal behavior which had been simultaneously emitted. The verbal and nonverbal stimuli were collected during 2 different standardized stress interviews. Judges (Js) were shown pairs of photographs together with short written speech samples and required on each trial to pick the photograph which matched the verbal behavior. In 4 separate experiments with different groups of Js, accurate judgments were obtained. Evidence for a relationship between nonverbal and verbal behavior simultaneously emitted was replicated across 2 different samples of interview behavior and under 3 cue conditions—seeing the head, body, or whole person.},
author = {Ekman, Paul},
doi = {10.1037/h0040225},
file = {:Users/gmac/mendeley/Ekman/Ekman - 1964 - Body Position, Facial Expression, and Verbal Behavior During Interviews.pdf:pdf},
isbn = {0021-843X (Print)\r0021-843X (Linking)},
journal = {Journal of Abnormal and Social Psychology},
keywords = {BEHAVIOR,COMMUNICATION,FACIAL EXPRESSION,POSTURE,SPEECH},
number = {3},
pages = {295--301},
pmid = {14126843},
title = {{Body Position, Facial  Expression, and Verbal Behavior During Interviews.}},
volume = {68},
year = {1964}
}
@article{Vrana1988,
abstract = {Twenty undergraduate subjects were presented with unsignaled 50-ms white noise bursts (95 dB) to probe their perceptual processing while viewing 36 colored photographic slides, depicting pleasant/interesting, neutral/dull, or unpleasant/interesting scenes and objects. Startle magnitudes to the noise bursts as measured by the eyeblink response were largest for unpleasant material and smallest for positive material. This effect was independent of measures or orienting, arousal, and interest in the materials. The results reconcile conflicting animal and human research. Alternative attentional and response matching explanations of these startle probe effects were evaluated. The startle probe is proposed as a broadly useful tool for studying emotion, its development and modification, and for the assessment of pathological anxiety.},
author = {Vrana, S R and Spence, E L and Lang, Peter J},
doi = {10.1037/0021-843X.97.4.487},
file = {:Users/gmac/mendeley/Vrana, Spence, Lang/Vrana, Spence, Lang - 1988 - The startle probe response a new measure of emotion.pdf:pdf},
isbn = {0021-843X (Print)\n0021-843X (Linking)},
issn = {0021-843X},
journal = {Journal of abnormal psychology},
number = {4},
pages = {487--491},
pmid = {3204235},
title = {{The startle probe response: a new measure of emotion?}},
volume = {97},
year = {1988}
}
@article{Morillon2017,
abstract = {In behavior, action and perception are inherently interdependent. However, the actual mechanistic contributions of the motor system to sensory processing are unknown. We present neurophysiological evidence that the motor system is involved in predictive timing, a brain function that aligns temporal fluctuations of attention with the timing of events in a task-relevant stream, thus facilitating sensory selection and optimizing behavior. In a magnetoencephalography experiment involving auditory temporal attention, participants had to disentangle twostreams of sound on the unique basis of endogenous temporal cues. We show that temporal predictions are encoded by interdependent delta and beta neural oscillations originating from the left sensorimotor cortex, and directed toward auditory regions. We also found that overt rhythmic movements improved the quality of temporal predictions and sharpened the temporal selection of relevant auditory information. This latter behavioral and functional benefit was associated with increased signaling of temporal predictions in right-lateralized frontoparietal associative regions. In sum, this study points at a covert form of auditory active sensing. Our results emphasize the key role of motor brain areas in providing contextual temporal information to sensory regions, driving perceptual and behavioral selection.},
author = {Morillon, Benjamin and Baillet, Sylvain},
doi = {10.1073/pnas.1705373114},
file = {:Users/gmac/mendeley/Morillon, Baillet/Morillon, Baillet - 2017 - Motor origin of temporal predictions in auditory attention.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {auditory perception,magnetoencephalography,psychophysics,rhythm,sensorimotor},
number = {42},
pages = {1--9},
pmid = {28973923},
title = {{Motor origin of temporal predictions in auditory attention}},
volume = {114},
year = {2017}
}
@article{Nieuwboer2007,
abstract = {Gait and mobility problems are difficult to treat in people with Parkinson's disease. The Rehabilitation in Parkinson's Disease: Strategies for Cueing (RESCUE) trial investigated the effects of a home physiotherapy programme based on rhythmical cueing on gait and gait-related activity.},
author = {Nieuwboer, A and Kwakkel, G and Rochester, L and Jones, D and van Wegen, E and Willems, A M and Chavret, F and Hetherington, V and Baker, K and Lim, I},
doi = {10.1136/jnnp.200X.097923},
file = {:Users/gmac/mendeley/Nieuwboer et al/Nieuwboer et al. - 2007 - Cueing training in the home improves gait-related mobility in Parkinson's disease the RESCUE trial.pdf:pdf},
isbn = {1468-330X (Electronic)},
issn = {0022-3050},
journal = {Journal of neurology, neurosurgery, and psychiatry},
number = {2},
pages = {134--140},
pmid = {17229744},
title = {{Cueing training in the home improves gait-related mobility in Parkinson's disease: the RESCUE trial.}},
volume = {78},
year = {2007}
}
@article{Rauschecker2009,
abstract = {Speech and language are considered uniquely human abilities: animals have communication systems, but they do not match human linguistic skills in terms of recursive structure and combinatorial power. Yet, in evolution, spoken language must have emerged from neural mechanisms at least partially available in animals. In this paper, we will demonstrate how our understanding of speech perception, one important facet of language, has profited from findings and theory in nonhuman primate studies. Chief among these are physiological and anatomical studies showing that primate auditory cortex, across species, shows patterns of hierarchical structure, topographic mapping and streams of functional processing. We will identify roles for different cortical areas in the perceptual processing of speech and review functional imaging work in humans that bears on our understanding of how the brain decodes and monitors speech. A new model connects structures in the temporal, frontal and parietal lobes linking speech perception and production.},
author = {Rauschecker, Josef P and Scott, Sophie K},
doi = {10.1038/nn.2331},
file = {:Users/gmac/mendeley/Rauschecker, Scott/Rauschecker, Scott - 2009 - Maps and streams in the auditory cortex nonhuman primates illuminate human speech processing.pdf:pdf},
isbn = {1546-1726 (Electronic)\r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature neuroscience},
number = {6},
pages = {718--724},
pmid = {19471271},
title = {{Maps and streams in the auditory cortex: nonhuman primates illuminate human speech processing.}},
volume = {12},
year = {2009}
}
@article{Barrett2007,
author = {Barrett, Lisa Feldman and Lindquist, Kristen A and Gendron, Maria},
file = {:Users/gmac/mendeley/Barrett, Lindquist, Gendron/Barrett, Lindquist, Gendron - 2007 - Language as context for the perception of emotion.pdf:pdf},
journal = {Trends in Cognitive Sciences},
month = {aug},
number = {8},
pages = {327--332},
publisher = {Elsevier Ltd},
title = {{Language as context for the perception of emotion}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661307001532 papers3://publication/doi/10.1016/j.tics.2007.06.003},
volume = {11},
year = {2007}
}
@article{Chatterjee2015,
abstract = {Hearing Research, 322 (2015) 151-162. doi:10.1016/j.heares.2014.10.003},
author = {Chatterjee, Monita and Zion, Danielle J and Deroche, Mickael L and Burianek, Brooke A and Limb, Charles J and Goren, Alison P and Kulkarni, Aditya M and Christensen, Julie A},
file = {:Users/gmac/mendeley/Chatterjee et al/Chatterjee et al. - 2015 - Voice emotion recognition by cochlear-implanted children and their normally-hearing peers.pdf:pdf},
journal = {Hearing Research},
month = {apr},
number = {C},
pages = {151--162},
publisher = {Elsevier B.V.},
title = {{Voice emotion recognition by cochlear-implanted children and their normally-hearing peers}},
url = {http://dx.doi.org/10.1016/j.heares.2014.10.003 papers3://publication/doi/10.1016/j.heares.2014.10.003},
volume = {322},
year = {2015}
}
@article{Aiken2008,
author = {Aiken, Steven J and Picton, Terence W},
file = {:Users/gmac/mendeley/Aiken, Picton/Aiken, Picton - 2008 - Envelope and spectral frequency-following responses to vowel sounds.pdf:pdf},
journal = {Hearing Research},
month = {nov},
number = {1-2},
pages = {35--47},
publisher = {Elsevier B.V.},
title = {{Envelope and spectral frequency-following responses to vowel sounds}},
url = {http://dx.doi.org/10.1016/j.heares.2008.08.004 papers3://publication/doi/10.1016/j.heares.2008.08.004},
volume = {245},
year = {2008}
}
@article{Martens2011,
author = {Martens, Peter A},
file = {:Users/gmac/mendeley/Martens/Martens - 2011 - The Ambiguous Tactus Tempo, Subdivision Benefit, And Three Listener Strategies.pdf:pdf},
journal = {Music Perception: An Interdisciplinary Journal},
month = {jun},
number = {5},
pages = {433--448},
publisher = {University of California Press},
title = {{The Ambiguous Tactus: Tempo, Subdivision Benefit, And Three Listener Strategies}},
url = {http://www.jstor.org/stable/info/10.1525/mp.2011.28.5.433},
volume = {28},
year = {2011}
}
@article{Repp2010,
author = {Repp, Bruno H},
file = {:Users/gmac/mendeley/Repp/Repp - 2010 - Sensorimotor synchronization and perception of timing Effects of music training and task experience.pdf:pdf},
journal = {Human Movement Science},
month = {apr},
number = {2},
pages = {200--213},
publisher = {Elsevier B.V.},
title = {{Sensorimotor synchronization and perception of timing: Effects of music training and task experience}},
url = {http://dx.doi.org/10.1016/j.humov.2009.08.002 papers3://publication/doi/10.1016/j.humov.2009.08.002},
volume = {29},
year = {2010}
}
@article{Watson1913,
author = {Watson, John B},
file = {:Users/gmac/mendeley/Watson/Watson - 1913 - Psychology as the behaviorist views it.pdf:pdf},
journal = {Psychological Review},
month = {jan},
pages = {158--177},
title = {{Psychology as the behaviorist views it}},
url = {papers3://publication/uuid/E11CB03F-771F-46E8-AACE-E1F66747C1AF},
volume = {20},
year = {1913}
}
@article{Most2009,
abstract = {This study evaluated the benefits of cochlear implant (CI) with regard to emotion perception of participants differing in their age of implantation, in comparison to hearing aid users and adolescents with normal hearing (NH). Emotion perception was examined by having the participants identify happiness, anger, surprise, sadness, fear, and disgust. The emotional content was placed upon the same neutral sentence. The stimuli were presented in auditory, visual, and combined auditory-visual modes. The results revealed better auditory identification by the participants with NH in comparison to all groups of participants with hearing loss (HL). No differences were found among the groups with HL in each of the 3 modes. Although auditory-visual perception was better than visual-only perception for the participants with NH, no such differentiation was found among the participants with HL. The results question the efficiency of some currently used CIs in providing the acoustic cues required to identify the speaker's emotional state.},
address = {School of Education, Tel Aviv University, Tel Aviv 69978, Israel. tovam@post.tau.ac.il},
author = {Most, Tova and Aviner, Chen},
file = {:Users/gmac/mendeley/Most, Aviner/Most, Aviner - 2009 - Auditory, visual, and auditory-visual perception of emotions by individuals with cochlear implants, hearing AIDS,.pdf:pdf},
journal = {Journal of Deaf Studies and Deaf Education},
month = {jan},
number = {4},
pages = {449--464},
publisher = {Oxford University Press},
title = {{Auditory, visual, and auditory-visual perception of emotions by individuals with cochlear implants, hearing AIDS, and normal hearing.}},
url = {http://www.jdsde.oxfordjournals.org/cgi/doi/10.1093/deafed/enp007 papers3://publication/doi/10.1093/deafed/enp007},
volume = {14},
year = {2009}
}
@article{Skoe2011,
abstract = {Journal of Neuroscience Methods, 196 (2011) 308-317. 10.1016/j.jneumeth.2011.01.020},
author = {Skoe, Erika and Nicol, Trent and Kraus, Nina},
file = {:Users/gmac/mendeley/Skoe, Nicol, Kraus/Skoe, Nicol, Kraus - 2011 - Cross-phaseogram Objective neural index of speech sound differentiation.pdf:pdf},
journal = {Journal of Neuroscience Methods},
month = {mar},
number = {2},
pages = {308--317},
publisher = {Elsevier B.V.},
title = {{Cross-phaseogram: Objective neural index of speech sound differentiation}},
url = {http://dx.doi.org/10.1016/j.jneumeth.2011.01.020 papers3://publication/doi/10.1016/j.jneumeth.2011.01.020},
volume = {196},
year = {2011}
}
@article{Pfordresher2009,
author = {Pfordresher, Peter Q and Brown, Steven},
file = {:Users/gmac/mendeley/Pfordresher, Brown/Pfordresher, Brown - 2009 - Enhanced production and perception of musical pitch in tone language speakers.pdf:pdf},
journal = {Attention, Perception, & Psychophysics},
month = {jan},
number = {6},
pages = {1385--1398},
title = {{Enhanced production and perception of musical pitch in tone language speakers}},
url = {papers3://publication/doi/10.3758/APP.71.6.1385},
volume = {71},
year = {2009}
}
@article{Bidelman2009,
author = {Bidelman, Gavin M and Krishnan, Ananthanarayan},
file = {:Users/gmac/mendeley/Bidelman, Krishnan/Bidelman, Krishnan - 2009 - Neural Correlates of Consonance, Dissonance, and the Hierarchy of Musical Pitch in the Human Brainstem.pdf:pdf},
journal = {Journal of Neuroscience},
month = {oct},
number = {42},
pages = {13165--13171},
title = {{Neural Correlates of Consonance, Dissonance, and the Hierarchy of Musical Pitch in the Human Brainstem}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3900-09.2009 papers3://publication/doi/10.1523/JNEUROSCI.3900-09.2009},
volume = {29},
year = {2009}
}
@article{Most1993,
abstract = {This study investigated the identification of non-verbal expressions of emotions by 19 hearing and 24 hearing-impaired adolescents. The participants were presented with video recordings of six emotions: anger, fear, sadness, surprise, happiness and disgust. The emotions were expressed on the same neutral sentence. The expressions were presented in three modes: visual, auditory and combined auditory-visual. The relative contributions of each mode to the identification processes were evaluated for the two research samples. The accuracy in identification of emotions through each of the presentation modes among the hearing-impaired participants was significantly lower than that of the hearing participants. The hearing participants performed better in the auditory-visual mode than in the auditory or the visual modes alone. The hearing-impaired participants performed better in the visual mode than in the auditory mode, and no difference was found between the auditory-visual mode and the visual mode alone. The lower performance of the hearing-impaired group suggested that rehabilitation processes should include training in the area of non-verbal perception. The rank order of the identification of emotions in both research samples was similar. Fear and surprise were the most difficult to identify. Similar order was found for each of the presentation modes as well. Further examination of the stimulus material with different groups of hearing-impaired individuals was recommended.},
address = {School of Education, Tel-Aviv University, Ramat-Aviv, Israel.},
author = {Most, T and Weisel, A and Zaychik, A},
file = {:Users/gmac/mendeley/Most, Weisel, Zaychik/Most, Weisel, Zaychik - 1993 - Auditory, visual and auditory-visual identification of emotions by hearing and hearing-impaired adolescen.pdf:pdf},
journal = {British journal of audiology},
month = {aug},
number = {4},
pages = {247--253},
title = {{Auditory, visual and auditory-visual identification of emotions by hearing and hearing-impaired adolescents.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=8312847&retmode=ref&cmd=prlinks papers3://publication/uuid/7708BE0C-69D1-40A9-AB3E-ED7F4EE769E4},
volume = {27},
year = {1993}
}
@article{Tallon-Baudry1999,
author = {Tallon-Baudry, Catherine and Bertrand, Olivier},
file = {:Users/gmac/mendeley/Tallon-Baudry, Bertrand/Tallon-Baudry, Bertrand - 1999 - Oscillatory gamma activity in humans and its role in object representation.pdf:pdf},
journal = {Trends in Cognitive Sciences},
keywords = {gamma},
month = {apr},
number = {4},
pages = {151--162},
publisher = {Elsevier Ltd},
title = {{Oscillatory gamma activity in humans and its role in object representation}},
url = {http://journals2.scholarsportal.info/tmp/11026268906314973442.pdf},
volume = {3},
year = {1999}
}
